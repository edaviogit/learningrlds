{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) 详解\n",
        "\n",
        "这是一个交互式的RLDS教程，包含了完整的代码示例和解释。\n",
        "\n",
        "**目标:**\n",
        "- 理解RLDS的核心概念和架构\n",
        "- 学习如何使用RLDS处理强化学习数据\n",
        "- 掌握数据集构建和处理的最佳实践\n",
        "\n",
        "**前置要求:**\n",
        "- Python 3.7+\n",
        "- TensorFlow 2.x\n",
        "- TensorFlow Datasets\n",
        "- RLDS库 (可选)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS (Reinforcement Learning Datasets) Tutorial\n",
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "# Try to import RLDS specific modules\n",
        "try:\n",
        "    import rlds\n",
        "    import envlogger\n",
        "    print(\"RLDS modules imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"RLDS modules not available. Install with: pip install rlds\")\n",
        "\n",
        "# Configure TensorFlow\n",
        "tf.config.experimental.set_memory_growth(\n",
        "    tf.config.experimental.list_physical_devices('GPU')[0], True\n",
        ") if tf.config.experimental.list_physical_devices('GPU') else None\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) 详解\n",
        "\n",
        "## 概述\n",
        "\n",
        "RLDS (Reinforcement Learning Datasets) 是Google DeepMind开发的用于强化学习的标准化数据集格式。它基于TensorFlow Datasets (TFDS) 构建，专门设计用于存储和处理强化学习轨迹数据，包括机器人学习、游戏AI等各种序列决策任务。\n",
        "\n",
        "**RLDS解决的核心问题：**\n",
        "- 缺乏标准化的强化学习数据集格式\n",
        "- 数据集格式不兼容导致算法无法重用\n",
        "- 时序信息丢失（如随机化步骤顺序）\n",
        "- 数据共享困难且易引入bug\n",
        "\n",
        "**RLDS的核心价值：**\n",
        "- **无损格式**：保留所有信息，维持时序关系\n",
        "- **算法无关**：支持不同算法的数据消费模式\n",
        "- **标准化**：统一的数据结构和语义\n",
        "- **生态系统**：完整的数据生产、共享、消费工具链\n",
        "\n",
        "## RLDS生态系统架构\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TB\n",
        "    subgraph Prod["Data Production"]\n",
        "        A[EnvLogger<br/>"Synthetic Data"] \n",
        "        B[RLDS Creator<br/>"Human Data"]\n",
        "        C["Custom Producers"]\n",
        "    end\n",
        "    \n",
        "    subgraph Store["Data Storage"]\n",
        "        D["RLDS Standard Format"]\n",
        "        E["TFDS Integration"]\n",
        "        F["Version Control"]\n",
        "    end\n",
        "    \n",
        "    subgraph Process["Data Processing"]\n",
        "        G["Transform Library"]\n",
        "        H["Batch Optimization"]\n",
        "        I["Performance Optimization"]\n",
        "    end\n",
        "    \n",
        "    subgraph Consume["Data Consumption"]\n",
        "        J["Episode-level Algorithms"]\n",
        "        K["Step-level Algorithms"]\n",
        "        L["Analysis Tools"]\n",
        "    end\n",
        "    \n",
        "    Prod --> Store\n",
        "    Store --> Process  \n",
        "    Process --> Consume\n",
        "    \n",
        "    Store -.-> M["TFDS Global Catalog"]\n",
        "    M -.-> N["Community Sharing"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDS架构图\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[RLDS Dataset] --> B[Episode Collection]\n",
        "    B --> C[Individual Episodes]\n",
        "    C --> D[Steps Sequence]\n",
        "    \n",
        "    D --> E[Observation]\n",
        "    D --> F[Action]\n",
        "    D --> G[Reward]\n",
        "    D --> H[Discount]\n",
        "    D --> I[Metadata]\n",
        "    \n",
        "    E --> E1[Images]\n",
        "    E --> E2[Proprio State]\n",
        "    E --> E3[Task Info]\n",
        "    \n",
        "    F --> F1[Joint Commands]\n",
        "    F --> F2[End-effector Pose]\n",
        "    F --> F3[Gripper Commands]\n",
        "    \n",
        "    subgraph Types["Data Types"]\n",
        "        J[\"tf.string - 压缩图像\"]\n",
        "        K[\"tf.float32 - 连续值\"]\n",
        "        L[\"tf.int32 - 离散值\"]\n",
        "        M[\"tf.bool - 布尔值\"]\n",
        "    end\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDS数据结构层次\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Dataset] --> B[Episodes]\n",
        "    B --> C[Steps]\n",
        "    C --> D[Fields]\n",
        "    \n",
        "    subgraph Episode[Episode级别]\n",
        "        E1[episode_id]\n",
        "        E2[episode_metadata]\n",
        "        E3[steps集合]\n",
        "    end\n",
        "    \n",
        "    subgraph Step[Step级别]\n",
        "        S1[observation]\n",
        "        S2[action]\n",
        "        S3[reward]\n",
        "        S4[discount]\n",
        "        S5[is_first]\n",
        "        S6[is_last]\n",
        "        S7[is_terminal]\n",
        "    end\n",
        "    \n",
        "    B -.-> Episode\n",
        "    C -.-> Step\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 核心数据结构\n",
        "\n",
        "### Episode 结构\n",
        "| 字段名 | 类型 | 描述 | 示例 |\n",
        "|--------|------|------|------|\n",
        "| `episode_id` | `tf.string` | 唯一标识符 | `\"episode_001\"` |\n",
        "| `episode_metadata` | `dict` | 元数据信息 | `{\"task\": \"pick_cup\", \"success\": True}` |\n",
        "| `steps` | `Sequence[Step]` | 步骤序列 | `[step_0, step_1, ..., step_n]` |\n",
        "\n",
        "### Step 结构\n",
        "| 字段名 | 类型 | 形状 | 描述 |\n",
        "|--------|------|------|------|\n",
        "| `observation` | `dict` | 可变 | 观测数据字典 |\n",
        "| `action` | `tf.float32` | `[action_dim]` | 动作向量 |\n",
        "| `reward` | `tf.float32` | `[]` | 奖励值 |\n",
        "| `discount` | `tf.float32` | `[]` | 折扣因子 |\n",
        "| `is_first` | `tf.bool` | `[]` | 是否为首步 |\n",
        "| `is_last` | `tf.bool` | `[]` | 是否为末步 |\n",
        "| `is_terminal` | `tf.bool` | `[]` | 是否终止 |\n",
        "\n",
        "### Observation 结构示例\n",
        "| 观测类型 | 字段名 | 类型 | 形状 | 描述 |\n",
        "|----------|--------|------|------|------|\n",
        "| 图像 | `image_primary` | `tf.string` | `[]` | 主摄像头图像(JPEG编码) |\n",
        "| 图像 | `image_wrist` | `tf.string` | `[]` | 手腕摄像头图像 |\n",
        "| 图像 | `image_side` | `tf.string` | `[]` | 侧视图像 |\n",
        "| 深度 | `depth_primary` | `tf.string` | `[]` | 深度图像 |\n",
        "| 状态 | `joint_positions` | `tf.float32` | `[7]` | 关节位置 |\n",
        "| 状态 | `joint_velocities` | `tf.float32` | `[7]` | 关节速度 |\n",
        "| 状态 | `end_effector_pose` | `tf.float32` | `[7]` | 末端执行器位姿 |\n",
        "| 状态 | `gripper_state` | `tf.float32` | `[1]` | 夹爪状态 |\n",
        "| 任务 | `task_description` | `tf.string` | `[]` | 任务描述 |\n",
        "| 任务 | `goal_image` | `tf.string` | `[]` | 目标图像 |\n",
        "\n",
        "## 示例数据集构建\n",
        "\n",
        "### 数据集配置信息\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "classDiagram\n",
        "    class DatasetConfig {\n",
        "        +string name\n",
        "        +string version\n",
        "        +string description\n",
        "        +dict features\n",
        "        +dict splits\n",
        "        +int total_episodes\n",
        "        +int total_steps\n",
        "    }\n",
        "    \n",
        "    class FeatureConfig {\n",
        "        +dict observation_space\n",
        "        +dict action_space\n",
        "        +float reward_range\n",
        "        +string task_type\n",
        "    }\n",
        "    \n",
        "    class SplitConfig {\n",
        "        +float train_ratio\n",
        "        +float val_ratio\n",
        "        +float test_ratio\n",
        "        +int train_episodes\n",
        "        +int val_episodes\n",
        "        +int test_episodes\n",
        "    }\n",
        "    \n",
        "    DatasetConfig --> FeatureConfig : contains\n",
        "    DatasetConfig --> SplitConfig : contains\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 示例：抓取任务数据集\n",
        "\n",
        "#### 数据集元信息\n",
        "| 属性 | 值 |\n",
        "|------|-----|\n",
        "| 数据集名称 | `robot_pick_place_v1` |\n",
        "| 版本 | `1.0.0` |\n",
        "| 任务类型 | `Pick and Place` |\n",
        "| 机器人平台 | `Franka Panda` |\n",
        "| 总episode数 | `10,000` |\n",
        "| 总步数 | `500,000` |\n",
        "| 平均episode长度 | `50 steps` |\n",
        "\n",
        "#### Episode示例数据\n",
        "\n",
        "**Episode 1 元数据**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\n",
        "{\n",
        "    \"episode_id\": \"episode_0001\",\n",
        "    \"task_type\": \"pick_red_cube\",\n",
        "    \"success\": true,\n",
        "    \"duration_seconds\": 12.5,\n",
        "    \"robot_id\": \"franka_001\",\n",
        "    \"scene_id\": \"kitchen_table_01\",\n",
        "    \"difficulty\": \"easy\",\n",
        "    \"annotations\": {\n",
        "        \"pick_frame\": 15,\n",
        "        \"place_frame\": 42,\n",
        "        \"contact_frames\": [16, 43]\n",
        "    }\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Step数据结构详解\n",
        "\n",
        "**Step 0 (初始状态)**\n",
        "| 字段 | 值 | 说明 |\n",
        "|------|-----|------|\n",
        "| `is_first` | `True` | 轨迹开始 |\n",
        "| `is_last` | `False` | 非结束步 |\n",
        "| `is_terminal` | `False` | 非终止步 |\n",
        "| `reward` | `0.0` | 初始奖励 |\n",
        "| `discount` | `1.0` | 标准折扣 |\n",
        "\n",
        "**观测数据 (Step 0)**\n",
        "| 观测项 | 数据类型 | 形状 | 示例值/描述 |\n",
        "|--------|----------|------|-------------|\n",
        "| `image_primary` | `tf.string` | `[]` | JPEG编码的RGB图像 (480×640×3) |\n",
        "| `image_wrist` | `tf.string` | `[]` | JPEG编码的手腕相机图像 (240×320×3) |\n",
        "| `depth_primary` | `tf.string` | `[]` | 压缩的深度图 (480×640×1) |\n",
        "| `joint_positions` | `tf.float32` | `[7]` | `[0.0, -0.785, 0.0, -2.356, 0.0, 1.571, 0.785]` |\n",
        "| `joint_velocities` | `tf.float32` | `[7]` | `[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]` |\n",
        "| `end_effector_pose` | `tf.float32` | `[7]` | `[0.5, 0.0, 0.3, 0.0, 0.0, 0.0, 1.0]` (位置+四元数) |\n",
        "| `gripper_state` | `tf.float32` | `[1]` | `[0.08]` (开启状态) |\n",
        "| `task_description` | `tf.string` | `[]` | `\"Pick up the red cube and place it in the box\"` |\n",
        "\n",
        "**动作数据 (Step 0→1)**\n",
        "| 动作维度 | 值 | 说明 |\n",
        "|----------|-----|------|\n",
        "| `delta_pos_x` | `0.02` | X轴位移 (m) |\n",
        "| `delta_pos_y` | `0.01` | Y轴位移 (m) |\n",
        "| `delta_pos_z` | `-0.005` | Z轴位移 (m) |\n",
        "| `delta_rot_x` | `0.0` | X轴旋转 (rad) |\n",
        "| `delta_rot_y` | `0.0` | Y轴旋转 (rad) |\n",
        "| `delta_rot_z` | `0.1` | Z轴旋转 (rad) |\n",
        "| `gripper_cmd` | `0.0` | 夹爪命令 (保持开启) |\n",
        "\n",
        "## 数据处理流水线\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart TD\n",
        "    A[原始传感器数据] --> B[数据采集]\n",
        "    B --> C[数据预处理]\n",
        "    C --> D[RLDS格式转换]\n",
        "    D --> E[质量检查]\n",
        "    E --> F[数据集构建]\n",
        "    \n",
        "    subgraph Preprocess[数据预处理]\n",
        "        C1[图像压缩]\n",
        "        C2[坐标系对齐]\n",
        "        C3[时间戳同步]\n",
        "        C4[异常值过滤]\n",
        "    end\n",
        "    \n",
        "    subgraph Quality[质量检查]\n",
        "        E1[轨迹完整性]\n",
        "        E2[数据一致性]\n",
        "        E3[成功率统计]\n",
        "        E4[异常检测]\n",
        "    end\n",
        "    \n",
        "    C -.-> Preprocess\n",
        "    E -.-> Quality\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 数据加载示例\n",
        "\n",
        "### Python代码示例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/edavio/anaconda3/envs/octo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "DatasetNotFoundError",
          "evalue": "Dataset robot_pick_place_v1 not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- user_libri_audio\n\t- user_libri_text\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: robot_pick_place_v1 -> robosuite_panda_pick_place_can ?\n\nThe builder directory /path/to/data/robot_pick_place_v1 doesn't contain any versions.\nNo builder could be found in the directory: /path/to/data for the builder: robot_pick_place_v1.\nNo registered data_dirs were found in:\n\t- /path/to/data\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 加载数据集\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ds_builder \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrobot_pick_place_v1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds_builder\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 检查数据结构\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/tensorflow_datasets/core/load.py:215\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)  \u001b[38;5;66;03m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m not_found_error\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/tensorflow_datasets/core/load.py:196\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# First check whether we can find the corresponding dataset builder code\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m   \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m registered\u001b[38;5;241m.\u001b[39mDatasetNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Class not found\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/tensorflow_datasets/core/load.py:121\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mregistered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimported_builder_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(Type[dataset_builder\u001b[38;5;241m.\u001b[39mDatasetBuilder], \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py:301\u001b[0m, in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is an abstract class.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _DATASET_REGISTRY:\n\u001b[0;32m--> 301\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    303\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m _DATASET_REGISTRY[name]\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_builder_available(builder_cls):\n",
            "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset robot_pick_place_v1 not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- user_libri_audio\n\t- user_libri_text\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: robot_pick_place_v1 -> robosuite_panda_pick_place_can ?\n\nThe builder directory /path/to/data/robot_pick_place_v1 doesn't contain any versions.\nNo builder could be found in the directory: /path/to/data for the builder: robot_pick_place_v1.\nNo registered data_dirs were found in:\n\t- /path/to/data\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# 加载数据集\n",
        "ds_builder = tfds.builder('robot_pick_place_v1', data_dir='/path/to/data')\n",
        "ds = ds_builder.as_dataset(split='train', shuffle_files=True)\n",
        "\n",
        "# 检查数据结构\n",
        "print(\"Dataset info:\")\n",
        "print(ds_builder.info)\n",
        "\n",
        "# 遍历episodes\n",
        "for episode in ds.take(1):\n",
        "    print(f\"Episode ID: {episode['episode_id']}\")\n",
        "    print(f\"Episode steps: {len(episode['steps'])}\")\n",
        "    \n",
        "    # 查看第一步\n",
        "    first_step = episode['steps'][0]\n",
        "    print(f\"First step observation keys: {first_step['observation'].keys()}\")\n",
        "    print(f\"Action shape: {first_step['action'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 数据统计信息\n",
        "\n",
        "#### 数据集分割\n",
        "| 分割 | Episode数 | 步数 | 成功率 | 平均长度 |\n",
        "|------|-----------|------|--------|----------|\n",
        "| Train | 8,000 | 400,000 | 85% | 50 steps |\n",
        "| Validation | 1,000 | 50,000 | 83% | 50 steps |\n",
        "| Test | 1,000 | 50,000 | 82% | 50 steps |\n",
        "\n",
        "#### 动作统计\n",
        "| 动作维度 | 最小值 | 最大值 | 均值 | 标准差 |\n",
        "|----------|--------|--------|------|--------|\n",
        "| `delta_pos_x` | -0.05 | 0.05 | 0.001 | 0.012 |\n",
        "| `delta_pos_y` | -0.05 | 0.05 | -0.002 | 0.015 |\n",
        "| `delta_pos_z` | -0.05 | 0.05 | 0.000 | 0.008 |\n",
        "| `delta_rot_x` | -0.2 | 0.2 | 0.003 | 0.045 |\n",
        "| `delta_rot_y` | -0.2 | 0.2 | -0.001 | 0.038 |\n",
        "| `delta_rot_z` | -0.2 | 0.2 | 0.005 | 0.052 |\n",
        "| `gripper_cmd` | -1.0 | 1.0 | 0.12 | 0.68 |\n",
        "\n",
        "## 与其他格式对比\n",
        "\n",
        "### 数据格式对比表\n",
        "| 特性 | RLDS | HDF5 | ROS Bag | OpenAI Gym |\n",
        "|------|------|------|---------|------------|\n",
        "| 标准化程度 | 高 | 中 | 低 | 中 |\n",
        "| 元数据支持 | 优秀 | 良好 | 优秀 | 基础 |\n",
        "| 压缩效率 | 高 | 高 | 中 | 低 |\n",
        "| 查询性能 | 优秀 | 良好 | 差 | 良好 |\n",
        "| 生态系统 | TF/JAX | 通用 | ROS | RL社区 |\n",
        "| "Version Control" | 支持 | 有限 | 无 | 无 |\n",
        "| 分布式训练 | 原生支持 | 需要额外工具 | 复杂 | 复杂 |\n",
        "\n",
        "## 最佳实践\n",
        "\n",
        "### 数据组织建议\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[数据集根目录] --> B[数据文件]\n",
        "    A --> C[元数据]\n",
        "    A --> D[配置文件]\n",
        "    A --> E[文档]\n",
        "    \n",
        "    B --> B1[\"train/\"]\n",
        "    B --> B2[\"validation/\"]\n",
        "    B --> B3[\"test/\"]\n",
        "    \n",
        "    C --> C1[\"dataset_info.json\"]\n",
        "    C --> C2[\"statistics.json\"]\n",
        "    C --> C3[\"features.json\"]\n",
        "    \n",
        "    D --> D1[\"builder_config.py\"]\n",
        "    D --> D2[\"preprocessing.py\"]\n",
        "    \n",
        "    E --> E1[\"README.md\"]\n",
        "    E --> E2[\"LICENSE\"]\n",
        "    E --> E3[\"CHANGELOG.md\"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 数据质量检查清单\n",
        "| 检查项 | 重要性 | 描述 |\n",
        "|--------|--------|------|\n",
        "| 轨迹完整性 | 高 | 确保每个episode都有完整的开始和结束 |\n",
        "| 时间一致性 | 高 | 检查时间戳的单调性和合理性 |\n",
        "| 动作合理性 | 高 | 验证动作在物理约束范围内 |\n",
        "| 图像质量 | 中 | 检查图像是否清晰、无损坏 |\n",
        "| 标注准确性 | 高 | 验证成功/失败标注的准确性 |\n",
        "| 数据平衡性 | 中 | 确保不同任务场景的平衡分布 |\n",
        "\n",
        "## 扩展和定制\n",
        "\n",
        "### 自定义观测空间\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 添加自定义观测\n",
        "custom_observation_spec = {\n",
        "    'image_overhead': tfds.features.Image(shape=(480, 640, 3)),\n",
        "    'force_torque': tfds.features.Tensor(shape=(6,), dtype=tf.float32),\n",
        "    'tactile_sensor': tfds.features.Tensor(shape=(16,), dtype=tf.float32),\n",
        "    'audio_data': tfds.features.Audio(sample_rate=16000),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 任务特定字段\n",
        "| 任务类型 | 特定字段 | 类型 | 描述 |\n",
        "|----------|----------|------|------|\n",
        "| 抓取任务 | `grasp_success` | `tf.bool` | 抓取是否成功 |\n",
        "| 导航任务 | `collision_detected` | `tf.bool` | 是否发生碰撞 |\n",
        "| 操作任务 | `contact_forces` | `tf.float32[6]` | 接触力信息 |\n",
        "| 学习任务 | `demonstration_id` | `tf.string` | 示教ID |\n",
        "\n",
        "## RLDS核心组件详解\n",
        "\n",
        "### 1. EnvLogger<br/>"Synthetic Data"收集\n",
        "\n",
        "EnvLogger是dm_env环境包装器，用于记录智能体与环境的交互：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import envlogger\n",
        "\n",
        "# 基本用法\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset'\n",
        ")\n",
        "\n",
        "# 高级用法 - 添加元数据回调\n",
        "def step_metadata_fn(timestep, action, env):\n",
        "    return {\n",
        "        'custom_reward': compute_custom_reward(timestep),\n",
        "        'difficulty': env.get_difficulty()\n",
        "    }\n",
        "\n",
        "def episode_metadata_fn(env):\n",
        "    return {\n",
        "        'success': env.is_success(),\n",
        "        'episode_length': env.step_count()\n",
        "    }\n",
        "\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset',\n",
        "    step_metadata_fn=step_metadata_fn,\n",
        "    episode_metadata_fn=episode_metadata_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**EnvLogger数据流**：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "生成: (o_0, _, _, _, m_0) → (o_1, a_0, r_0, d_0, m_1) → (o_2, a_1, r_1, d_1, m_2)\n",
        "存储: (o_0, a_0, r_0, d_0, m_0) → (o_1, a_1, r_1, d_1, m_1) → (o_2, a_2, r_2, d_2, m_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. RLDS Creator<br/>"Human Data"收集\n",
        "\n",
        "基于Web的工具，允许人类通过浏览器与环境交互：\n",
        "\n",
        "**特性：**\n",
        "- 跨平台Web界面\n",
        "- 实时数据记录\n",
        "- 支持多种输入设备\n",
        "- 众包数据收集支持\n",
        "\n",
        "### 3. "TFDS Integration"\n",
        "\n",
        "#### 数据集加载方式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 方式1: 从目录加载\n",
        "ds = tfds.builder_from_directory('/path/to/dataset').as_dataset(split='all')\n",
        "\n",
        "# 方式2: 从多个目录加载\n",
        "ds = tfds.builder_from_directories(['/path1', '/path2']).as_dataset(split='all')\n",
        "\n",
        "# 方式3: 从TFDS目录加载\n",
        "ds = tfds.load('d4rl_mujoco_halfcheetah/v0-medium')['train']\n",
        "\n",
        "# 方式4: 批量加载(非嵌套格式)\n",
        "ds = tfds.load('dataset_name', \n",
        "               decoders={rlds.STEPS: tfds.decode.SkipDecoding()},\n",
        "               split='train')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDS对TFDS的革命性扩展\n",
        "\n",
        "RLDS不仅是TFDS的简单用户，而是对TFDS进行了深度扩展和改进，专门针对强化学习数据的特殊需求。以下是RLDS在TFDS基础上做出的关键创新和改进：\n",
        "\n",
        "### 1. 嵌套数据集结构支持\n",
        "\n",
        "#### 传统TFDS的局限性\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 传统TFDS - 扁平化数据结构\n",
        "traditional_sample = {\n",
        "    'image': tf.Tensor(...),\n",
        "    'label': tf.Tensor(...),\n",
        "    'metadata': tf.Tensor(...)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### RLDS的嵌套数据集创新\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS - 嵌套数据集结构\n",
        "rlds_episode = {\n",
        "    'episode_id': tf.string,\n",
        "    'episode_metadata': {\n",
        "        'success': tf.bool,\n",
        "        'task_id': tf.string,\n",
        "        'collector_id': tf.string\n",
        "    },\n",
        "    'steps': tf.data.Dataset.from_generator(...)  # 嵌套数据集！\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**核心创新点：**\n",
        "- **嵌套tf.data.Dataset**：RLDS在TFDS中首次实现了数据集内嵌套数据集的支持\n",
        "- **时序数据保护**：确保episode内步骤的时序关系不被破坏\n",
        "- **动态长度支持**：每个episode可以有不同的步数\n",
        "\n",
        "### 2. 专用的RLDS Builder基类\n",
        "\n",
        "RLDS扩展了TFDS的Builder架构，提供了专门的基类：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import rlds\n",
        "\n",
        "class RoboticDatasetBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"RLDS专用的数据集构建器\"\"\"\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"RLDS compliant robotic dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                # Episode级元数据\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'episode_metadata': tfds.features.FeaturesDict({\n",
        "                    'success': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'task': tfds.features.Text(),\n",
        "                    'total_reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                }),\n",
        "                \n",
        "                # 核心创新：嵌套数据集结构\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    # Step级数据结构\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        # 支持多模态观测\n",
        "                        'image_primary': tfds.features.Image(shape=(224, 224, 3)),\n",
        "                        'image_wrist': tfds.features.Image(shape=(128, 128, 3)),\n",
        "                        'depth': tfds.features.Tensor(shape=(224, 224, 1), dtype=tf.float32),\n",
        "                        'proprioception': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                        'gripper_state': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    \n",
        "                    # RLDS标准字段\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    \n",
        "                    # 可扩展的元数据\n",
        "                    'step_metadata': tfds.features.FeaturesDict({\n",
        "                        'timestamp': tfds.features.Scalar(dtype=tf.float64),\n",
        "                        'control_frequency': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,  # RL数据没有监督学习的键\n",
        "            homepage='https://robotics-dataset.example.com',\n",
        "            citation=BIBTEX_CITATION,\n",
        "        )\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"生成RLDS兼容的样本\"\"\"\n",
        "        for episode_idx, episode_data in enumerate(self._load_episodes(data_path)):\n",
        "            # 构建步骤序列\n",
        "            steps = []\n",
        "            for step_idx, step_data in enumerate(episode_data['trajectory']):\n",
        "                step = {\n",
        "                    'observation': {\n",
        "                        'image_primary': step_data['cam_primary'],\n",
        "                        'image_wrist': step_data['cam_wrist'],\n",
        "                        'depth': step_data['depth_map'],\n",
        "                        'proprioception': step_data['joint_positions'],\n",
        "                        'gripper_state': step_data['gripper_pos'],\n",
        "                    },\n",
        "                    'action': step_data['action'],\n",
        "                    'reward': step_data['reward'],\n",
        "                    'discount': step_data.get('discount', 1.0),\n",
        "                    'is_first': step_idx == 0,\n",
        "                    'is_last': step_idx == len(episode_data['trajectory']) - 1,\n",
        "                    'is_terminal': step_data.get('terminal', False),\n",
        "                    'step_metadata': {\n",
        "                        'timestamp': step_data['timestamp'],\n",
        "                        'control_frequency': step_data['freq'],\n",
        "                    }\n",
        "                }\n",
        "                steps.append(step)\n",
        "            \n",
        "            # 构建完整episode\n",
        "            episode = {\n",
        "                'episode_id': f\"episode_{episode_idx:06d}\",\n",
        "                'episode_metadata': {\n",
        "                    'success': episode_data['metadata']['success'],\n",
        "                    'task': episode_data['metadata']['task_name'],\n",
        "                    'total_reward': sum(s['reward'] for s in steps),\n",
        "                },\n",
        "                'steps': steps\n",
        "            }\n",
        "            \n",
        "            yield f\"episode_{episode_idx}\", episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. 高级数据变换框架\n",
        "\n",
        "RLDS为TFDS添加了专门的变换框架，支持复杂的RL数据处理：\n",
        "\n",
        "#### a) Episode级变换\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds.transformations as rlds_transforms\n",
        "\n",
        "def advanced_episode_transform():\n",
        "    \"\"\"高级episode变换示例\"\"\"\n",
        "    \n",
        "    def add_episode_statistics(episode):\n",
        "        \"\"\"为episode添加统计信息\"\"\"\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # 计算episode级统计\n",
        "        total_steps = tf.data.experimental.cardinality(steps)\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        total_reward = rewards.reduce(tf.constant(0.0), tf.add)\n",
        "        \n",
        "        # 添加到元数据\n",
        "        episode['episode_metadata']['episode_length'] = total_steps\n",
        "        episode['episode_metadata']['total_reward'] = total_reward\n",
        "        return episode\n",
        "    \n",
        "    def filter_successful_episodes(episode):\n",
        "        \"\"\"过滤成功的episode\"\"\"\n",
        "        return episode['episode_metadata']['success']\n",
        "    \n",
        "    def normalize_rewards(episode):\n",
        "        \"\"\"归一化奖励\"\"\"\n",
        "        def normalize_step(step):\n",
        "            # 应用z-score归一化\n",
        "            normalized_reward = (step['reward'] - reward_mean) / reward_std\n",
        "            step['reward'] = normalized_reward\n",
        "            return step\n",
        "        \n",
        "        steps = episode[rlds.STEPS].map(normalize_step)\n",
        "        episode[rlds.STEPS] = steps\n",
        "        return episode\n",
        "    \n",
        "    return [add_episode_statistics, filter_successful_episodes, normalize_rewards]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) Step级高级变换\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def advanced_step_transforms():\n",
        "    \"\"\"高级step变换示例\"\"\"\n",
        "    \n",
        "    def augment_observations(step):\n",
        "        \"\"\"数据增强\"\"\"\n",
        "        obs = step['observation']\n",
        "        \n",
        "        # 图像增强\n",
        "        if 'image_primary' in obs:\n",
        "            image = obs['image_primary']\n",
        "            # 随机颜色抖动\n",
        "            image = tf.image.random_hue(image, max_delta=0.1)\n",
        "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "            obs['image_primary'] = image\n",
        "        \n",
        "        step['observation'] = obs\n",
        "        return step\n",
        "    \n",
        "    def add_next_observation(step, next_step):\n",
        "        \"\"\"添加下一步观测（用于Q学习等）\"\"\"\n",
        "        step['next_observation'] = next_step['observation']\n",
        "        return step\n",
        "    \n",
        "    def compute_advantage(step, value_estimate):\n",
        "        \"\"\"计算优势函数（用于策略梯度）\"\"\"\n",
        "        step['advantage'] = step['reward'] + 0.99 * value_estimate - step['value']\n",
        "        return step\n",
        "    \n",
        "    return [augment_observations, add_next_observation, compute_advantage]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4. 并行化数据构建支持\n",
        "\n",
        "RLDS扩展了TFDS的Apache Beam支持，实现高效的并行数据处理：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 传统TFDS构建\n",
        "tfds build\n",
        "\n",
        "# RLDS并行构建\n",
        "tfds build --overwrite --beam_pipeline_options=\"direct_running_mode=multi_processing,direct_num_workers=16\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 自定义并行处理器\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSParallelBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"支持并行处理的RLDS构建器\"\"\"\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"支持Beam并行处理的生成器\"\"\"\n",
        "        import apache_beam as beam\n",
        "        \n",
        "        # 创建Beam管道\n",
        "        with beam.Pipeline() as pipeline:\n",
        "            episodes = (\n",
        "                pipeline\n",
        "                | 'CreateEpisodePaths' >> beam.Create(self._get_episode_paths(data_path))\n",
        "                | 'ProcessEpisodes' >> beam.Map(self._process_single_episode)\n",
        "                | 'ValidateEpisodes' >> beam.Filter(self._is_valid_episode)\n",
        "                | 'FormatForTFDS' >> beam.Map(self._format_for_tfds)\n",
        "            )\n",
        "        \n",
        "        return episodes\n",
        "    \n",
        "    def _process_single_episode(self, episode_path):\n",
        "        \"\"\"处理单个episode（并行执行）\"\"\"\n",
        "        # 这个函数会在多个worker上并行执行\n",
        "        raw_data = self._load_episode_data(episode_path)\n",
        "        processed_episode = self._convert_to_rlds_format(raw_data)\n",
        "        return processed_episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5. 数据集修改和转换框架\n",
        "\n",
        "RLDS提供了强大的数据集后处理能力：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用RLDS数据集修改框架\n",
        "python modify_rlds_dataset.py \\\n",
        "    --dataset=my_robot_dataset \\\n",
        "    --mods=resize_images,add_language_conditioning,normalize_actions \\\n",
        "    --target_dir=/path/to/modified/dataset \\\n",
        "    --n_workers=16\n",
        "\n",
        "# 支持的修改操作\n",
        "SUPPORTED_MODIFICATIONS = {\n",
        "    'resize_images': ResizeImagesTransform(target_size=(224, 224)),\n",
        "    'jpeg_encode': JpegEncodeTransform(quality=95),\n",
        "    'add_language_conditioning': AddLanguageConditioningTransform(),\n",
        "    'normalize_actions': NormalizeActionsTransform(),\n",
        "    'filter_by_success': FilterBySuccessTransform(),\n",
        "    'subsample_timesteps': SubsampleTimestepsTransform(factor=2),\n",
        "    'add_goal_conditioning': AddGoalConditioningTransform(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 自定义修改函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomRLDSModification:\n",
        "    \"\"\"自定义RLDS数据修改\"\"\"\n",
        "    \n",
        "    def modify_dataset_info(self, info):\n",
        "        \"\"\"修改数据集信息\"\"\"\n",
        "        # 添加新的特征\n",
        "        features = info.features.copy()\n",
        "        features['steps']['goal_image'] = tfds.features.Image(shape=(224, 224, 3))\n",
        "        \n",
        "        return info._replace(features=features)\n",
        "    \n",
        "    def modify_example(self, example):\n",
        "        \"\"\"修改单个样本\"\"\"\n",
        "        steps = example['steps']\n",
        "        \n",
        "        # 为每个step添加目标图像\n",
        "        def add_goal_to_step(step):\n",
        "            # 使用最后一步的观测作为目标\n",
        "            step['goal_image'] = steps[-1]['observation']['image_primary']\n",
        "            return step\n",
        "        \n",
        "        modified_steps = steps.map(add_goal_to_step)\n",
        "        example['steps'] = modified_steps\n",
        "        \n",
        "        return example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 6. 专用的RLDS验证框架\n",
        "\n",
        "RLDS扩展了TFDS的验证机制，增加了RL特定的检查：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSValidator:\n",
        "    \"\"\"RLDS数据集验证器\"\"\"\n",
        "    \n",
        "    def validate_episode_structure(self, episode):\n",
        "        \"\"\"验证episode结构\"\"\"\n",
        "        checks = [\n",
        "            self._check_required_fields(episode),\n",
        "            self._check_step_consistency(episode),\n",
        "            self._check_temporal_ordering(episode),\n",
        "            self._check_terminal_states(episode),\n",
        "            self._check_reward_validity(episode),\n",
        "        ]\n",
        "        \n",
        "        return all(checks)\n",
        "    \n",
        "    def _check_step_consistency(self, episode):\n",
        "        \"\"\"检查步骤一致性\"\"\"\n",
        "        steps = episode['steps']\n",
        "        \n",
        "        # 检查第一步标记\n",
        "        first_step = next(iter(steps))\n",
        "        if not first_step['is_first']:\n",
        "            raise ValueError(\"First step must have is_first=True\")\n",
        "        \n",
        "        # 检查最后一步标记\n",
        "        step_count = 0\n",
        "        last_step = None\n",
        "        for step in steps:\n",
        "            step_count += 1\n",
        "            last_step = step\n",
        "        \n",
        "        if not last_step['is_last']:\n",
        "            raise ValueError(\"Last step must have is_last=True\")\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def _check_temporal_ordering(self, episode):\n",
        "        \"\"\"检查时间序列完整性\"\"\"\n",
        "        steps = list(episode['steps'])\n",
        "        \n",
        "        # 验证时间戳单调递增\n",
        "        if 'timestamp' in steps[0].get('step_metadata', {}):\n",
        "            timestamps = [s['step_metadata']['timestamp'] for s in steps]\n",
        "            if not all(t1 <= t2 for t1, t2 in zip(timestamps, timestamps[1:])):\n",
        "                raise ValueError(\"Timestamps must be non-decreasing\")\n",
        "        \n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 7. Open X-Embodiment数据集集成\n",
        "\n",
        "RLDS为大规模机器人数据集提供了专门的支持：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open X-Embodiment数据集下载和处理\n",
        "bash prepare_open_x.sh\n",
        "\n",
        "# 支持的数据集转换\n",
        "OPEN_X_DATASETS = [\n",
        "    'bridge_v2',\n",
        "    'rt_1',\n",
        "    'berkeley_autolab_ur5',\n",
        "    'taco_play',\n",
        "    'kuka_multimodal',\n",
        "    'stanford_robocook',\n",
        "    # ... 50+ 数据集\n",
        "]\n",
        "\n",
        "# 统一的变换接口\n",
        "def transform_for_x_embodiment(step):\n",
        "    \"\"\"转换为X-embodiment标准格式\"\"\"\n",
        "    return {\n",
        "        'observation': {\n",
        "            'image': step['observation']['image_primary'],  # 单一RGB输入\n",
        "            'natural_language_embedding': step['language_embedding'],\n",
        "        },\n",
        "        'action': step['action'][:7],  # 标准7-DOF动作\n",
        "        'reward': step['reward'],\n",
        "        'is_first': step['is_first'],\n",
        "        'is_last': step['is_last'],\n",
        "        'is_terminal': step['is_terminal'],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 8. 高级"Performance Optimization"\n",
        "\n",
        "RLDS实现了针对RL数据的专门优化：\n",
        "\n",
        "#### a) 智能缓存策略\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSCachingStrategy:\n",
        "    \"\"\"RLDS专用缓存策略\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.episode_cache = {}\n",
        "        self.step_cache = {}\n",
        "    \n",
        "    def cache_episode(self, episode_id, episode):\n",
        "        \"\"\"缓存完整episode\"\"\"\n",
        "        # 只缓存小型episode，避免内存溢出\n",
        "        if self._estimate_episode_size(episode) < 100_000_000:  # 100MB\n",
        "            self.episode_cache[episode_id] = episode\n",
        "    \n",
        "    def cache_step_sequence(self, episode_id, start_idx, steps):\n",
        "        \"\"\"缓存步骤序列（用于N-step学习）\"\"\"\n",
        "        cache_key = f\"{episode_id}_{start_idx}\"\n",
        "        self.step_cache[cache_key] = steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) 自适应批处理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaptive_batching(dataset, target_memory_usage=8_000_000_000):  # 8GB\n",
        "    \"\"\"根据内存使用情况自适应调整批大小\"\"\"\n",
        "    \n",
        "    def estimate_sample_size(sample):\n",
        "        \"\"\"估算样本内存使用\"\"\"\n",
        "        size = 0\n",
        "        for step in sample['steps']:\n",
        "            for key, value in step['observation'].items():\n",
        "                if 'image' in key:\n",
        "                    size += value.shape.num_elements() * 4  # float32\n",
        "                else:\n",
        "                    size += value.shape.num_elements() * value.dtype.size\n",
        "        return size\n",
        "    \n",
        "    # 动态计算批大小\n",
        "    sample = next(iter(dataset))\n",
        "    sample_size = estimate_sample_size(sample)\n",
        "    optimal_batch_size = max(1, target_memory_usage // sample_size)\n",
        "    \n",
        "    return dataset.batch(optimal_batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9. 与现有生态系统的兼容性\n",
        "\n",
        "RLDS确保与TensorFlow生态系统的完美兼容：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 与tf.data的无缝集成\n",
        "rlds_dataset = tfds.load('my_robot_dataset')\n",
        "tf_data_pipeline = (\n",
        "    rlds_dataset['train']\n",
        "    .flat_map(lambda ep: ep['steps'])  # 展平为step级数据\n",
        "    .map(preprocess_function)\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# 与tf.saved_model的兼容\n",
        "@tf.function\n",
        "def process_rlds_batch(batch):\n",
        "    \"\"\"处理RLDS批次数据\"\"\"\n",
        "    observations = batch['observation']['image']\n",
        "    actions = batch['action']\n",
        "    return model(observations), actions\n",
        "\n",
        "# 保存为SavedModel\n",
        "tf.saved_model.save(process_rlds_batch, '/path/to/saved_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 引用和致谢\n",
        "\n",
        "如果使用RLDS，请引用官方论文：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@misc{ramos2021rlds,\n",
        "    title={RLDS: an Ecosystem to Generate, Share and Use Datasets in Reinforcement Learning},\n",
        "    author={Sabela Ramos and Sertan Girgin and Léonard Hussenot and Damien Vincent and Hanna Yakubovich and Daniel Toyama and Anita Gergely and Piotr Stanczyk and Raphael Marinier and Jeremiah Harmsen and Olivier Pietquin and Nikola Momchev},\n",
        "    year={2021},\n",
        "    eprint={2111.02767},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.LG}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 使用RLDS的重要论文\n",
        "\n",
        "- **Hyperparameter Selection for Imitation Learning** (ICML 2021)\n",
        "- **Continuous Control with Action Quantization from Demonstrations** (NeurIPS 2021)  \n",
        "- **What Matters for Adversarial Imitation Learning?** (NeurIPS 2021)\n",
        "- **MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale**\n",
        "- **Offline Reinforcement Learning with Pseudometric Learning** (ICML 2021)\n",
        "\n",
        "## 总结\n",
        "\n",
        "RLDS提供了一个标准化、高效的强化学习数据存储和处理框架。其主要优势包括：\n",
        "\n",
        "1. **标准化格式**：统一的数据结构便于不同项目间的数据共享\n",
        "2. **高效存储**：基于TensorFlow的优化存储格式  \n",
        "3. **丰富元数据**：支持详细的任务和轨迹标注\n",
        "4. **易于处理**：与现代机器学习工具链无缝集成\n",
        "5. **可扩展性**：支持自定义观测空间和任务特定字段\n",
        "6. **"Performance Optimization"**：针对RL数据特点的专门优化\n",
        "7. **社区生态**：活跃的开源社区和丰富的数据集资源\n",
        "\n",
        "通过使用RLDS，研究者可以更容易地构建、共享和使用大规模强化学习数据集，推动强化学习技术的发展。 \n",
        "\n",
        "## 高级数据结构规范\n",
        "\n",
        "### Episode元数据扩展规范\n",
        "\n",
        "基于官方GitHub仓库，Episode支持以下标准元数据字段：\n",
        "\n",
        "| 字段名 | 类型 | 必需 | 描述 | 示例 |\n",
        "|--------|------|------|------|------|\n",
        "| `episode_id` | `tf.string` | 推荐 | 全局唯一标识符 | `\"dataset_v1_episode_12345\"` |\n",
        "| `agent_id` | `tf.string/tf.Tensor` | 可选 | 智能体标识符(支持多智能体) | `\"sac_agent_v2\"` 或 `[[agent_name, agent_id], ...]` |\n",
        "| `environment_config` | `dict` | 可选 | 环境配置参数 | `{\"gravity\": -9.8, \"friction\": 0.1}` |\n",
        "| `experiment_id` | `tf.string` | 可选 | 实验标识符 | `\"exp_20231215_hyperopt\"` |\n",
        "| `invalid` | `tf.bool` | 可选 | 无效episode标记 | `False` |\n",
        "\n",
        "### Step字段完整规范\n",
        "\n",
        "#### 必需字段\n",
        "| 字段名 | 类型 | 描述 | 重要说明 |\n",
        "|--------|------|------|----------|\n",
        "| `is_first` | `tf.bool` | 是否为首步 | 包含初始状态 |\n",
        "| `is_last` | `tf.bool` | 是否为末步 | 当为True时，后续字段无效 |\n",
        "\n",
        "#### 可选字段\n",
        "| 字段名 | 类型 | 描述 | 条件约束 |\n",
        "|--------|------|------|----------|\n",
        "| `observation` | `dict` | 当前观测 | 结构在数据集内必须一致 |\n",
        "| `action` | `tf.Tensor` | 执行的动作 | `is_last=True`时无效 |\n",
        "| `reward` | `tf.float32` | 获得的奖励 | `is_last=True`时无效 |\n",
        "| `discount` | `tf.float32` | 折扣因子 | 通常为1.0或γ |\n",
        "| `is_terminal` | `tf.bool` | 是否为终止状态 | 区分截断vs终止 |\n",
        "\n",
        "#### 终止状态语义\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 自然终止 (游戏结束)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': True,\n",
        "    'observation': final_obs,  # 有效的最终观测\n",
        "    'action': None,           # 无效\n",
        "    'reward': None,           # 无效\n",
        "    'discount': None          # 无效\n",
        "}\n",
        "\n",
        "# 截断终止 (时间限制)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': False,\n",
        "    'observation': final_obs,  # 有效的截断观测\n",
        "    'action': None,           # 可能无效\n",
        "    'reward': final_reward,   # 可能有效\n",
        "    'discount': gamma         # 可能有效\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDS"Transform Library"详解\n",
        "\n",
        "### 核心变换操作\n",
        "\n",
        "RLDS提供优化的"Transform Library"，考虑了RL数据集的嵌套结构：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds\n",
        "\n",
        "# 1. Episode级变换\n",
        "def process_episode(episode):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    # 添加自定义episode统计\n",
        "    episode_length = tf.data.experimental.cardinality(steps)\n",
        "    episode['metadata']['length'] = episode_length\n",
        "    return episode\n",
        "\n",
        "dataset = dataset.map(process_episode)\n",
        "\n",
        "# 2. Step级变换 - 展平episode\n",
        "step_dataset = episode_dataset.flat_map(lambda x: x[rlds.STEPS])\n",
        "\n",
        "# 3. 窗口化变换 - N步转移\n",
        "def make_n_step_transitions(episode, n=5):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    windowed = steps.window(n, shift=1, drop_remainder=True)\n",
        "    return windowed.flat_map(lambda w: w.batch(n))\n",
        "\n",
        "# 4. 过滤变换\n",
        "def filter_successful_episodes(episode):\n",
        "    return episode['metadata']['success'] == True\n",
        "\n",
        "dataset = dataset.filter(filter_successful_episodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 高性能批处理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 自动批处理 - 考虑episode边界\n",
        "def smart_batch(dataset, batch_size, respect_episode_boundaries=True):\n",
        "    if respect_episode_boundaries:\n",
        "        # 确保batch内的step来自同一episode\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS].batch(batch_size)\n",
        "        )\n",
        "    else:\n",
        "        # 跨episode批处理\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS]\n",
        "        ).batch(batch_size)\n",
        "\n",
        "# 示例用法\n",
        "batched_steps = smart_batch(dataset, batch_size=32, \n",
        "                           respect_episode_boundaries=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## "Performance Optimization"最佳实践\n",
        "\n",
        "### 1. 内存优化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 减少内存使用的ReadConfig\n",
        "read_config = tfds.ReadConfig(\n",
        "    # 减少并行加载的文件数\n",
        "    interleave_cycle_length=4,\n",
        "    interleave_block_length=1,\n",
        "    # 启用确定性读取\n",
        "    shuffle_seed=42,\n",
        "    shuffle_reshuffle_each_iteration=True\n",
        ")\n",
        "\n",
        "dataset = tfds.load('dataset_name', read_config=read_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. 并行处理优化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 多进程数据加载\n",
        "def optimized_pipeline(dataset_name, num_parallel_calls=tf.data.AUTOTUNE):\n",
        "    dataset = tfds.load(dataset_name, shuffle_files=True)\n",
        "    \n",
        "    # 并行解码和预处理\n",
        "    dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        num_parallel_calls=num_parallel_calls\n",
        "    )\n",
        "    \n",
        "    # 预取优化\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. 随机化策略\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方式1: 完美随机化 (高内存)\n",
        "shuffled = dataset.shuffle(buffer_size=10000)  # 需要大缓冲区\n",
        "\n",
        "# 方式2: 交错随机化 (内存友好)\n",
        "def create_interleaved_dataset(dataset_name, num_copies=4):\n",
        "    def dataset_loader():\n",
        "        ds = tfds.load(dataset_name, shuffle_files=True)\n",
        "        return ds.flat_map(lambda x: x[rlds.STEPS])\n",
        "    \n",
        "    # 创建多个独立随机化的数据集副本\n",
        "    dataset = tf.data.Dataset.range(num_copies).interleave(\n",
        "        lambda _: dataset_loader(),\n",
        "        cycle_length=num_copies,\n",
        "        block_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "# 方式3: 分片随机化 (避免重复)\n",
        "def distributed_random_access(dataset_name, num_workers, worker_id):\n",
        "    # 每个worker处理不同的分片\n",
        "    split_name = f'train[{worker_id}shard{num_workers}]'\n",
        "    return tfds.load(dataset_name, split=split_name, shuffle_files=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 多智能体支持\n",
        "\n",
        "RLDS原生支持多智能体场景：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 多智能体Episode结构\n",
        "multi_agent_episode = {\n",
        "    'episode_id': 'multi_agent_001',\n",
        "    'agent_id': tf.constant([\n",
        "        ['player_1', 'dqn_agent_v1'],\n",
        "        ['player_2', 'human_expert'],\n",
        "        ['env_bot', 'scripted_agent']\n",
        "    ]),\n",
        "    'steps': [\n",
        "        {\n",
        "            'observation': {\n",
        "                'player_1': player1_obs,\n",
        "                'player_2': player2_obs,\n",
        "                'global': global_obs\n",
        "            },\n",
        "            'action': {\n",
        "                'player_1': player1_action,\n",
        "                'player_2': player2_action\n",
        "            },\n",
        "            'reward': {\n",
        "                'player_1': player1_reward,\n",
        "                'player_2': player2_reward\n",
        "            },\n",
        "            'is_first': True,\n",
        "            'is_last': False,\n",
        "            'is_terminal': False\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 可用数据集生态\n",
        "\n",
        "### 官方支持的数据集\n",
        "\n",
        "| 数据集系列 | 领域 | 任务数量 | 描述 |\n",
        "|------------|------|----------|------|\n",
        "| **D4RL** | 机器人/游戏 | 34+ | Mujoco, Adroit, AntMaze任务 |\n",
        "| **RL Unplugged** | 多领域 | 50+ | DMLab, Atari, 真实世界RL |\n",
        "| **Robosuite** | 机器人操作 | 3 | 用RLDS工具生成 |\n",
        "| **Robomimic** | 机器人学习 | 15+ | 模仿学习数据集 |\n",
        "| **MuJoCo Locomotion** | 运动控制 | 8 | SAC智能体生成 |\n",
        "| **MT-Opt** | 机器人 | 1 | 大规模多任务数据集 |\n",
        "\n",
        "### 数据集使用示例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载不同类型的数据集\n",
        "datasets = {\n",
        "    # 连续控制\n",
        "    'mujoco': tfds.load('d4rl_mujoco_hopper/v1-medium'),\n",
        "    \n",
        "    # 离散控制  \n",
        "    'atari': tfds.load('rl_unplugged_atari_breakout/run_1'),\n",
        "    \n",
        "    # 机器人操作\n",
        "    'robot': tfds.load('robosuite_lift/human_demos'),\n",
        "    \n",
        "    # 导航任务\n",
        "    'maze': tfds.load('d4rl_antmaze/umaze-v1')\n",
        "}\n",
        "\n",
        "# 统一处理接口\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"\\n{name.upper()} Dataset:\")\n",
        "    for episode in dataset['train'].take(1):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        print(f\"  Episode length: {tf.data.experimental.cardinality(steps)}\")\n",
        "        \n",
        "        for step in steps.take(1):\n",
        "            obs_keys = list(step['observation'].keys())\n",
        "            action_shape = step['action'].shape\n",
        "            print(f\"  Observation keys: {obs_keys}\")\n",
        "            print(f\"  Action shape: {action_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 社区贡献和扩展\n",
        "\n",
        "### 添加自定义数据集到TFDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class MyRLDataset(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"自定义RLDS兼容数据集\"\"\"\n",
        "    \n",
        "    VERSION = tfds.core.Version('1.0.0')\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"My custom RL dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        'image': tfds.features.Image(shape=(84, 84, 3)),\n",
        "                        'state': tfds.features.Tensor(shape=(10,), dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,\n",
        "            homepage='https://my-dataset-homepage.com',\n",
        "            citation=\"\"\"@article{my2023dataset, ...}\"\"\",\n",
        "        )\n",
        "    \n",
        "    def _split_generators(self, dl_manager):\n",
        "        return [\n",
        "            tfds.core.SplitGenerator(\n",
        "                name=tfds.Split.TRAIN,\n",
        "                gen_kwargs={'data_path': '/path/to/train/data'},\n",
        "            ),\n",
        "        ]\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        # 实现数据生成逻辑\n",
        "        for episode_file in episode_files:\n",
        "            episode_id, steps = load_episode(episode_file)\n",
        "            yield episode_id, {\n",
        "                'episode_id': episode_id,\n",
        "                'steps': steps\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 实际应用案例\n",
        "\n",
        "### 案例1: 离线强化学习\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def offline_rl_pipeline(dataset_name, algorithm='cql'):\n",
        "    # 加载数据集\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # 数据预处理\n",
        "    def preprocess_for_offline_rl(episode):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # 计算return-to-go\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        returns = compute_returns_to_go(rewards)\n",
        "        \n",
        "        # 添加return信息\n",
        "        enriched_steps = tf.data.Dataset.zip((steps, returns))\n",
        "        return enriched_steps.map(lambda step, ret: {\n",
        "            **step, 'return_to_go': ret\n",
        "        })\n",
        "    \n",
        "    processed_dataset = dataset.map(preprocess_for_offline_rl)\n",
        "    \n",
        "    # 转换为step级数据用于训练\n",
        "    step_dataset = processed_dataset.flat_map(lambda x: x)\n",
        "    \n",
        "    return step_dataset.batch(256).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 案例2: 模仿学习\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imitation_learning_pipeline(expert_dataset, student_dataset):\n",
        "    # 加载专家数据\n",
        "    expert_ds = tfds.load(expert_dataset)['train']\n",
        "    expert_steps = expert_ds.flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # 过滤成功的轨迹\n",
        "    def is_successful_episode(episode):\n",
        "        return episode.get('metadata', {}).get('success', True)\n",
        "    \n",
        "    expert_steps = expert_ds.filter(is_successful_episode)\\\n",
        "                           .flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # 创建(observation, action)对\n",
        "    bc_data = expert_steps.map(lambda step: {\n",
        "        'observation': step['observation'],\n",
        "        'action': step['action']\n",
        "    }).filter(lambda x: not x.get('is_last', False))\n",
        "    \n",
        "    return bc_data.batch(128).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 案例3: 数据集分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset(dataset_name):\n",
        "    \"\"\"全面分析RLDS数据集\"\"\"\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # Episode级统计\n",
        "    episode_lengths = []\n",
        "    success_rates = []\n",
        "    \n",
        "    # Step级统计  \n",
        "    action_stats = []\n",
        "    reward_stats = []\n",
        "    \n",
        "    for episode in dataset:\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # Episode分析\n",
        "        episode_length = tf.data.experimental.cardinality(steps).numpy()\n",
        "        episode_lengths.append(episode_length)\n",
        "        \n",
        "        success = episode.get('metadata', {}).get('success', None)\n",
        "        if success is not None:\n",
        "            success_rates.append(success.numpy())\n",
        "        \n",
        "        # Step分析\n",
        "        for step in steps:\n",
        "            if not step['is_last']:\n",
        "                action_stats.append(step['action'].numpy())\n",
        "                reward_stats.append(step['reward'].numpy())\n",
        "    \n",
        "    # 生成报告\n",
        "    analysis_report = {\n",
        "        'episode_count': len(episode_lengths),\n",
        "        'avg_episode_length': np.mean(episode_lengths),\n",
        "        'std_episode_length': np.std(episode_lengths),\n",
        "        'success_rate': np.mean(success_rates) if success_rates else None,\n",
        "        'total_steps': sum(episode_lengths),\n",
        "        'action_dimensionality': action_stats[0].shape if action_stats else None,\n",
        "        'reward_range': (np.min(reward_stats), np.max(reward_stats)) if reward_stats else None,\n",
        "    }\n",
        "    \n",
        "    return analysis_report \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "octo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
