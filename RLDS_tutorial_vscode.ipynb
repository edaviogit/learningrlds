{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) è¯¦è§£\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ªäº¤äº’å¼çš„RLDSæ•™ç¨‹ï¼ŒåŒ…å«äº†å®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œè§£é‡Šã€‚\n",
        "\n",
        "**ç›®æ ‡:**\n",
        "- ç†è§£RLDSçš„æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ„\n",
        "- å­¦ä¹ å¦‚ä½•ä½¿ç”¨RLDSå¤„ç†å¼ºåŒ–å­¦ä¹ æ•°æ®\n",
        "- æŒæ¡æ•°æ®é›†æ„å»ºå’Œå¤„ç†çš„æœ€ä½³å®è·µ\n",
        "\n",
        "**å‰ç½®è¦æ±‚:**\n",
        "- Python 3.7+\n",
        "- TensorFlow 2.x\n",
        "- TensorFlow Datasets\n",
        "- RLDSåº“ (å¯é€‰)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ VSCode ç”¨æˆ·è®¾ç½®æŒ‡å—\n",
        "\n",
        "æœ¬æ•™ç¨‹åŒ…å«å¤šä¸ª Mermaid æ¶æ„å›¾ã€‚å¦‚æœæ‚¨ä½¿ç”¨ VSCodeï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è®¾ç½®ï¼š\n",
        "\n",
        "### 1. å®‰è£… Mermaid é¢„è§ˆæ‰©å±•\n",
        "```\n",
        "1. æŒ‰ Ctrl+Shift+X æ‰“å¼€æ‰©å±•é¢æ¿\n",
        "2. æœç´¢ \"Mermaid Preview\"\n",
        "3. å®‰è£… \"Mermaid Preview\" (bierner.markdown-mermaid)\n",
        "4. é‡å¯ VSCode\n",
        "```\n",
        "\n",
        "### 2. é…ç½® VSCode è®¾ç½® (å¯é€‰)\n",
        "åœ¨ `settings.json` ä¸­æ·»åŠ ï¼š\n",
        "```json\n",
        "{\n",
        "    \"markdown.mermaid.theme\": \"default\",\n",
        "    \"markdown.preview.breaks\": true\n",
        "}\n",
        "```\n",
        "\n",
        "### 3. æŸ¥çœ‹å›¾è¡¨\n",
        "- **æ–¹æ³•1**: å®‰è£…æ‰©å±•åç›´æ¥åœ¨ notebook ä¸­æŸ¥çœ‹\n",
        "- **æ–¹æ³•2**: å¤åˆ¶ mermaid ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "- **æ–¹æ³•3**: æŸ¥çœ‹æ¯ä¸ªå›¾è¡¨ä¸‹æ–¹çš„æ–‡å­—ç‰ˆè¯´æ˜\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplot\n",
        "!pip install tensorflow \n",
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS (Reinforcement Learning Datasets) Tutorial\n",
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from typing import Dict, Any, List, Optional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python executable: /Users/edavio/anaconda3/envs/octo_clean/bin/python\n",
            "Python path: ['/Users/edavio/anaconda3/envs/octo_clean/lib/python310.zip', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/lib-dynload', '', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages/rlds-0.1.8-py3.10.egg']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "print(\"Python path:\", sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export https_proxy=http://127.0.0.1:7890\n",
        "!export http_proxy=http://127.0.0.1:7890\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (reverb.py, line 64)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/octo_clean/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
            "\u001b[0m  Cell \u001b[1;32mIn[4], line 1\u001b[0m\n    import rlds\u001b[0m\n",
            "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/octo_clean/lib/python3.10/site-packages/rlds/__init__.py:22\u001b[0m\n    from rlds import transformations\u001b[0m\n",
            "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/octo_clean/lib/python3.10/site-packages/rlds/transformations/__init__.py:41\u001b[0m\n    from rlds.transformations.pattern import pattern_map\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/octo_clean/lib/python3.10/site-packages/rlds/transformations/pattern.py:20\u001b[0;36m\n\u001b[0;31m    import reverb\u001b[0;36m\n",
            "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/octo_clean/lib/python3.10/site-packages/reverb.py:64\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise TypeError, 'Regexp cannot be negated'\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import rlds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RLDS modules not available. Install with: pip install rlds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Try to import RLDS specific modules\n",
        "try:\n",
        "    import rlds\n",
        "    import envlogger\n",
        "    print(\"RLDS modules imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"RLDS modules not available. Install with: pip install rlds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Configure TensorFlow\n",
        "tf.config.experimental.set_memory_growth(\n",
        "    tf.config.experimental.list_physical_devices('GPU')[0], True\n",
        ") if tf.config.experimental.list_physical_devices('GPU') else None\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) è¯¦è§£\n",
        "\n",
        "## æ¦‚è¿°\n",
        "\n",
        "RLDS (Reinforcement Learning Datasets) æ˜¯Google DeepMindå¼€å‘çš„ç”¨äºå¼ºåŒ–å­¦ä¹ çš„æ ‡å‡†åŒ–æ•°æ®é›†æ ¼å¼ã€‚å®ƒåŸºäºTensorFlow Datasets (TFDS) æ„å»ºï¼Œä¸“é—¨è®¾è®¡ç”¨äºå­˜å‚¨å’Œå¤„ç†å¼ºåŒ–å­¦ä¹ è½¨è¿¹æ•°æ®ï¼ŒåŒ…æ‹¬æœºå™¨äººå­¦ä¹ ã€æ¸¸æˆAIç­‰å„ç§åºåˆ—å†³ç­–ä»»åŠ¡ã€‚\n",
        "\n",
        "**RLDSè§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š**\n",
        "- ç¼ºä¹æ ‡å‡†åŒ–çš„å¼ºåŒ–å­¦ä¹ æ•°æ®é›†æ ¼å¼\n",
        "- æ•°æ®é›†æ ¼å¼ä¸å…¼å®¹å¯¼è‡´ç®—æ³•æ— æ³•é‡ç”¨\n",
        "- æ—¶åºä¿¡æ¯ä¸¢å¤±ï¼ˆå¦‚éšæœºåŒ–æ­¥éª¤é¡ºåºï¼‰\n",
        "- æ•°æ®å…±äº«å›°éš¾ä¸”æ˜“å¼•å…¥bug\n",
        "\n",
        "**RLDSçš„æ ¸å¿ƒä»·å€¼ï¼š**\n",
        "- **æ— æŸæ ¼å¼**ï¼šä¿ç•™æ‰€æœ‰ä¿¡æ¯ï¼Œç»´æŒæ—¶åºå…³ç³»\n",
        "- **ç®—æ³•æ— å…³**ï¼šæ”¯æŒä¸åŒç®—æ³•çš„æ•°æ®æ¶ˆè´¹æ¨¡å¼\n",
        "- **æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„æ•°æ®ç»“æ„å’Œè¯­ä¹‰\n",
        "- **ç”Ÿæ€ç³»ç»Ÿ**ï¼šå®Œæ•´çš„æ•°æ®ç”Ÿäº§ã€å…±äº«ã€æ¶ˆè´¹å·¥å…·é“¾\n",
        "\n",
        "## RLDSç”Ÿæ€ç³»ç»Ÿæ¶æ„\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 1\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**è‡ªä¸Šè€Œä¸‹çš„æµç¨‹å›¾**ï¼Œå±•ç¤ºäº†ç»„ä»¶ä¹‹é—´çš„å±‚æ¬¡å…³ç³»å’Œæ•°æ®æµå‘ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TB\n",
        "    subgraph Production[æ•°æ®ç”Ÿäº§]\n",
        "        A[EnvLogger - åˆæˆæ•°æ®] \n",
        "        B[RLDS Creator - äººç±»æ•°æ®]\n",
        "        C[è‡ªå®šä¹‰ç”Ÿäº§å™¨]\n",
        "    end\n",
        "    \n",
        "    subgraph Storage[æ•°æ®å­˜å‚¨]\n",
        "        D[RLDSæ ‡å‡†æ ¼å¼]\n",
        "        E[TFDSé›†æˆ]\n",
        "        F[ç‰ˆæœ¬æ§åˆ¶]\n",
        "    end\n",
        "    \n",
        "    subgraph Processing[æ•°æ®å¤„ç†]\n",
        "        G[å˜æ¢åº“]\n",
        "        H[æ‰¹å¤„ç†ä¼˜åŒ–]\n",
        "        I[æ€§èƒ½ä¼˜åŒ–]\n",
        "    end\n",
        "    \n",
        "    subgraph Consumption[æ•°æ®æ¶ˆè´¹]\n",
        "        J[Episodeçº§ç®—æ³•]\n",
        "        K[Stepçº§ç®—æ³•]\n",
        "        L[åˆ†æå·¥å…·]\n",
        "    end\n",
        "    \n",
        "    Production --> Storage\n",
        "    Storage --> Processing  \n",
        "    Processing --> Consumption\n",
        "    \n",
        "    Storage -.-> M[TFDSå…¨å±€ç›®å½•]\n",
        "    M -.-> N[ç¤¾åŒºå…±äº«]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSæ¶æ„å›¾\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 2\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**è‡ªä¸Šè€Œä¸‹çš„æµç¨‹å›¾**ï¼Œå±•ç¤ºäº†ç»„ä»¶ä¹‹é—´çš„å±‚æ¬¡å…³ç³»å’Œæ•°æ®æµå‘ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[RLDS Dataset] --> B[Episode Collection]\n",
        "    B --> C[Individual Episodes]\n",
        "    C --> D[Steps Sequence]\n",
        "    \n",
        "    D --> E[Observation]\n",
        "    D --> F[Action]\n",
        "    D --> G[Reward]\n",
        "    D --> H[Discount]\n",
        "    D --> I[Metadata]\n",
        "    \n",
        "    E --> E1[Images]\n",
        "    E --> E2[Proprio State]\n",
        "    E --> E3[Task Info]\n",
        "    \n",
        "    F --> F1[Joint Commands]\n",
        "    F --> F2[End-effector Pose]\n",
        "    F --> F3[Gripper Commands]\n",
        "    \n",
        "    subgraph Types[æ•°æ®ç±»å‹]\n",
        "        J[\"tf.string - å‹ç¼©å›¾åƒ\"]\n",
        "        K[\"tf.float32 - è¿ç»­å€¼\"]\n",
        "        L[\"tf.int32 - ç¦»æ•£å€¼\"]\n",
        "        M[\"tf.bool - å¸ƒå°”å€¼\"]\n",
        "    end\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSæ•°æ®ç»“æ„å±‚æ¬¡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 3\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**æµç¨‹å›¾**ï¼Œæè¿°äº†å¤„ç†æ­¥éª¤å’Œå†³ç­–æµç¨‹ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Dataset] --> B[Episodes]\n",
        "    B --> C[Steps]\n",
        "    C --> D[Fields]\n",
        "    \n",
        "    subgraph Episode[Episodeçº§åˆ«]\n",
        "        E1[episode_id]\n",
        "        E2[episode_metadata]\n",
        "        E3[stepsé›†åˆ]\n",
        "    end\n",
        "    \n",
        "    subgraph Step[Stepçº§åˆ«]\n",
        "        S1[observation]\n",
        "        S2[action]\n",
        "        S3[reward]\n",
        "        S4[discount]\n",
        "        S5[is_first]\n",
        "        S6[is_last]\n",
        "        S7[is_terminal]\n",
        "    end\n",
        "    \n",
        "    B -.-> Episode\n",
        "    C -.-> Step\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## æ ¸å¿ƒæ•°æ®ç»“æ„\n",
        "\n",
        "### Episode ç»“æ„\n",
        "| å­—æ®µå | ç±»å‹ | æè¿° | ç¤ºä¾‹ |\n",
        "|--------|------|------|------|\n",
        "| `episode_id` | `tf.string` | å”¯ä¸€æ ‡è¯†ç¬¦ | `\"episode_001\"` |\n",
        "| `episode_metadata` | `dict` | å…ƒæ•°æ®ä¿¡æ¯ | `{\"task\": \"pick_cup\", \"success\": True}` |\n",
        "| `steps` | `Sequence[Step]` | æ­¥éª¤åºåˆ— | `[step_0, step_1, ..., step_n]` |\n",
        "\n",
        "### Step ç»“æ„\n",
        "| å­—æ®µå | ç±»å‹ | å½¢çŠ¶ | æè¿° |\n",
        "|--------|------|------|------|\n",
        "| `observation` | `dict` | å¯å˜ | è§‚æµ‹æ•°æ®å­—å…¸ |\n",
        "| `action` | `tf.float32` | `[action_dim]` | åŠ¨ä½œå‘é‡ |\n",
        "| `reward` | `tf.float32` | `[]` | å¥–åŠ±å€¼ |\n",
        "| `discount` | `tf.float32` | `[]` | æŠ˜æ‰£å› å­ |\n",
        "| `is_first` | `tf.bool` | `[]` | æ˜¯å¦ä¸ºé¦–æ­¥ |\n",
        "| `is_last` | `tf.bool` | `[]` | æ˜¯å¦ä¸ºæœ«æ­¥ |\n",
        "| `is_terminal` | `tf.bool` | `[]` | æ˜¯å¦ç»ˆæ­¢ |\n",
        "\n",
        "### Observation ç»“æ„ç¤ºä¾‹\n",
        "| è§‚æµ‹ç±»å‹ | å­—æ®µå | ç±»å‹ | å½¢çŠ¶ | æè¿° |\n",
        "|----------|--------|------|------|------|\n",
        "| å›¾åƒ | `image_primary` | `tf.string` | `[]` | ä¸»æ‘„åƒå¤´å›¾åƒ(JPEGç¼–ç ) |\n",
        "| å›¾åƒ | `image_wrist` | `tf.string` | `[]` | æ‰‹è…•æ‘„åƒå¤´å›¾åƒ |\n",
        "| å›¾åƒ | `image_side` | `tf.string` | `[]` | ä¾§è§†å›¾åƒ |\n",
        "| æ·±åº¦ | `depth_primary` | `tf.string` | `[]` | æ·±åº¦å›¾åƒ |\n",
        "| çŠ¶æ€ | `joint_positions` | `tf.float32` | `[7]` | å…³èŠ‚ä½ç½® |\n",
        "| çŠ¶æ€ | `joint_velocities` | `tf.float32` | `[7]` | å…³èŠ‚é€Ÿåº¦ |\n",
        "| çŠ¶æ€ | `end_effector_pose` | `tf.float32` | `[7]` | æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿ |\n",
        "| çŠ¶æ€ | `gripper_state` | `tf.float32` | `[1]` | å¤¹çˆªçŠ¶æ€ |\n",
        "| ä»»åŠ¡ | `task_description` | `tf.string` | `[]` | ä»»åŠ¡æè¿° |\n",
        "| ä»»åŠ¡ | `goal_image` | `tf.string` | `[]` | ç›®æ ‡å›¾åƒ |\n",
        "\n",
        "## ç¤ºä¾‹æ•°æ®é›†æ„å»º\n",
        "\n",
        "### æ•°æ®é›†é…ç½®ä¿¡æ¯\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 4\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**ç±»å…³ç³»å›¾**ï¼Œæ˜¾ç¤ºäº†ä¸åŒç±»ä¹‹é—´çš„ç»§æ‰¿å’Œå…³è”å…³ç³»ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "classDiagram\n",
        "    class DatasetConfig {\n",
        "        +string name\n",
        "        +string version\n",
        "        +string description\n",
        "        +dict features\n",
        "        +dict splits\n",
        "        +int total_episodes\n",
        "        +int total_steps\n",
        "    }\n",
        "    \n",
        "    class FeatureConfig {\n",
        "        +dict observation_space\n",
        "        +dict action_space\n",
        "        +float reward_range\n",
        "        +string task_type\n",
        "    }\n",
        "    \n",
        "    class SplitConfig {\n",
        "        +float train_ratio\n",
        "        +float val_ratio\n",
        "        +float test_ratio\n",
        "        +int train_episodes\n",
        "        +int val_episodes\n",
        "        +int test_episodes\n",
        "    }\n",
        "    \n",
        "    DatasetConfig --> FeatureConfig : contains\n",
        "    DatasetConfig --> SplitConfig : contains\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ç¤ºä¾‹ï¼šæŠ“å–ä»»åŠ¡æ•°æ®é›†\n",
        "\n",
        "#### æ•°æ®é›†å…ƒä¿¡æ¯\n",
        "| å±æ€§ | å€¼ |\n",
        "|------|-----|\n",
        "| æ•°æ®é›†åç§° | `robot_pick_place_v1` |\n",
        "| ç‰ˆæœ¬ | `1.0.0` |\n",
        "| ä»»åŠ¡ç±»å‹ | `Pick and Place` |\n",
        "| æœºå™¨äººå¹³å° | `Franka Panda` |\n",
        "| æ€»episodeæ•° | `10,000` |\n",
        "| æ€»æ­¥æ•° | `500,000` |\n",
        "| å¹³å‡episodeé•¿åº¦ | `50 steps` |\n",
        "\n",
        "#### Episodeç¤ºä¾‹æ•°æ®\n",
        "\n",
        "**Episode 1 å…ƒæ•°æ®**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\n",
        "{\n",
        "    \"episode_id\": \"episode_0001\",\n",
        "    \"task_type\": \"pick_red_cube\",\n",
        "    \"success\": true,\n",
        "    \"duration_seconds\": 12.5,\n",
        "    \"robot_id\": \"franka_001\",\n",
        "    \"scene_id\": \"kitchen_table_01\",\n",
        "    \"difficulty\": \"easy\",\n",
        "    \"annotations\": {\n",
        "        \"pick_frame\": 15,\n",
        "        \"place_frame\": 42,\n",
        "        \"contact_frames\": [16, 43]\n",
        "    }\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Stepæ•°æ®ç»“æ„è¯¦è§£\n",
        "\n",
        "**Step 0 (åˆå§‹çŠ¶æ€)**\n",
        "| å­—æ®µ | å€¼ | è¯´æ˜ |\n",
        "|------|-----|------|\n",
        "| `is_first` | `True` | è½¨è¿¹å¼€å§‹ |\n",
        "| `is_last` | `False` | éç»“æŸæ­¥ |\n",
        "| `is_terminal` | `False` | éç»ˆæ­¢æ­¥ |\n",
        "| `reward` | `0.0` | åˆå§‹å¥–åŠ± |\n",
        "| `discount` | `1.0` | æ ‡å‡†æŠ˜æ‰£ |\n",
        "\n",
        "**è§‚æµ‹æ•°æ® (Step 0)**\n",
        "| è§‚æµ‹é¡¹ | æ•°æ®ç±»å‹ | å½¢çŠ¶ | ç¤ºä¾‹å€¼/æè¿° |\n",
        "|--------|----------|------|-------------|\n",
        "| `image_primary` | `tf.string` | `[]` | JPEGç¼–ç çš„RGBå›¾åƒ (480Ã—640Ã—3) |\n",
        "| `image_wrist` | `tf.string` | `[]` | JPEGç¼–ç çš„æ‰‹è…•ç›¸æœºå›¾åƒ (240Ã—320Ã—3) |\n",
        "| `depth_primary` | `tf.string` | `[]` | å‹ç¼©çš„æ·±åº¦å›¾ (480Ã—640Ã—1) |\n",
        "| `joint_positions` | `tf.float32` | `[7]` | `[0.0, -0.785, 0.0, -2.356, 0.0, 1.571, 0.785]` |\n",
        "| `joint_velocities` | `tf.float32` | `[7]` | `[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]` |\n",
        "| `end_effector_pose` | `tf.float32` | `[7]` | `[0.5, 0.0, 0.3, 0.0, 0.0, 0.0, 1.0]` (ä½ç½®+å››å…ƒæ•°) |\n",
        "| `gripper_state` | `tf.float32` | `[1]` | `[0.08]` (å¼€å¯çŠ¶æ€) |\n",
        "| `task_description` | `tf.string` | `[]` | `\"Pick up the red cube and place it in the box\"` |\n",
        "\n",
        "**åŠ¨ä½œæ•°æ® (Step 0â†’1)**\n",
        "| åŠ¨ä½œç»´åº¦ | å€¼ | è¯´æ˜ |\n",
        "|----------|-----|------|\n",
        "| `delta_pos_x` | `0.02` | Xè½´ä½ç§» (m) |\n",
        "| `delta_pos_y` | `0.01` | Yè½´ä½ç§» (m) |\n",
        "| `delta_pos_z` | `-0.005` | Zè½´ä½ç§» (m) |\n",
        "| `delta_rot_x` | `0.0` | Xè½´æ—‹è½¬ (rad) |\n",
        "| `delta_rot_y` | `0.0` | Yè½´æ—‹è½¬ (rad) |\n",
        "| `delta_rot_z` | `0.1` | Zè½´æ—‹è½¬ (rad) |\n",
        "| `gripper_cmd` | `0.0` | å¤¹çˆªå‘½ä»¤ (ä¿æŒå¼€å¯) |\n",
        "\n",
        "## æ•°æ®å¤„ç†æµæ°´çº¿\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 5\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**æµç¨‹å›¾**ï¼Œæè¿°äº†å¤„ç†æ­¥éª¤å’Œå†³ç­–æµç¨‹ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart TD\n",
        "    A[åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®] --> B[æ•°æ®é‡‡é›†]\n",
        "    B --> C[æ•°æ®é¢„å¤„ç†]\n",
        "    C --> D[RLDSæ ¼å¼è½¬æ¢]\n",
        "    D --> E[è´¨é‡æ£€æŸ¥]\n",
        "    E --> F[æ•°æ®é›†æ„å»º]\n",
        "    \n",
        "    subgraph Preprocess[æ•°æ®é¢„å¤„ç†]\n",
        "        C1[å›¾åƒå‹ç¼©]\n",
        "        C2[åæ ‡ç³»å¯¹é½]\n",
        "        C3[æ—¶é—´æˆ³åŒæ­¥]\n",
        "        C4[å¼‚å¸¸å€¼è¿‡æ»¤]\n",
        "    end\n",
        "    \n",
        "    subgraph Quality[è´¨é‡æ£€æŸ¥]\n",
        "        E1[è½¨è¿¹å®Œæ•´æ€§]\n",
        "        E2[æ•°æ®ä¸€è‡´æ€§]\n",
        "        E3[æˆåŠŸç‡ç»Ÿè®¡]\n",
        "        E4[å¼‚å¸¸æ£€æµ‹]\n",
        "    end\n",
        "    \n",
        "    C -.-> Preprocess\n",
        "    E -.-> Quality\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## æ•°æ®åŠ è½½ç¤ºä¾‹\n",
        "\n",
        "### Pythonä»£ç ç¤ºä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# åŠ è½½æ•°æ®é›†\n",
        "ds_builder = tfds.builder('robot_pick_place_v1', data_dir='/path/to/data')\n",
        "ds = ds_builder.as_dataset(split='train', shuffle_files=True)\n",
        "\n",
        "# æ£€æŸ¥æ•°æ®ç»“æ„\n",
        "print(\"Dataset info:\")\n",
        "print(ds_builder.info)\n",
        "\n",
        "# éå†episodes\n",
        "for episode in ds.take(1):\n",
        "    print(f\"Episode ID: {episode['episode_id']}\")\n",
        "    print(f\"Episode steps: {len(episode['steps'])}\")\n",
        "    \n",
        "    # æŸ¥çœ‹ç¬¬ä¸€æ­¥\n",
        "    first_step = episode['steps'][0]\n",
        "    print(f\"First step observation keys: {first_step['observation'].keys()}\")\n",
        "    print(f\"Action shape: {first_step['action'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### æ•°æ®ç»Ÿè®¡ä¿¡æ¯\n",
        "\n",
        "#### æ•°æ®é›†åˆ†å‰²\n",
        "| åˆ†å‰² | Episodeæ•° | æ­¥æ•° | æˆåŠŸç‡ | å¹³å‡é•¿åº¦ |\n",
        "|------|-----------|------|--------|----------|\n",
        "| Train | 8,000 | 400,000 | 85% | 50 steps |\n",
        "| Validation | 1,000 | 50,000 | 83% | 50 steps |\n",
        "| Test | 1,000 | 50,000 | 82% | 50 steps |\n",
        "\n",
        "#### åŠ¨ä½œç»Ÿè®¡\n",
        "| åŠ¨ä½œç»´åº¦ | æœ€å°å€¼ | æœ€å¤§å€¼ | å‡å€¼ | æ ‡å‡†å·® |\n",
        "|----------|--------|--------|------|--------|\n",
        "| `delta_pos_x` | -0.05 | 0.05 | 0.001 | 0.012 |\n",
        "| `delta_pos_y` | -0.05 | 0.05 | -0.002 | 0.015 |\n",
        "| `delta_pos_z` | -0.05 | 0.05 | 0.000 | 0.008 |\n",
        "| `delta_rot_x` | -0.2 | 0.2 | 0.003 | 0.045 |\n",
        "| `delta_rot_y` | -0.2 | 0.2 | -0.001 | 0.038 |\n",
        "| `delta_rot_z` | -0.2 | 0.2 | 0.005 | 0.052 |\n",
        "| `gripper_cmd` | -1.0 | 1.0 | 0.12 | 0.68 |\n",
        "\n",
        "## ä¸å…¶ä»–æ ¼å¼å¯¹æ¯”\n",
        "\n",
        "### æ•°æ®æ ¼å¼å¯¹æ¯”è¡¨\n",
        "| ç‰¹æ€§ | RLDS | HDF5 | ROS Bag | OpenAI Gym |\n",
        "|------|------|------|---------|------------|\n",
        "| æ ‡å‡†åŒ–ç¨‹åº¦ | é«˜ | ä¸­ | ä½ | ä¸­ |\n",
        "| å…ƒæ•°æ®æ”¯æŒ | ä¼˜ç§€ | è‰¯å¥½ | ä¼˜ç§€ | åŸºç¡€ |\n",
        "| å‹ç¼©æ•ˆç‡ | é«˜ | é«˜ | ä¸­ | ä½ |\n",
        "| æŸ¥è¯¢æ€§èƒ½ | ä¼˜ç§€ | è‰¯å¥½ | å·® | è‰¯å¥½ |\n",
        "| ç”Ÿæ€ç³»ç»Ÿ | TF/JAX | é€šç”¨ | ROS | RLç¤¾åŒº |\n",
        "| ç‰ˆæœ¬æ§åˆ¶ | æ”¯æŒ | æœ‰é™ | æ—  | æ—  |\n",
        "| åˆ†å¸ƒå¼è®­ç»ƒ | åŸç”Ÿæ”¯æŒ | éœ€è¦é¢å¤–å·¥å…· | å¤æ‚ | å¤æ‚ |\n",
        "\n",
        "## æœ€ä½³å®è·µ\n",
        "\n",
        "### æ•°æ®ç»„ç»‡å»ºè®®\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š æ¶æ„å›¾ 6\n",
        "\n",
        "> **VSCode ç”¨æˆ·æ³¨æ„**: è¦æŸ¥çœ‹ä¸‹æ–¹çš„ Mermaid å›¾è¡¨ï¼Œè¯·ï¼š\n",
        "> \n",
        "> 1. **æ¨è**: å®‰è£… VSCode æ‰©å±• `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **ä¸´æ—¶æ–¹æ¡ˆ**: å¤åˆ¶ä¸‹æ–¹ä»£ç åˆ° https://mermaid.live/ åœ¨çº¿æŸ¥çœ‹\n",
        "> 3. **æ›¿ä»£æ–¹æ¡ˆ**: æŸ¥çœ‹æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "#### ğŸ“ æ–‡å­—ç‰ˆæ¶æ„è¯´æ˜\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**è‡ªä¸Šè€Œä¸‹çš„æµç¨‹å›¾**ï¼Œå±•ç¤ºäº†ç»„ä»¶ä¹‹é—´çš„å±‚æ¬¡å…³ç³»å’Œæ•°æ®æµå‘ã€‚\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[æ•°æ®é›†æ ¹ç›®å½•] --> B[æ•°æ®æ–‡ä»¶]\n",
        "    A --> C[å…ƒæ•°æ®]\n",
        "    A --> D[é…ç½®æ–‡ä»¶]\n",
        "    A --> E[æ–‡æ¡£]\n",
        "    \n",
        "    B --> B1[\"train/\"]\n",
        "    B --> B2[\"validation/\"]\n",
        "    B --> B3[\"test/\"]\n",
        "    \n",
        "    C --> C1[\"dataset_info.json\"]\n",
        "    C --> C2[\"statistics.json\"]\n",
        "    C --> C3[\"features.json\"]\n",
        "    \n",
        "    D --> D1[\"builder_config.py\"]\n",
        "    D --> D2[\"preprocessing.py\"]\n",
        "    \n",
        "    E --> E1[\"README.md\"]\n",
        "    E --> E2[\"LICENSE\"]\n",
        "    E --> E3[\"CHANGELOG.md\"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### æ•°æ®è´¨é‡æ£€æŸ¥æ¸…å•\n",
        "| æ£€æŸ¥é¡¹ | é‡è¦æ€§ | æè¿° |\n",
        "|--------|--------|------|\n",
        "| è½¨è¿¹å®Œæ•´æ€§ | é«˜ | ç¡®ä¿æ¯ä¸ªepisodeéƒ½æœ‰å®Œæ•´çš„å¼€å§‹å’Œç»“æŸ |\n",
        "| æ—¶é—´ä¸€è‡´æ€§ | é«˜ | æ£€æŸ¥æ—¶é—´æˆ³çš„å•è°ƒæ€§å’Œåˆç†æ€§ |\n",
        "| åŠ¨ä½œåˆç†æ€§ | é«˜ | éªŒè¯åŠ¨ä½œåœ¨ç‰©ç†çº¦æŸèŒƒå›´å†… |\n",
        "| å›¾åƒè´¨é‡ | ä¸­ | æ£€æŸ¥å›¾åƒæ˜¯å¦æ¸…æ™°ã€æ— æŸå |\n",
        "| æ ‡æ³¨å‡†ç¡®æ€§ | é«˜ | éªŒè¯æˆåŠŸ/å¤±è´¥æ ‡æ³¨çš„å‡†ç¡®æ€§ |\n",
        "| æ•°æ®å¹³è¡¡æ€§ | ä¸­ | ç¡®ä¿ä¸åŒä»»åŠ¡åœºæ™¯çš„å¹³è¡¡åˆ†å¸ƒ |\n",
        "\n",
        "## æ‰©å±•å’Œå®šåˆ¶\n",
        "\n",
        "### è‡ªå®šä¹‰è§‚æµ‹ç©ºé—´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ·»åŠ è‡ªå®šä¹‰è§‚æµ‹\n",
        "custom_observation_spec = {\n",
        "    'image_overhead': tfds.features.Image(shape=(480, 640, 3)),\n",
        "    'force_torque': tfds.features.Tensor(shape=(6,), dtype=tf.float32),\n",
        "    'tactile_sensor': tfds.features.Tensor(shape=(16,), dtype=tf.float32),\n",
        "    'audio_data': tfds.features.Audio(sample_rate=16000),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ä»»åŠ¡ç‰¹å®šå­—æ®µ\n",
        "| ä»»åŠ¡ç±»å‹ | ç‰¹å®šå­—æ®µ | ç±»å‹ | æè¿° |\n",
        "|----------|----------|------|------|\n",
        "| æŠ“å–ä»»åŠ¡ | `grasp_success` | `tf.bool` | æŠ“å–æ˜¯å¦æˆåŠŸ |\n",
        "| å¯¼èˆªä»»åŠ¡ | `collision_detected` | `tf.bool` | æ˜¯å¦å‘ç”Ÿç¢°æ’ |\n",
        "| æ“ä½œä»»åŠ¡ | `contact_forces` | `tf.float32[6]` | æ¥è§¦åŠ›ä¿¡æ¯ |\n",
        "| å­¦ä¹ ä»»åŠ¡ | `demonstration_id` | `tf.string` | ç¤ºæ•™ID |\n",
        "\n",
        "## RLDSæ ¸å¿ƒç»„ä»¶è¯¦è§£\n",
        "\n",
        "### 1. EnvLogger - åˆæˆæ•°æ®æ”¶é›†\n",
        "\n",
        "EnvLoggeræ˜¯dm_envç¯å¢ƒåŒ…è£…å™¨ï¼Œç”¨äºè®°å½•æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import envlogger\n",
        "\n",
        "# åŸºæœ¬ç”¨æ³•\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset'\n",
        ")\n",
        "\n",
        "# é«˜çº§ç”¨æ³• - æ·»åŠ å…ƒæ•°æ®å›è°ƒ\n",
        "def step_metadata_fn(timestep, action, env):\n",
        "    return {\n",
        "        'custom_reward': compute_custom_reward(timestep),\n",
        "        'difficulty': env.get_difficulty()\n",
        "    }\n",
        "\n",
        "def episode_metadata_fn(env):\n",
        "    return {\n",
        "        'success': env.is_success(),\n",
        "        'episode_length': env.step_count()\n",
        "    }\n",
        "\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset',\n",
        "    step_metadata_fn=step_metadata_fn,\n",
        "    episode_metadata_fn=episode_metadata_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**EnvLoggeræ•°æ®æµ**ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ç”Ÿæˆ: (o_0, _, _, _, m_0) â†’ (o_1, a_0, r_0, d_0, m_1) â†’ (o_2, a_1, r_1, d_1, m_2)\n",
        "å­˜å‚¨: (o_0, a_0, r_0, d_0, m_0) â†’ (o_1, a_1, r_1, d_1, m_1) â†’ (o_2, a_2, r_2, d_2, m_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. RLDS Creator - äººç±»æ•°æ®æ”¶é›†\n",
        "\n",
        "åŸºäºWebçš„å·¥å…·ï¼Œå…è®¸äººç±»é€šè¿‡æµè§ˆå™¨ä¸ç¯å¢ƒäº¤äº’ï¼š\n",
        "\n",
        "**ç‰¹æ€§ï¼š**\n",
        "- è·¨å¹³å°Webç•Œé¢\n",
        "- å®æ—¶æ•°æ®è®°å½•\n",
        "- æ”¯æŒå¤šç§è¾“å…¥è®¾å¤‡\n",
        "- ä¼—åŒ…æ•°æ®æ”¶é›†æ”¯æŒ\n",
        "\n",
        "### 3. TFDSé›†æˆ\n",
        "\n",
        "#### æ•°æ®é›†åŠ è½½æ–¹å¼\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# æ–¹å¼1: ä»ç›®å½•åŠ è½½\n",
        "ds = tfds.builder_from_directory('/path/to/dataset').as_dataset(split='all')\n",
        "\n",
        "# æ–¹å¼2: ä»å¤šä¸ªç›®å½•åŠ è½½\n",
        "ds = tfds.builder_from_directories(['/path1', '/path2']).as_dataset(split='all')\n",
        "\n",
        "# æ–¹å¼3: ä»TFDSç›®å½•åŠ è½½\n",
        "ds = tfds.load('d4rl_mujoco_halfcheetah/v0-medium')['train']\n",
        "\n",
        "# æ–¹å¼4: æ‰¹é‡åŠ è½½(éåµŒå¥—æ ¼å¼)\n",
        "ds = tfds.load('dataset_name', \n",
        "               decoders={rlds.STEPS: tfds.decode.SkipDecoding()},\n",
        "               split='train')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSå¯¹TFDSçš„é©å‘½æ€§æ‰©å±•\n",
        "\n",
        "RLDSä¸ä»…æ˜¯TFDSçš„ç®€å•ç”¨æˆ·ï¼Œè€Œæ˜¯å¯¹TFDSè¿›è¡Œäº†æ·±åº¦æ‰©å±•å’Œæ”¹è¿›ï¼Œä¸“é—¨é’ˆå¯¹å¼ºåŒ–å­¦ä¹ æ•°æ®çš„ç‰¹æ®Šéœ€æ±‚ã€‚ä»¥ä¸‹æ˜¯RLDSåœ¨TFDSåŸºç¡€ä¸Šåšå‡ºçš„å…³é”®åˆ›æ–°å’Œæ”¹è¿›ï¼š\n",
        "\n",
        "### 1. åµŒå¥—æ•°æ®é›†ç»“æ„æ”¯æŒ\n",
        "\n",
        "#### ä¼ ç»ŸTFDSçš„å±€é™æ€§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¼ ç»ŸTFDS - æ‰å¹³åŒ–æ•°æ®ç»“æ„\n",
        "traditional_sample = {\n",
        "    'image': tf.Tensor(...),\n",
        "    'label': tf.Tensor(...),\n",
        "    'metadata': tf.Tensor(...)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### RLDSçš„åµŒå¥—æ•°æ®é›†åˆ›æ–°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS - åµŒå¥—æ•°æ®é›†ç»“æ„\n",
        "rlds_episode = {\n",
        "    'episode_id': tf.string,\n",
        "    'episode_metadata': {\n",
        "        'success': tf.bool,\n",
        "        'task_id': tf.string,\n",
        "        'collector_id': tf.string\n",
        "    },\n",
        "    'steps': tf.data.Dataset.from_generator(...)  # åµŒå¥—æ•°æ®é›†ï¼\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š**\n",
        "- **åµŒå¥—tf.data.Dataset**ï¼šRLDSåœ¨TFDSä¸­é¦–æ¬¡å®ç°äº†æ•°æ®é›†å†…åµŒå¥—æ•°æ®é›†çš„æ”¯æŒ\n",
        "- **æ—¶åºæ•°æ®ä¿æŠ¤**ï¼šç¡®ä¿episodeå†…æ­¥éª¤çš„æ—¶åºå…³ç³»ä¸è¢«ç ´å\n",
        "- **åŠ¨æ€é•¿åº¦æ”¯æŒ**ï¼šæ¯ä¸ªepisodeå¯ä»¥æœ‰ä¸åŒçš„æ­¥æ•°\n",
        "\n",
        "### 2. ä¸“ç”¨çš„RLDS BuilderåŸºç±»\n",
        "\n",
        "RLDSæ‰©å±•äº†TFDSçš„Builderæ¶æ„ï¼Œæä¾›äº†ä¸“é—¨çš„åŸºç±»ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import rlds\n",
        "\n",
        "class RoboticDatasetBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"RLDSä¸“ç”¨çš„æ•°æ®é›†æ„å»ºå™¨\"\"\"\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"RLDS compliant robotic dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                # Episodeçº§å…ƒæ•°æ®\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'episode_metadata': tfds.features.FeaturesDict({\n",
        "                    'success': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'task': tfds.features.Text(),\n",
        "                    'total_reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                }),\n",
        "                \n",
        "                # æ ¸å¿ƒåˆ›æ–°ï¼šåµŒå¥—æ•°æ®é›†ç»“æ„\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    # Stepçº§æ•°æ®ç»“æ„\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        # æ”¯æŒå¤šæ¨¡æ€è§‚æµ‹\n",
        "                        'image_primary': tfds.features.Image(shape=(224, 224, 3)),\n",
        "                        'image_wrist': tfds.features.Image(shape=(128, 128, 3)),\n",
        "                        'depth': tfds.features.Tensor(shape=(224, 224, 1), dtype=tf.float32),\n",
        "                        'proprioception': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                        'gripper_state': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    \n",
        "                    # RLDSæ ‡å‡†å­—æ®µ\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    \n",
        "                    # å¯æ‰©å±•çš„å…ƒæ•°æ®\n",
        "                    'step_metadata': tfds.features.FeaturesDict({\n",
        "                        'timestamp': tfds.features.Scalar(dtype=tf.float64),\n",
        "                        'control_frequency': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,  # RLæ•°æ®æ²¡æœ‰ç›‘ç£å­¦ä¹ çš„é”®\n",
        "            homepage='https://robotics-dataset.example.com',\n",
        "            citation=BIBTEX_CITATION,\n",
        "        )\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"ç”ŸæˆRLDSå…¼å®¹çš„æ ·æœ¬\"\"\"\n",
        "        for episode_idx, episode_data in enumerate(self._load_episodes(data_path)):\n",
        "            # æ„å»ºæ­¥éª¤åºåˆ—\n",
        "            steps = []\n",
        "            for step_idx, step_data in enumerate(episode_data['trajectory']):\n",
        "                step = {\n",
        "                    'observation': {\n",
        "                        'image_primary': step_data['cam_primary'],\n",
        "                        'image_wrist': step_data['cam_wrist'],\n",
        "                        'depth': step_data['depth_map'],\n",
        "                        'proprioception': step_data['joint_positions'],\n",
        "                        'gripper_state': step_data['gripper_pos'],\n",
        "                    },\n",
        "                    'action': step_data['action'],\n",
        "                    'reward': step_data['reward'],\n",
        "                    'discount': step_data.get('discount', 1.0),\n",
        "                    'is_first': step_idx == 0,\n",
        "                    'is_last': step_idx == len(episode_data['trajectory']) - 1,\n",
        "                    'is_terminal': step_data.get('terminal', False),\n",
        "                    'step_metadata': {\n",
        "                        'timestamp': step_data['timestamp'],\n",
        "                        'control_frequency': step_data['freq'],\n",
        "                    }\n",
        "                }\n",
        "                steps.append(step)\n",
        "            \n",
        "            # æ„å»ºå®Œæ•´episode\n",
        "            episode = {\n",
        "                'episode_id': f\"episode_{episode_idx:06d}\",\n",
        "                'episode_metadata': {\n",
        "                    'success': episode_data['metadata']['success'],\n",
        "                    'task': episode_data['metadata']['task_name'],\n",
        "                    'total_reward': sum(s['reward'] for s in steps),\n",
        "                },\n",
        "                'steps': steps\n",
        "            }\n",
        "            \n",
        "            yield f\"episode_{episode_idx}\", episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. é«˜çº§æ•°æ®å˜æ¢æ¡†æ¶\n",
        "\n",
        "RLDSä¸ºTFDSæ·»åŠ äº†ä¸“é—¨çš„å˜æ¢æ¡†æ¶ï¼Œæ”¯æŒå¤æ‚çš„RLæ•°æ®å¤„ç†ï¼š\n",
        "\n",
        "#### a) Episodeçº§å˜æ¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds.transformations as rlds_transforms\n",
        "\n",
        "def advanced_episode_transform():\n",
        "    \"\"\"é«˜çº§episodeå˜æ¢ç¤ºä¾‹\"\"\"\n",
        "    \n",
        "    def add_episode_statistics(episode):\n",
        "        \"\"\"ä¸ºepisodeæ·»åŠ ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # è®¡ç®—episodeçº§ç»Ÿè®¡\n",
        "        total_steps = tf.data.experimental.cardinality(steps)\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        total_reward = rewards.reduce(tf.constant(0.0), tf.add)\n",
        "        \n",
        "        # æ·»åŠ åˆ°å…ƒæ•°æ®\n",
        "        episode['episode_metadata']['episode_length'] = total_steps\n",
        "        episode['episode_metadata']['total_reward'] = total_reward\n",
        "        return episode\n",
        "    \n",
        "    def filter_successful_episodes(episode):\n",
        "        \"\"\"è¿‡æ»¤æˆåŠŸçš„episode\"\"\"\n",
        "        return episode['episode_metadata']['success']\n",
        "    \n",
        "    def normalize_rewards(episode):\n",
        "        \"\"\"å½’ä¸€åŒ–å¥–åŠ±\"\"\"\n",
        "        def normalize_step(step):\n",
        "            # åº”ç”¨z-scoreå½’ä¸€åŒ–\n",
        "            normalized_reward = (step['reward'] - reward_mean) / reward_std\n",
        "            step['reward'] = normalized_reward\n",
        "            return step\n",
        "        \n",
        "        steps = episode[rlds.STEPS].map(normalize_step)\n",
        "        episode[rlds.STEPS] = steps\n",
        "        return episode\n",
        "    \n",
        "    return [add_episode_statistics, filter_successful_episodes, normalize_rewards]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) Stepçº§é«˜çº§å˜æ¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def advanced_step_transforms():\n",
        "    \"\"\"é«˜çº§stepå˜æ¢ç¤ºä¾‹\"\"\"\n",
        "    \n",
        "    def augment_observations(step):\n",
        "        \"\"\"æ•°æ®å¢å¼º\"\"\"\n",
        "        obs = step['observation']\n",
        "        \n",
        "        # å›¾åƒå¢å¼º\n",
        "        if 'image_primary' in obs:\n",
        "            image = obs['image_primary']\n",
        "            # éšæœºé¢œè‰²æŠ–åŠ¨\n",
        "            image = tf.image.random_hue(image, max_delta=0.1)\n",
        "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "            obs['image_primary'] = image\n",
        "        \n",
        "        step['observation'] = obs\n",
        "        return step\n",
        "    \n",
        "    def add_next_observation(step, next_step):\n",
        "        \"\"\"æ·»åŠ ä¸‹ä¸€æ­¥è§‚æµ‹ï¼ˆç”¨äºQå­¦ä¹ ç­‰ï¼‰\"\"\"\n",
        "        step['next_observation'] = next_step['observation']\n",
        "        return step\n",
        "    \n",
        "    def compute_advantage(step, value_estimate):\n",
        "        \"\"\"è®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼ˆç”¨äºç­–ç•¥æ¢¯åº¦ï¼‰\"\"\"\n",
        "        step['advantage'] = step['reward'] + 0.99 * value_estimate - step['value']\n",
        "        return step\n",
        "    \n",
        "    return [augment_observations, add_next_observation, compute_advantage]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4. å¹¶è¡ŒåŒ–æ•°æ®æ„å»ºæ”¯æŒ\n",
        "\n",
        "RLDSæ‰©å±•äº†TFDSçš„Apache Beamæ”¯æŒï¼Œå®ç°é«˜æ•ˆçš„å¹¶è¡Œæ•°æ®å¤„ç†ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¼ ç»ŸTFDSæ„å»º\n",
        "tfds build\n",
        "\n",
        "# RLDSå¹¶è¡Œæ„å»º\n",
        "tfds build --overwrite --beam_pipeline_options=\"direct_running_mode=multi_processing,direct_num_workers=16\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### è‡ªå®šä¹‰å¹¶è¡Œå¤„ç†å™¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSParallelBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"æ”¯æŒå¹¶è¡Œå¤„ç†çš„RLDSæ„å»ºå™¨\"\"\"\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"æ”¯æŒBeamå¹¶è¡Œå¤„ç†çš„ç”Ÿæˆå™¨\"\"\"\n",
        "        import apache_beam as beam\n",
        "        \n",
        "        # åˆ›å»ºBeamç®¡é“\n",
        "        with beam.Pipeline() as pipeline:\n",
        "            episodes = (\n",
        "                pipeline\n",
        "                | 'CreateEpisodePaths' >> beam.Create(self._get_episode_paths(data_path))\n",
        "                | 'ProcessEpisodes' >> beam.Map(self._process_single_episode)\n",
        "                | 'ValidateEpisodes' >> beam.Filter(self._is_valid_episode)\n",
        "                | 'FormatForTFDS' >> beam.Map(self._format_for_tfds)\n",
        "            )\n",
        "        \n",
        "        return episodes\n",
        "    \n",
        "    def _process_single_episode(self, episode_path):\n",
        "        \"\"\"å¤„ç†å•ä¸ªepisodeï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰\"\"\"\n",
        "        # è¿™ä¸ªå‡½æ•°ä¼šåœ¨å¤šä¸ªworkerä¸Šå¹¶è¡Œæ‰§è¡Œ\n",
        "        raw_data = self._load_episode_data(episode_path)\n",
        "        processed_episode = self._convert_to_rlds_format(raw_data)\n",
        "        return processed_episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5. æ•°æ®é›†ä¿®æ”¹å’Œè½¬æ¢æ¡†æ¶\n",
        "\n",
        "RLDSæä¾›äº†å¼ºå¤§çš„æ•°æ®é›†åå¤„ç†èƒ½åŠ›ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä½¿ç”¨RLDSæ•°æ®é›†ä¿®æ”¹æ¡†æ¶\n",
        "python modify_rlds_dataset.py \\\n",
        "    --dataset=my_robot_dataset \\\n",
        "    --mods=resize_images,add_language_conditioning,normalize_actions \\\n",
        "    --target_dir=/path/to/modified/dataset \\\n",
        "    --n_workers=16\n",
        "\n",
        "# æ”¯æŒçš„ä¿®æ”¹æ“ä½œ\n",
        "SUPPORTED_MODIFICATIONS = {\n",
        "    'resize_images': ResizeImagesTransform(target_size=(224, 224)),\n",
        "    'jpeg_encode': JpegEncodeTransform(quality=95),\n",
        "    'add_language_conditioning': AddLanguageConditioningTransform(),\n",
        "    'normalize_actions': NormalizeActionsTransform(),\n",
        "    'filter_by_success': FilterBySuccessTransform(),\n",
        "    'subsample_timesteps': SubsampleTimestepsTransform(factor=2),\n",
        "    'add_goal_conditioning': AddGoalConditioningTransform(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### è‡ªå®šä¹‰ä¿®æ”¹å‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomRLDSModification:\n",
        "    \"\"\"è‡ªå®šä¹‰RLDSæ•°æ®ä¿®æ”¹\"\"\"\n",
        "    \n",
        "    def modify_dataset_info(self, info):\n",
        "        \"\"\"ä¿®æ”¹æ•°æ®é›†ä¿¡æ¯\"\"\"\n",
        "        # æ·»åŠ æ–°çš„ç‰¹å¾\n",
        "        features = info.features.copy()\n",
        "        features['steps']['goal_image'] = tfds.features.Image(shape=(224, 224, 3))\n",
        "        \n",
        "        return info._replace(features=features)\n",
        "    \n",
        "    def modify_example(self, example):\n",
        "        \"\"\"ä¿®æ”¹å•ä¸ªæ ·æœ¬\"\"\"\n",
        "        steps = example['steps']\n",
        "        \n",
        "        # ä¸ºæ¯ä¸ªstepæ·»åŠ ç›®æ ‡å›¾åƒ\n",
        "        def add_goal_to_step(step):\n",
        "            # ä½¿ç”¨æœ€åä¸€æ­¥çš„è§‚æµ‹ä½œä¸ºç›®æ ‡\n",
        "            step['goal_image'] = steps[-1]['observation']['image_primary']\n",
        "            return step\n",
        "        \n",
        "        modified_steps = steps.map(add_goal_to_step)\n",
        "        example['steps'] = modified_steps\n",
        "        \n",
        "        return example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 6. ä¸“ç”¨çš„RLDSéªŒè¯æ¡†æ¶\n",
        "\n",
        "RLDSæ‰©å±•äº†TFDSçš„éªŒè¯æœºåˆ¶ï¼Œå¢åŠ äº†RLç‰¹å®šçš„æ£€æŸ¥ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSValidator:\n",
        "    \"\"\"RLDSæ•°æ®é›†éªŒè¯å™¨\"\"\"\n",
        "    \n",
        "    def validate_episode_structure(self, episode):\n",
        "        \"\"\"éªŒè¯episodeç»“æ„\"\"\"\n",
        "        checks = [\n",
        "            self._check_required_fields(episode),\n",
        "            self._check_step_consistency(episode),\n",
        "            self._check_temporal_ordering(episode),\n",
        "            self._check_terminal_states(episode),\n",
        "            self._check_reward_validity(episode),\n",
        "        ]\n",
        "        \n",
        "        return all(checks)\n",
        "    \n",
        "    def _check_step_consistency(self, episode):\n",
        "        \"\"\"æ£€æŸ¥æ­¥éª¤ä¸€è‡´æ€§\"\"\"\n",
        "        steps = episode['steps']\n",
        "        \n",
        "        # æ£€æŸ¥ç¬¬ä¸€æ­¥æ ‡è®°\n",
        "        first_step = next(iter(steps))\n",
        "        if not first_step['is_first']:\n",
        "            raise ValueError(\"First step must have is_first=True\")\n",
        "        \n",
        "        # æ£€æŸ¥æœ€åä¸€æ­¥æ ‡è®°\n",
        "        step_count = 0\n",
        "        last_step = None\n",
        "        for step in steps:\n",
        "            step_count += 1\n",
        "            last_step = step\n",
        "        \n",
        "        if not last_step['is_last']:\n",
        "            raise ValueError(\"Last step must have is_last=True\")\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def _check_temporal_ordering(self, episode):\n",
        "        \"\"\"æ£€æŸ¥æ—¶é—´åºåˆ—å®Œæ•´æ€§\"\"\"\n",
        "        steps = list(episode['steps'])\n",
        "        \n",
        "        # éªŒè¯æ—¶é—´æˆ³å•è°ƒé€’å¢\n",
        "        if 'timestamp' in steps[0].get('step_metadata', {}):\n",
        "            timestamps = [s['step_metadata']['timestamp'] for s in steps]\n",
        "            if not all(t1 <= t2 for t1, t2 in zip(timestamps, timestamps[1:])):\n",
        "                raise ValueError(\"Timestamps must be non-decreasing\")\n",
        "        \n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 7. Open X-Embodimentæ•°æ®é›†é›†æˆ\n",
        "\n",
        "RLDSä¸ºå¤§è§„æ¨¡æœºå™¨äººæ•°æ®é›†æä¾›äº†ä¸“é—¨çš„æ”¯æŒï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open X-Embodimentæ•°æ®é›†ä¸‹è½½å’Œå¤„ç†\n",
        "bash prepare_open_x.sh\n",
        "\n",
        "# æ”¯æŒçš„æ•°æ®é›†è½¬æ¢\n",
        "OPEN_X_DATASETS = [\n",
        "    'bridge_v2',\n",
        "    'rt_1',\n",
        "    'berkeley_autolab_ur5',\n",
        "    'taco_play',\n",
        "    'kuka_multimodal',\n",
        "    'stanford_robocook',\n",
        "    # ... 50+ æ•°æ®é›†\n",
        "]\n",
        "\n",
        "# ç»Ÿä¸€çš„å˜æ¢æ¥å£\n",
        "def transform_for_x_embodiment(step):\n",
        "    \"\"\"è½¬æ¢ä¸ºX-embodimentæ ‡å‡†æ ¼å¼\"\"\"\n",
        "    return {\n",
        "        'observation': {\n",
        "            'image': step['observation']['image_primary'],  # å•ä¸€RGBè¾“å…¥\n",
        "            'natural_language_embedding': step['language_embedding'],\n",
        "        },\n",
        "        'action': step['action'][:7],  # æ ‡å‡†7-DOFåŠ¨ä½œ\n",
        "        'reward': step['reward'],\n",
        "        'is_first': step['is_first'],\n",
        "        'is_last': step['is_last'],\n",
        "        'is_terminal': step['is_terminal'],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 8. é«˜çº§æ€§èƒ½ä¼˜åŒ–\n",
        "\n",
        "RLDSå®ç°äº†é’ˆå¯¹RLæ•°æ®çš„ä¸“é—¨ä¼˜åŒ–ï¼š\n",
        "\n",
        "#### a) æ™ºèƒ½ç¼“å­˜ç­–ç•¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSCachingStrategy:\n",
        "    \"\"\"RLDSä¸“ç”¨ç¼“å­˜ç­–ç•¥\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.episode_cache = {}\n",
        "        self.step_cache = {}\n",
        "    \n",
        "    def cache_episode(self, episode_id, episode):\n",
        "        \"\"\"ç¼“å­˜å®Œæ•´episode\"\"\"\n",
        "        # åªç¼“å­˜å°å‹episodeï¼Œé¿å…å†…å­˜æº¢å‡º\n",
        "        if self._estimate_episode_size(episode) < 100_000_000:  # 100MB\n",
        "            self.episode_cache[episode_id] = episode\n",
        "    \n",
        "    def cache_step_sequence(self, episode_id, start_idx, steps):\n",
        "        \"\"\"ç¼“å­˜æ­¥éª¤åºåˆ—ï¼ˆç”¨äºN-stepå­¦ä¹ ï¼‰\"\"\"\n",
        "        cache_key = f\"{episode_id}_{start_idx}\"\n",
        "        self.step_cache[cache_key] = steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) è‡ªé€‚åº”æ‰¹å¤„ç†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaptive_batching(dataset, target_memory_usage=8_000_000_000):  # 8GB\n",
        "    \"\"\"æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µè‡ªé€‚åº”è°ƒæ•´æ‰¹å¤§å°\"\"\"\n",
        "    \n",
        "    def estimate_sample_size(sample):\n",
        "        \"\"\"ä¼°ç®—æ ·æœ¬å†…å­˜ä½¿ç”¨\"\"\"\n",
        "        size = 0\n",
        "        for step in sample['steps']:\n",
        "            for key, value in step['observation'].items():\n",
        "                if 'image' in key:\n",
        "                    size += value.shape.num_elements() * 4  # float32\n",
        "                else:\n",
        "                    size += value.shape.num_elements() * value.dtype.size\n",
        "        return size\n",
        "    \n",
        "    # åŠ¨æ€è®¡ç®—æ‰¹å¤§å°\n",
        "    sample = next(iter(dataset))\n",
        "    sample_size = estimate_sample_size(sample)\n",
        "    optimal_batch_size = max(1, target_memory_usage // sample_size)\n",
        "    \n",
        "    return dataset.batch(optimal_batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9. ä¸ç°æœ‰ç”Ÿæ€ç³»ç»Ÿçš„å…¼å®¹æ€§\n",
        "\n",
        "RLDSç¡®ä¿ä¸TensorFlowç”Ÿæ€ç³»ç»Ÿçš„å®Œç¾å…¼å®¹ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¸tf.dataçš„æ— ç¼é›†æˆ\n",
        "rlds_dataset = tfds.load('my_robot_dataset')\n",
        "tf_data_pipeline = (\n",
        "    rlds_dataset['train']\n",
        "    .flat_map(lambda ep: ep['steps'])  # å±•å¹³ä¸ºstepçº§æ•°æ®\n",
        "    .map(preprocess_function)\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# ä¸tf.saved_modelçš„å…¼å®¹\n",
        "@tf.function\n",
        "def process_rlds_batch(batch):\n",
        "    \"\"\"å¤„ç†RLDSæ‰¹æ¬¡æ•°æ®\"\"\"\n",
        "    observations = batch['observation']['image']\n",
        "    actions = batch['action']\n",
        "    return model(observations), actions\n",
        "\n",
        "# ä¿å­˜ä¸ºSavedModel\n",
        "tf.saved_model.save(process_rlds_batch, '/path/to/saved_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## å¼•ç”¨å’Œè‡´è°¢\n",
        "\n",
        "å¦‚æœä½¿ç”¨RLDSï¼Œè¯·å¼•ç”¨å®˜æ–¹è®ºæ–‡ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@misc{ramos2021rlds,\n",
        "    title={RLDS: an Ecosystem to Generate, Share and Use Datasets in Reinforcement Learning},\n",
        "    author={Sabela Ramos and Sertan Girgin and LÃ©onard Hussenot and Damien Vincent and Hanna Yakubovich and Daniel Toyama and Anita Gergely and Piotr Stanczyk and Raphael Marinier and Jeremiah Harmsen and Olivier Pietquin and Nikola Momchev},\n",
        "    year={2021},\n",
        "    eprint={2111.02767},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.LG}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ä½¿ç”¨RLDSçš„é‡è¦è®ºæ–‡\n",
        "\n",
        "- **Hyperparameter Selection for Imitation Learning** (ICML 2021)\n",
        "- **Continuous Control with Action Quantization from Demonstrations** (NeurIPS 2021)  \n",
        "- **What Matters for Adversarial Imitation Learning?** (NeurIPS 2021)\n",
        "- **MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale**\n",
        "- **Offline Reinforcement Learning with Pseudometric Learning** (ICML 2021)\n",
        "\n",
        "## æ€»ç»“\n",
        "\n",
        "RLDSæä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–ã€é«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ æ•°æ®å­˜å‚¨å’Œå¤„ç†æ¡†æ¶ã€‚å…¶ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š\n",
        "\n",
        "1. **æ ‡å‡†åŒ–æ ¼å¼**ï¼šç»Ÿä¸€çš„æ•°æ®ç»“æ„ä¾¿äºä¸åŒé¡¹ç›®é—´çš„æ•°æ®å…±äº«\n",
        "2. **é«˜æ•ˆå­˜å‚¨**ï¼šåŸºäºTensorFlowçš„ä¼˜åŒ–å­˜å‚¨æ ¼å¼  \n",
        "3. **ä¸°å¯Œå…ƒæ•°æ®**ï¼šæ”¯æŒè¯¦ç»†çš„ä»»åŠ¡å’Œè½¨è¿¹æ ‡æ³¨\n",
        "4. **æ˜“äºå¤„ç†**ï¼šä¸ç°ä»£æœºå™¨å­¦ä¹ å·¥å…·é“¾æ— ç¼é›†æˆ\n",
        "5. **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒè‡ªå®šä¹‰è§‚æµ‹ç©ºé—´å’Œä»»åŠ¡ç‰¹å®šå­—æ®µ\n",
        "6. **æ€§èƒ½ä¼˜åŒ–**ï¼šé’ˆå¯¹RLæ•°æ®ç‰¹ç‚¹çš„ä¸“é—¨ä¼˜åŒ–\n",
        "7. **ç¤¾åŒºç”Ÿæ€**ï¼šæ´»è·ƒçš„å¼€æºç¤¾åŒºå’Œä¸°å¯Œçš„æ•°æ®é›†èµ„æº\n",
        "\n",
        "é€šè¿‡ä½¿ç”¨RLDSï¼Œç ”ç©¶è€…å¯ä»¥æ›´å®¹æ˜“åœ°æ„å»ºã€å…±äº«å’Œä½¿ç”¨å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ æ•°æ®é›†ï¼Œæ¨åŠ¨å¼ºåŒ–å­¦ä¹ æŠ€æœ¯çš„å‘å±•ã€‚ \n",
        "\n",
        "## é«˜çº§æ•°æ®ç»“æ„è§„èŒƒ\n",
        "\n",
        "### Episodeå…ƒæ•°æ®æ‰©å±•è§„èŒƒ\n",
        "\n",
        "åŸºäºå®˜æ–¹GitHubä»“åº“ï¼ŒEpisodeæ”¯æŒä»¥ä¸‹æ ‡å‡†å…ƒæ•°æ®å­—æ®µï¼š\n",
        "\n",
        "| å­—æ®µå | ç±»å‹ | å¿…éœ€ | æè¿° | ç¤ºä¾‹ |\n",
        "|--------|------|------|------|------|\n",
        "| `episode_id` | `tf.string` | æ¨è | å…¨å±€å”¯ä¸€æ ‡è¯†ç¬¦ | `\"dataset_v1_episode_12345\"` |\n",
        "| `agent_id` | `tf.string/tf.Tensor` | å¯é€‰ | æ™ºèƒ½ä½“æ ‡è¯†ç¬¦(æ”¯æŒå¤šæ™ºèƒ½ä½“) | `\"sac_agent_v2\"` æˆ– `[[agent_name, agent_id], ...]` |\n",
        "| `environment_config` | `dict` | å¯é€‰ | ç¯å¢ƒé…ç½®å‚æ•° | `{\"gravity\": -9.8, \"friction\": 0.1}` |\n",
        "| `experiment_id` | `tf.string` | å¯é€‰ | å®éªŒæ ‡è¯†ç¬¦ | `\"exp_20231215_hyperopt\"` |\n",
        "| `invalid` | `tf.bool` | å¯é€‰ | æ— æ•ˆepisodeæ ‡è®° | `False` |\n",
        "\n",
        "### Stepå­—æ®µå®Œæ•´è§„èŒƒ\n",
        "\n",
        "#### å¿…éœ€å­—æ®µ\n",
        "| å­—æ®µå | ç±»å‹ | æè¿° | é‡è¦è¯´æ˜ |\n",
        "|--------|------|------|----------|\n",
        "| `is_first` | `tf.bool` | æ˜¯å¦ä¸ºé¦–æ­¥ | åŒ…å«åˆå§‹çŠ¶æ€ |\n",
        "| `is_last` | `tf.bool` | æ˜¯å¦ä¸ºæœ«æ­¥ | å½“ä¸ºTrueæ—¶ï¼Œåç»­å­—æ®µæ— æ•ˆ |\n",
        "\n",
        "#### å¯é€‰å­—æ®µ\n",
        "| å­—æ®µå | ç±»å‹ | æè¿° | æ¡ä»¶çº¦æŸ |\n",
        "|--------|------|------|----------|\n",
        "| `observation` | `dict` | å½“å‰è§‚æµ‹ | ç»“æ„åœ¨æ•°æ®é›†å†…å¿…é¡»ä¸€è‡´ |\n",
        "| `action` | `tf.Tensor` | æ‰§è¡Œçš„åŠ¨ä½œ | `is_last=True`æ—¶æ— æ•ˆ |\n",
        "| `reward` | `tf.float32` | è·å¾—çš„å¥–åŠ± | `is_last=True`æ—¶æ— æ•ˆ |\n",
        "| `discount` | `tf.float32` | æŠ˜æ‰£å› å­ | é€šå¸¸ä¸º1.0æˆ–Î³ |\n",
        "| `is_terminal` | `tf.bool` | æ˜¯å¦ä¸ºç»ˆæ­¢çŠ¶æ€ | åŒºåˆ†æˆªæ–­vsç»ˆæ­¢ |\n",
        "\n",
        "#### ç»ˆæ­¢çŠ¶æ€è¯­ä¹‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è‡ªç„¶ç»ˆæ­¢ (æ¸¸æˆç»“æŸ)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': True,\n",
        "    'observation': final_obs,  # æœ‰æ•ˆçš„æœ€ç»ˆè§‚æµ‹\n",
        "    'action': None,           # æ— æ•ˆ\n",
        "    'reward': None,           # æ— æ•ˆ\n",
        "    'discount': None          # æ— æ•ˆ\n",
        "}\n",
        "\n",
        "# æˆªæ–­ç»ˆæ­¢ (æ—¶é—´é™åˆ¶)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': False,\n",
        "    'observation': final_obs,  # æœ‰æ•ˆçš„æˆªæ–­è§‚æµ‹\n",
        "    'action': None,           # å¯èƒ½æ— æ•ˆ\n",
        "    'reward': final_reward,   # å¯èƒ½æœ‰æ•ˆ\n",
        "    'discount': gamma         # å¯èƒ½æœ‰æ•ˆ\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSå˜æ¢åº“è¯¦è§£\n",
        "\n",
        "### æ ¸å¿ƒå˜æ¢æ“ä½œ\n",
        "\n",
        "RLDSæä¾›ä¼˜åŒ–çš„å˜æ¢åº“ï¼Œè€ƒè™‘äº†RLæ•°æ®é›†çš„åµŒå¥—ç»“æ„ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds\n",
        "\n",
        "# 1. Episodeçº§å˜æ¢\n",
        "def process_episode(episode):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    # æ·»åŠ è‡ªå®šä¹‰episodeç»Ÿè®¡\n",
        "    episode_length = tf.data.experimental.cardinality(steps)\n",
        "    episode['metadata']['length'] = episode_length\n",
        "    return episode\n",
        "\n",
        "dataset = dataset.map(process_episode)\n",
        "\n",
        "# 2. Stepçº§å˜æ¢ - å±•å¹³episode\n",
        "step_dataset = episode_dataset.flat_map(lambda x: x[rlds.STEPS])\n",
        "\n",
        "# 3. çª—å£åŒ–å˜æ¢ - Næ­¥è½¬ç§»\n",
        "def make_n_step_transitions(episode, n=5):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    windowed = steps.window(n, shift=1, drop_remainder=True)\n",
        "    return windowed.flat_map(lambda w: w.batch(n))\n",
        "\n",
        "# 4. è¿‡æ»¤å˜æ¢\n",
        "def filter_successful_episodes(episode):\n",
        "    return episode['metadata']['success'] == True\n",
        "\n",
        "dataset = dataset.filter(filter_successful_episodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### é«˜æ€§èƒ½æ‰¹å¤„ç†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è‡ªåŠ¨æ‰¹å¤„ç† - è€ƒè™‘episodeè¾¹ç•Œ\n",
        "def smart_batch(dataset, batch_size, respect_episode_boundaries=True):\n",
        "    if respect_episode_boundaries:\n",
        "        # ç¡®ä¿batchå†…çš„stepæ¥è‡ªåŒä¸€episode\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS].batch(batch_size)\n",
        "        )\n",
        "    else:\n",
        "        # è·¨episodeæ‰¹å¤„ç†\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS]\n",
        "        ).batch(batch_size)\n",
        "\n",
        "# ç¤ºä¾‹ç”¨æ³•\n",
        "batched_steps = smart_batch(dataset, batch_size=32, \n",
        "                           respect_episode_boundaries=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ\n",
        "\n",
        "### 1. å†…å­˜ä¼˜åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å‡å°‘å†…å­˜ä½¿ç”¨çš„ReadConfig\n",
        "read_config = tfds.ReadConfig(\n",
        "    # å‡å°‘å¹¶è¡ŒåŠ è½½çš„æ–‡ä»¶æ•°\n",
        "    interleave_cycle_length=4,\n",
        "    interleave_block_length=1,\n",
        "    # å¯ç”¨ç¡®å®šæ€§è¯»å–\n",
        "    shuffle_seed=42,\n",
        "    shuffle_reshuffle_each_iteration=True\n",
        ")\n",
        "\n",
        "dataset = tfds.load('dataset_name', read_config=read_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. å¹¶è¡Œå¤„ç†ä¼˜åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¤šè¿›ç¨‹æ•°æ®åŠ è½½\n",
        "def optimized_pipeline(dataset_name, num_parallel_calls=tf.data.AUTOTUNE):\n",
        "    dataset = tfds.load(dataset_name, shuffle_files=True)\n",
        "    \n",
        "    # å¹¶è¡Œè§£ç å’Œé¢„å¤„ç†\n",
        "    dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        num_parallel_calls=num_parallel_calls\n",
        "    )\n",
        "    \n",
        "    # é¢„å–ä¼˜åŒ–\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. éšæœºåŒ–ç­–ç•¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ–¹å¼1: å®Œç¾éšæœºåŒ– (é«˜å†…å­˜)\n",
        "shuffled = dataset.shuffle(buffer_size=10000)  # éœ€è¦å¤§ç¼“å†²åŒº\n",
        "\n",
        "# æ–¹å¼2: äº¤é”™éšæœºåŒ– (å†…å­˜å‹å¥½)\n",
        "def create_interleaved_dataset(dataset_name, num_copies=4):\n",
        "    def dataset_loader():\n",
        "        ds = tfds.load(dataset_name, shuffle_files=True)\n",
        "        return ds.flat_map(lambda x: x[rlds.STEPS])\n",
        "    \n",
        "    # åˆ›å»ºå¤šä¸ªç‹¬ç«‹éšæœºåŒ–çš„æ•°æ®é›†å‰¯æœ¬\n",
        "    dataset = tf.data.Dataset.range(num_copies).interleave(\n",
        "        lambda _: dataset_loader(),\n",
        "        cycle_length=num_copies,\n",
        "        block_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "# æ–¹å¼3: åˆ†ç‰‡éšæœºåŒ– (é¿å…é‡å¤)\n",
        "def distributed_random_access(dataset_name, num_workers, worker_id):\n",
        "    # æ¯ä¸ªworkerå¤„ç†ä¸åŒçš„åˆ†ç‰‡\n",
        "    split_name = f'train[{worker_id}shard{num_workers}]'\n",
        "    return tfds.load(dataset_name, split=split_name, shuffle_files=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## å¤šæ™ºèƒ½ä½“æ”¯æŒ\n",
        "\n",
        "RLDSåŸç”Ÿæ”¯æŒå¤šæ™ºèƒ½ä½“åœºæ™¯ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¤šæ™ºèƒ½ä½“Episodeç»“æ„\n",
        "multi_agent_episode = {\n",
        "    'episode_id': 'multi_agent_001',\n",
        "    'agent_id': tf.constant([\n",
        "        ['player_1', 'dqn_agent_v1'],\n",
        "        ['player_2', 'human_expert'],\n",
        "        ['env_bot', 'scripted_agent']\n",
        "    ]),\n",
        "    'steps': [\n",
        "        {\n",
        "            'observation': {\n",
        "                'player_1': player1_obs,\n",
        "                'player_2': player2_obs,\n",
        "                'global': global_obs\n",
        "            },\n",
        "            'action': {\n",
        "                'player_1': player1_action,\n",
        "                'player_2': player2_action\n",
        "            },\n",
        "            'reward': {\n",
        "                'player_1': player1_reward,\n",
        "                'player_2': player2_reward\n",
        "            },\n",
        "            'is_first': True,\n",
        "            'is_last': False,\n",
        "            'is_terminal': False\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## å¯ç”¨æ•°æ®é›†ç”Ÿæ€\n",
        "\n",
        "### å®˜æ–¹æ”¯æŒçš„æ•°æ®é›†\n",
        "\n",
        "| æ•°æ®é›†ç³»åˆ— | é¢†åŸŸ | ä»»åŠ¡æ•°é‡ | æè¿° |\n",
        "|------------|------|----------|------|\n",
        "| **D4RL** | æœºå™¨äºº/æ¸¸æˆ | 34+ | Mujoco, Adroit, AntMazeä»»åŠ¡ |\n",
        "| **RL Unplugged** | å¤šé¢†åŸŸ | 50+ | DMLab, Atari, çœŸå®ä¸–ç•ŒRL |\n",
        "| **Robosuite** | æœºå™¨äººæ“ä½œ | 3 | ç”¨RLDSå·¥å…·ç”Ÿæˆ |\n",
        "| **Robomimic** | æœºå™¨äººå­¦ä¹  | 15+ | æ¨¡ä»¿å­¦ä¹ æ•°æ®é›† |\n",
        "| **MuJoCo Locomotion** | è¿åŠ¨æ§åˆ¶ | 8 | SACæ™ºèƒ½ä½“ç”Ÿæˆ |\n",
        "| **MT-Opt** | æœºå™¨äºº | 1 | å¤§è§„æ¨¡å¤šä»»åŠ¡æ•°æ®é›† |\n",
        "\n",
        "### æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŠ è½½ä¸åŒç±»å‹çš„æ•°æ®é›†\n",
        "datasets = {\n",
        "    # è¿ç»­æ§åˆ¶\n",
        "    'mujoco': tfds.load('d4rl_mujoco_hopper/v1-medium'),\n",
        "    \n",
        "    # ç¦»æ•£æ§åˆ¶  \n",
        "    'atari': tfds.load('rl_unplugged_atari_breakout/run_1'),\n",
        "    \n",
        "    # æœºå™¨äººæ“ä½œ\n",
        "    'robot': tfds.load('robosuite_lift/human_demos'),\n",
        "    \n",
        "    # å¯¼èˆªä»»åŠ¡\n",
        "    'maze': tfds.load('d4rl_antmaze/umaze-v1')\n",
        "}\n",
        "\n",
        "# ç»Ÿä¸€å¤„ç†æ¥å£\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"\\n{name.upper()} Dataset:\")\n",
        "    for episode in dataset['train'].take(1):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        print(f\"  Episode length: {tf.data.experimental.cardinality(steps)}\")\n",
        "        \n",
        "        for step in steps.take(1):\n",
        "            obs_keys = list(step['observation'].keys())\n",
        "            action_shape = step['action'].shape\n",
        "            print(f\"  Observation keys: {obs_keys}\")\n",
        "            print(f\"  Action shape: {action_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ç¤¾åŒºè´¡çŒ®å’Œæ‰©å±•\n",
        "\n",
        "### æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†åˆ°TFDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class MyRLDataset(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"è‡ªå®šä¹‰RLDSå…¼å®¹æ•°æ®é›†\"\"\"\n",
        "    \n",
        "    VERSION = tfds.core.Version('1.0.0')\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"My custom RL dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        'image': tfds.features.Image(shape=(84, 84, 3)),\n",
        "                        'state': tfds.features.Tensor(shape=(10,), dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,\n",
        "            homepage='https://my-dataset-homepage.com',\n",
        "            citation=\"\"\"@article{my2023dataset, ...}\"\"\",\n",
        "        )\n",
        "    \n",
        "    def _split_generators(self, dl_manager):\n",
        "        return [\n",
        "            tfds.core.SplitGenerator(\n",
        "                name=tfds.Split.TRAIN,\n",
        "                gen_kwargs={'data_path': '/path/to/train/data'},\n",
        "            ),\n",
        "        ]\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        # å®ç°æ•°æ®ç”Ÿæˆé€»è¾‘\n",
        "        for episode_file in episode_files:\n",
        "            episode_id, steps = load_episode(episode_file)\n",
        "            yield episode_id, {\n",
        "                'episode_id': episode_id,\n",
        "                'steps': steps\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## å®é™…åº”ç”¨æ¡ˆä¾‹\n",
        "\n",
        "### æ¡ˆä¾‹1: ç¦»çº¿å¼ºåŒ–å­¦ä¹ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def offline_rl_pipeline(dataset_name, algorithm='cql'):\n",
        "    # åŠ è½½æ•°æ®é›†\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # æ•°æ®é¢„å¤„ç†\n",
        "    def preprocess_for_offline_rl(episode):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # è®¡ç®—return-to-go\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        returns = compute_returns_to_go(rewards)\n",
        "        \n",
        "        # æ·»åŠ returnä¿¡æ¯\n",
        "        enriched_steps = tf.data.Dataset.zip((steps, returns))\n",
        "        return enriched_steps.map(lambda step, ret: {\n",
        "            **step, 'return_to_go': ret\n",
        "        })\n",
        "    \n",
        "    processed_dataset = dataset.map(preprocess_for_offline_rl)\n",
        "    \n",
        "    # è½¬æ¢ä¸ºstepçº§æ•°æ®ç”¨äºè®­ç»ƒ\n",
        "    step_dataset = processed_dataset.flat_map(lambda x: x)\n",
        "    \n",
        "    return step_dataset.batch(256).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### æ¡ˆä¾‹2: æ¨¡ä»¿å­¦ä¹ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imitation_learning_pipeline(expert_dataset, student_dataset):\n",
        "    # åŠ è½½ä¸“å®¶æ•°æ®\n",
        "    expert_ds = tfds.load(expert_dataset)['train']\n",
        "    expert_steps = expert_ds.flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # è¿‡æ»¤æˆåŠŸçš„è½¨è¿¹\n",
        "    def is_successful_episode(episode):\n",
        "        return episode.get('metadata', {}).get('success', True)\n",
        "    \n",
        "    expert_steps = expert_ds.filter(is_successful_episode)\\\n",
        "                           .flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # åˆ›å»º(observation, action)å¯¹\n",
        "    bc_data = expert_steps.map(lambda step: {\n",
        "        'observation': step['observation'],\n",
        "        'action': step['action']\n",
        "    }).filter(lambda x: not x.get('is_last', False))\n",
        "    \n",
        "    return bc_data.batch(128).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### æ¡ˆä¾‹3: æ•°æ®é›†åˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset(dataset_name):\n",
        "    \"\"\"å…¨é¢åˆ†æRLDSæ•°æ®é›†\"\"\"\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # Episodeçº§ç»Ÿè®¡\n",
        "    episode_lengths = []\n",
        "    success_rates = []\n",
        "    \n",
        "    # Stepçº§ç»Ÿè®¡  \n",
        "    action_stats = []\n",
        "    reward_stats = []\n",
        "    \n",
        "    for episode in dataset:\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # Episodeåˆ†æ\n",
        "        episode_length = tf.data.experimental.cardinality(steps).numpy()\n",
        "        episode_lengths.append(episode_length)\n",
        "        \n",
        "        success = episode.get('metadata', {}).get('success', None)\n",
        "        if success is not None:\n",
        "            success_rates.append(success.numpy())\n",
        "        \n",
        "        # Stepåˆ†æ\n",
        "        for step in steps:\n",
        "            if not step['is_last']:\n",
        "                action_stats.append(step['action'].numpy())\n",
        "                reward_stats.append(step['reward'].numpy())\n",
        "    \n",
        "    # ç”ŸæˆæŠ¥å‘Š\n",
        "    analysis_report = {\n",
        "        'episode_count': len(episode_lengths),\n",
        "        'avg_episode_length': np.mean(episode_lengths),\n",
        "        'std_episode_length': np.std(episode_lengths),\n",
        "        'success_rate': np.mean(success_rates) if success_rates else None,\n",
        "        'total_steps': sum(episode_lengths),\n",
        "        'action_dimensionality': action_stats[0].shape if action_stats else None,\n",
        "        'reward_range': (np.min(reward_stats), np.max(reward_stats)) if reward_stats else None,\n",
        "    }\n",
        "    \n",
        "    return analysis_report \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "octo_clean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
