{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) ËØ¶Ëß£\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™‰∫§‰∫íÂºèÁöÑRLDSÊïôÁ®ãÔºåÂåÖÂê´‰∫ÜÂÆåÊï¥ÁöÑ‰ª£Á†ÅÁ§∫‰æãÂíåËß£Èáä„ÄÇ\n",
        "\n",
        "**ÁõÆÊ†á:**\n",
        "- ÁêÜËß£RLDSÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÂíåÊû∂ÊûÑ\n",
        "- Â≠¶‰π†Â¶Ç‰Ωï‰ΩøÁî®RLDSÂ§ÑÁêÜÂº∫ÂåñÂ≠¶‰π†Êï∞ÊçÆ\n",
        "- ÊéåÊè°Êï∞ÊçÆÈõÜÊûÑÂª∫ÂíåÂ§ÑÁêÜÁöÑÊúÄ‰Ω≥ÂÆûË∑µ\n",
        "\n",
        "**ÂâçÁΩÆË¶ÅÊ±Ç:**\n",
        "- Python 3.7+\n",
        "- TensorFlow 2.x\n",
        "- TensorFlow Datasets\n",
        "- RLDSÂ∫ì (ÂèØÈÄâ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß VSCode Áî®Êà∑ËÆæÁΩÆÊåáÂçó\n",
        "\n",
        "Êú¨ÊïôÁ®ãÂåÖÂê´Â§ö‰∏™ Mermaid Êû∂ÊûÑÂõæ„ÄÇÂ¶ÇÊûúÊÇ®‰ΩøÁî® VSCodeÔºåËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§ËÆæÁΩÆÔºö\n",
        "\n",
        "### 1. ÂÆâË£Ö Mermaid È¢ÑËßàÊâ©Â±ï\n",
        "```\n",
        "1. Êåâ Ctrl+Shift+X ÊâìÂºÄÊâ©Â±ïÈù¢Êùø\n",
        "2. ÊêúÁ¥¢ \"Mermaid Preview\"\n",
        "3. ÂÆâË£Ö \"Mermaid Preview\" (bierner.markdown-mermaid)\n",
        "4. ÈáçÂêØ VSCode\n",
        "```\n",
        "\n",
        "### 2. ÈÖçÁΩÆ VSCode ËÆæÁΩÆ (ÂèØÈÄâ)\n",
        "Âú® `settings.json` ‰∏≠Ê∑ªÂä†Ôºö\n",
        "```json\n",
        "{\n",
        "    \"markdown.mermaid.theme\": \"default\",\n",
        "    \"markdown.preview.breaks\": true\n",
        "}\n",
        "```\n",
        "\n",
        "### 3. Êü•ÁúãÂõæË°®\n",
        "- **ÊñπÊ≥ï1**: ÂÆâË£ÖÊâ©Â±ïÂêéÁõ¥Êé•Âú® notebook ‰∏≠Êü•Áúã\n",
        "- **ÊñπÊ≥ï2**: Â§çÂà∂ mermaid ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "- **ÊñπÊ≥ï3**: Êü•ÁúãÊØè‰∏™ÂõæË°®‰∏ãÊñπÁöÑÊñáÂ≠óÁâàËØ¥Êòé\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplot in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (0.1.9)\n",
            "Requirement already satisfied: pyloco>=0.0.134 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplot) (0.0.139)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplot) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (2.9.0.post0)\n",
            "Requirement already satisfied: ushlex in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (0.99.1)\n",
            "Requirement already satisfied: websocket-client in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (1.8.0)\n",
            "Requirement already satisfied: twine in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (6.1.0)\n",
            "Requirement already satisfied: typing in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (3.7.4.3)\n",
            "Requirement already satisfied: SimpleWebSocketServer in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->matplot) (1.17.0)\n",
            "Requirement already satisfied: readme-renderer>=35.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (44.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (1.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (2.4.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (25.6.0)\n",
            "Requirement already satisfied: rfc3986>=1.4.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (2.0.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (14.0.0)\n",
            "Requirement already satisfied: id in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (1.5.0)\n",
            "Requirement already satisfied: importlib_metadata>=4.11.4 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (8.7.0)\n",
            "Requirement already satisfied: jaraco.classes in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.4.0)\n",
            "Requirement already satisfied: jaraco.functools in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (4.1.0)\n",
            "Requirement already satisfied: jaraco.context in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (6.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from importlib_metadata>=4.11.4->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.22.0)\n",
            "Requirement already satisfied: nh3>=0.2.14 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (0.2.21)\n",
            "Requirement already satisfied: docutils>=0.21.2 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (0.21.2)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (0.1.2)\n",
            "Requirement already satisfied: more-itertools in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from jaraco.classes->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (10.7.0)\n",
            "Requirement already satisfied: backports.tarfile in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from jaraco.context->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (1.2.0)\n",
            "Requirement already satisfied: tensorflow in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (4.21.12)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (78.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (4.9.9)\n",
            "Requirement already satisfied: absl-py in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (2.3.0)\n",
            "Requirement already satisfied: dm-tree in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.6.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (2.1.3)\n",
            "Requirement already satisfied: promise in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (4.21.12)\n",
            "Requirement already satisfied: psutil in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (5.9.0)\n",
            "Requirement already satisfied: pyarrow in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (20.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple_parsing in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (1.17.1)\n",
            "Requirement already satisfied: termcolor in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (3.1.0)\n",
            "Requirement already satisfied: toml in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: einops in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (0.8.1)\n",
            "Requirement already satisfied: typing_extensions in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (4.13.2)\n",
            "Requirement already satisfied: fsspec in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2025.5.1)\n",
            "Requirement already satisfied: importlib_resources in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets) (2025.4.26)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
            "Requirement already satisfied: six in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages (from simple_parsing->tensorflow-datasets) (0.16)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplot\n",
        "!pip install tensorflow \n",
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS (Reinforcement Learning Datasets) Tutorial\n",
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from typing import Dict, Any, List, Optional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python executable: /Users/edavio/anaconda3/envs/octo_clean/bin/python\n",
            "Python path: ['/Users/edavio/anaconda3/envs/octo_clean/lib/python310.zip', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/lib-dynload', '', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages', '/Users/edavio/anaconda3/envs/octo_clean/lib/python3.10/site-packages/rlds-0.1.8-py3.10.egg']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "print(\"Python path:\", sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export https_proxy=http://127.0.0.1:7890\n",
        "!export http_proxy=http://127.0.0.1:7890\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!curl www.google.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google-research/rlds.git#subdirectory=pip_package\n",
            "  Cloning https://github.com/google-research/rlds.git to /private/var/folders/vq/zr6yk0ls1xb_dr6w32zq2wmw0000gp/T/pip-req-build-4jy9skj0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/rlds.git /private/var/folders/vq/zr6yk0ls1xb_dr6w32zq2wmw0000gp/T/pip-req-build-4jy9skj0\n",
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip intall git+https://github.com/google-research/rlds.git#subdirectory=pip_package   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                      Version\n",
            "---------------------------- -----------\n",
            "absl-py                      2.3.0\n",
            "appnope                      0.1.4\n",
            "asttokens                    3.0.0\n",
            "astunparse                   1.6.3\n",
            "attrs                        25.3.0\n",
            "backports.tarfile            1.2.0\n",
            "certifi                      2025.4.26\n",
            "charset-normalizer           3.4.2\n",
            "comm                         0.2.2\n",
            "contourpy                    1.3.2\n",
            "cycler                       0.12.1\n",
            "debugpy                      1.8.11\n",
            "decorator                    5.2.1\n",
            "dm-env                       1.6\n",
            "dm-tree                      0.1.9\n",
            "docstring_parser             0.16\n",
            "docutils                     0.21.2\n",
            "einops                       0.8.1\n",
            "etils                        1.12.2\n",
            "exceptiongroup               1.3.0\n",
            "executing                    2.2.0\n",
            "flatbuffers                  25.2.10\n",
            "fonttools                    4.58.1\n",
            "fsspec                       2025.5.1\n",
            "gast                         0.6.0\n",
            "google-pasta                 0.2.0\n",
            "grpcio                       1.72.1\n",
            "grpcio-tools                 1.72.1\n",
            "h5py                         3.13.0\n",
            "id                           1.5.0\n",
            "idna                         3.10\n",
            "immutabledict                4.2.1\n",
            "importlib_metadata           8.7.0\n",
            "importlib_resources          6.5.2\n",
            "ipykernel                    6.29.5\n",
            "ipython                      8.18.1\n",
            "ipywidgets                   8.1.5\n",
            "jaraco.classes               3.4.0\n",
            "jaraco.context               6.0.1\n",
            "jaraco.functools             4.1.0\n",
            "jedi                         0.19.2\n",
            "jupyter_client               8.6.3\n",
            "jupyter_core                 5.8.1\n",
            "jupyterlab_widgets           3.0.13\n",
            "keras                        3.10.0\n",
            "keyring                      25.6.0\n",
            "kiwisolver                   1.4.8\n",
            "libclang                     18.1.1\n",
            "Markdown                     3.8\n",
            "markdown-it-py               3.0.0\n",
            "MarkupSafe                   3.0.2\n",
            "matplot                      0.1.9\n",
            "matplotlib                   3.10.3\n",
            "matplotlib-inline            0.1.7\n",
            "mdurl                        0.1.2\n",
            "ml_dtypes                    0.5.1\n",
            "more-itertools               10.7.0\n",
            "namex                        0.1.0\n",
            "nest_asyncio                 1.6.0\n",
            "nh3                          0.2.21\n",
            "numpy                        2.1.3\n",
            "opt_einsum                   3.4.0\n",
            "optree                       0.16.0\n",
            "packaging                    25.0\n",
            "parso                        0.8.4\n",
            "pexpect                      4.9.0\n",
            "pickleshare                  0.7.5\n",
            "pillow                       11.2.1\n",
            "pip                          25.1\n",
            "platformdirs                 4.3.8\n",
            "promise                      2.3\n",
            "prompt_toolkit               3.0.51\n",
            "protobuf                     6.31.1\n",
            "psutil                       5.9.0\n",
            "ptyprocess                   0.7.0\n",
            "pure_eval                    0.2.3\n",
            "pyarrow                      20.0.0\n",
            "Pygments                     2.19.1\n",
            "pyloco                       0.0.139\n",
            "pyparsing                    3.2.3\n",
            "python-dateutil              2.9.0.post0\n",
            "pyzmq                        26.2.0\n",
            "readme_renderer              44.0\n",
            "requests                     2.32.3\n",
            "requests-toolbelt            1.0.0\n",
            "rfc3986                      2.0.0\n",
            "rich                         14.0.0\n",
            "rlds                         0.1.8\n",
            "setuptools                   78.1.1\n",
            "simple-parsing               0.1.7\n",
            "SimpleWebSocketServer        0.1.2\n",
            "six                          1.17.0\n",
            "stack_data                   0.6.3\n",
            "tensorboard                  2.19.0\n",
            "tensorboard-data-server      0.7.2\n",
            "tensorflow                   2.19.0\n",
            "tensorflow-datasets          4.9.9\n",
            "tensorflow-io-gcs-filesystem 0.37.1\n",
            "tensorflow-metadata          1.17.1\n",
            "termcolor                    3.1.0\n",
            "toml                         0.10.2\n",
            "tornado                      6.5\n",
            "tqdm                         4.67.1\n",
            "traitlets                    5.14.3\n",
            "twine                        6.1.0\n",
            "typing                       3.7.4.3\n",
            "typing_extensions            4.13.2\n",
            "urllib3                      2.4.0\n",
            "ushlex                       0.99.1\n",
            "wcwidth                      0.2.13\n",
            "websocket-client             1.8.0\n",
            "Werkzeug                     3.1.3\n",
            "wheel                        0.45.1\n",
            "widgetsnbextension           4.0.13\n",
            "wrapt                        1.17.2\n",
            "zipp                         3.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rlds'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrlds\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rlds'"
          ]
        }
      ],
      "source": [
        "import rlds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RLDS modules not available. Install with: pip install rlds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Try to import RLDS specific modules\n",
        "try:\n",
        "    import rlds\n",
        "    import envlogger\n",
        "    print(\"RLDS modules imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"RLDS modules not available. Install with: pip install rlds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Configure TensorFlow\n",
        "tf.config.experimental.set_memory_growth(\n",
        "    tf.config.experimental.list_physical_devices('GPU')[0], True\n",
        ") if tf.config.experimental.list_physical_devices('GPU') else None\n",
        "\n",
        "print(\"Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLDS (Reinforcement Learning Datasets) ËØ¶Ëß£\n",
        "\n",
        "## Ê¶ÇËø∞\n",
        "\n",
        "RLDS (Reinforcement Learning Datasets) ÊòØGoogle DeepMindÂºÄÂèëÁöÑÁî®‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊ†áÂáÜÂåñÊï∞ÊçÆÈõÜÊ†ºÂºè„ÄÇÂÆÉÂü∫‰∫éTensorFlow Datasets (TFDS) ÊûÑÂª∫Ôºå‰∏ìÈó®ËÆæËÆ°Áî®‰∫éÂ≠òÂÇ®ÂíåÂ§ÑÁêÜÂº∫ÂåñÂ≠¶‰π†ËΩ®ËøπÊï∞ÊçÆÔºåÂåÖÊã¨Êú∫Âô®‰∫∫Â≠¶‰π†„ÄÅÊ∏∏ÊàèAIÁ≠âÂêÑÁßçÂ∫èÂàóÂÜ≥Á≠ñ‰ªªÂä°„ÄÇ\n",
        "\n",
        "**RLDSËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢òÔºö**\n",
        "- Áº∫‰πèÊ†áÂáÜÂåñÁöÑÂº∫ÂåñÂ≠¶‰π†Êï∞ÊçÆÈõÜÊ†ºÂºè\n",
        "- Êï∞ÊçÆÈõÜÊ†ºÂºè‰∏çÂÖºÂÆπÂØºËá¥ÁÆóÊ≥ïÊó†Ê≥ïÈáçÁî®\n",
        "- Êó∂Â∫è‰ø°ÊÅØ‰∏¢Â§±ÔºàÂ¶ÇÈöèÊú∫ÂåñÊ≠•È™§È°∫Â∫èÔºâ\n",
        "- Êï∞ÊçÆÂÖ±‰∫´Âõ∞Èöæ‰∏îÊòìÂºïÂÖ•bug\n",
        "\n",
        "**RLDSÁöÑÊ†∏ÂøÉ‰ª∑ÂÄºÔºö**\n",
        "- **Êó†ÊçüÊ†ºÂºè**Ôºö‰øùÁïôÊâÄÊúâ‰ø°ÊÅØÔºåÁª¥ÊåÅÊó∂Â∫èÂÖ≥Á≥ª\n",
        "- **ÁÆóÊ≥ïÊó†ÂÖ≥**ÔºöÊîØÊåÅ‰∏çÂêåÁÆóÊ≥ïÁöÑÊï∞ÊçÆÊ∂àË¥πÊ®°Âºè\n",
        "- **Ê†áÂáÜÂåñ**ÔºöÁªü‰∏ÄÁöÑÊï∞ÊçÆÁªìÊûÑÂíåËØ≠‰πâ\n",
        "- **ÁîüÊÄÅÁ≥ªÁªü**ÔºöÂÆåÊï¥ÁöÑÊï∞ÊçÆÁîü‰∫ß„ÄÅÂÖ±‰∫´„ÄÅÊ∂àË¥πÂ∑•ÂÖ∑Èìæ\n",
        "\n",
        "## RLDSÁîüÊÄÅÁ≥ªÁªüÊû∂ÊûÑ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 1\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**Ëá™‰∏äËÄå‰∏ãÁöÑÊµÅÁ®ãÂõæ**ÔºåÂ±ïÁ§∫‰∫ÜÁªÑ‰ª∂‰πãÈó¥ÁöÑÂ±ÇÊ¨°ÂÖ≥Á≥ªÂíåÊï∞ÊçÆÊµÅÂêë„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TB\n",
        "    subgraph Production[Êï∞ÊçÆÁîü‰∫ß]\n",
        "        A[EnvLogger - ÂêàÊàêÊï∞ÊçÆ] \n",
        "        B[RLDS Creator - ‰∫∫Á±ªÊï∞ÊçÆ]\n",
        "        C[Ëá™ÂÆö‰πâÁîü‰∫ßÂô®]\n",
        "    end\n",
        "    \n",
        "    subgraph Storage[Êï∞ÊçÆÂ≠òÂÇ®]\n",
        "        D[RLDSÊ†áÂáÜÊ†ºÂºè]\n",
        "        E[TFDSÈõÜÊàê]\n",
        "        F[ÁâàÊú¨ÊéßÂà∂]\n",
        "    end\n",
        "    \n",
        "    subgraph Processing[Êï∞ÊçÆÂ§ÑÁêÜ]\n",
        "        G[ÂèòÊç¢Â∫ì]\n",
        "        H[ÊâπÂ§ÑÁêÜ‰ºòÂåñ]\n",
        "        I[ÊÄßËÉΩ‰ºòÂåñ]\n",
        "    end\n",
        "    \n",
        "    subgraph Consumption[Êï∞ÊçÆÊ∂àË¥π]\n",
        "        J[EpisodeÁ∫ßÁÆóÊ≥ï]\n",
        "        K[StepÁ∫ßÁÆóÊ≥ï]\n",
        "        L[ÂàÜÊûêÂ∑•ÂÖ∑]\n",
        "    end\n",
        "    \n",
        "    Production --> Storage\n",
        "    Storage --> Processing  \n",
        "    Processing --> Consumption\n",
        "    \n",
        "    Storage -.-> M[TFDSÂÖ®Â±ÄÁõÆÂΩï]\n",
        "    M -.-> N[Á§æÂå∫ÂÖ±‰∫´]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSÊû∂ÊûÑÂõæ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 2\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**Ëá™‰∏äËÄå‰∏ãÁöÑÊµÅÁ®ãÂõæ**ÔºåÂ±ïÁ§∫‰∫ÜÁªÑ‰ª∂‰πãÈó¥ÁöÑÂ±ÇÊ¨°ÂÖ≥Á≥ªÂíåÊï∞ÊçÆÊµÅÂêë„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[RLDS Dataset] --> B[Episode Collection]\n",
        "    B --> C[Individual Episodes]\n",
        "    C --> D[Steps Sequence]\n",
        "    \n",
        "    D --> E[Observation]\n",
        "    D --> F[Action]\n",
        "    D --> G[Reward]\n",
        "    D --> H[Discount]\n",
        "    D --> I[Metadata]\n",
        "    \n",
        "    E --> E1[Images]\n",
        "    E --> E2[Proprio State]\n",
        "    E --> E3[Task Info]\n",
        "    \n",
        "    F --> F1[Joint Commands]\n",
        "    F --> F2[End-effector Pose]\n",
        "    F --> F3[Gripper Commands]\n",
        "    \n",
        "    subgraph Types[Êï∞ÊçÆÁ±ªÂûã]\n",
        "        J[\"tf.string - ÂéãÁº©ÂõæÂÉè\"]\n",
        "        K[\"tf.float32 - ËøûÁª≠ÂÄº\"]\n",
        "        L[\"tf.int32 - Á¶ªÊï£ÂÄº\"]\n",
        "        M[\"tf.bool - Â∏ÉÂ∞îÂÄº\"]\n",
        "    end\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSÊï∞ÊçÆÁªìÊûÑÂ±ÇÊ¨°\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 3\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**ÊµÅÁ®ãÂõæ**ÔºåÊèèËø∞‰∫ÜÂ§ÑÁêÜÊ≠•È™§ÂíåÂÜ≥Á≠ñÊµÅÁ®ã„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Dataset] --> B[Episodes]\n",
        "    B --> C[Steps]\n",
        "    C --> D[Fields]\n",
        "    \n",
        "    subgraph Episode[EpisodeÁ∫ßÂà´]\n",
        "        E1[episode_id]\n",
        "        E2[episode_metadata]\n",
        "        E3[stepsÈõÜÂêà]\n",
        "    end\n",
        "    \n",
        "    subgraph Step[StepÁ∫ßÂà´]\n",
        "        S1[observation]\n",
        "        S2[action]\n",
        "        S3[reward]\n",
        "        S4[discount]\n",
        "        S5[is_first]\n",
        "        S6[is_last]\n",
        "        S7[is_terminal]\n",
        "    end\n",
        "    \n",
        "    B -.-> Episode\n",
        "    C -.-> Step\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Ê†∏ÂøÉÊï∞ÊçÆÁªìÊûÑ\n",
        "\n",
        "### Episode ÁªìÊûÑ\n",
        "| Â≠óÊÆµÂêç | Á±ªÂûã | ÊèèËø∞ | Á§∫‰æã |\n",
        "|--------|------|------|------|\n",
        "| `episode_id` | `tf.string` | ÂîØ‰∏ÄÊ†áËØÜÁ¨¶ | `\"episode_001\"` |\n",
        "| `episode_metadata` | `dict` | ÂÖÉÊï∞ÊçÆ‰ø°ÊÅØ | `{\"task\": \"pick_cup\", \"success\": True}` |\n",
        "| `steps` | `Sequence[Step]` | Ê≠•È™§Â∫èÂàó | `[step_0, step_1, ..., step_n]` |\n",
        "\n",
        "### Step ÁªìÊûÑ\n",
        "| Â≠óÊÆµÂêç | Á±ªÂûã | ÂΩ¢Áä∂ | ÊèèËø∞ |\n",
        "|--------|------|------|------|\n",
        "| `observation` | `dict` | ÂèØÂèò | ËßÇÊµãÊï∞ÊçÆÂ≠óÂÖ∏ |\n",
        "| `action` | `tf.float32` | `[action_dim]` | Âä®‰ΩúÂêëÈáè |\n",
        "| `reward` | `tf.float32` | `[]` | Â•ñÂä±ÂÄº |\n",
        "| `discount` | `tf.float32` | `[]` | ÊäòÊâ£Âõ†Â≠ê |\n",
        "| `is_first` | `tf.bool` | `[]` | ÊòØÂê¶‰∏∫È¶ñÊ≠• |\n",
        "| `is_last` | `tf.bool` | `[]` | ÊòØÂê¶‰∏∫Êú´Ê≠• |\n",
        "| `is_terminal` | `tf.bool` | `[]` | ÊòØÂê¶ÁªàÊ≠¢ |\n",
        "\n",
        "### Observation ÁªìÊûÑÁ§∫‰æã\n",
        "| ËßÇÊµãÁ±ªÂûã | Â≠óÊÆµÂêç | Á±ªÂûã | ÂΩ¢Áä∂ | ÊèèËø∞ |\n",
        "|----------|--------|------|------|------|\n",
        "| ÂõæÂÉè | `image_primary` | `tf.string` | `[]` | ‰∏ªÊëÑÂÉèÂ§¥ÂõæÂÉè(JPEGÁºñÁ†Å) |\n",
        "| ÂõæÂÉè | `image_wrist` | `tf.string` | `[]` | ÊâãËÖïÊëÑÂÉèÂ§¥ÂõæÂÉè |\n",
        "| ÂõæÂÉè | `image_side` | `tf.string` | `[]` | ‰æßËßÜÂõæÂÉè |\n",
        "| Ê∑±Â∫¶ | `depth_primary` | `tf.string` | `[]` | Ê∑±Â∫¶ÂõæÂÉè |\n",
        "| Áä∂ÊÄÅ | `joint_positions` | `tf.float32` | `[7]` | ÂÖ≥ËäÇ‰ΩçÁΩÆ |\n",
        "| Áä∂ÊÄÅ | `joint_velocities` | `tf.float32` | `[7]` | ÂÖ≥ËäÇÈÄüÂ∫¶ |\n",
        "| Áä∂ÊÄÅ | `end_effector_pose` | `tf.float32` | `[7]` | Êú´Á´ØÊâßË°åÂô®‰ΩçÂßø |\n",
        "| Áä∂ÊÄÅ | `gripper_state` | `tf.float32` | `[1]` | Â§πÁà™Áä∂ÊÄÅ |\n",
        "| ‰ªªÂä° | `task_description` | `tf.string` | `[]` | ‰ªªÂä°ÊèèËø∞ |\n",
        "| ‰ªªÂä° | `goal_image` | `tf.string` | `[]` | ÁõÆÊ†áÂõæÂÉè |\n",
        "\n",
        "## Á§∫‰æãÊï∞ÊçÆÈõÜÊûÑÂª∫\n",
        "\n",
        "### Êï∞ÊçÆÈõÜÈÖçÁΩÆ‰ø°ÊÅØ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 4\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**Á±ªÂÖ≥Á≥ªÂõæ**ÔºåÊòæÁ§∫‰∫Ü‰∏çÂêåÁ±ª‰πãÈó¥ÁöÑÁªßÊâøÂíåÂÖ≥ËÅîÂÖ≥Á≥ª„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "classDiagram\n",
        "    class DatasetConfig {\n",
        "        +string name\n",
        "        +string version\n",
        "        +string description\n",
        "        +dict features\n",
        "        +dict splits\n",
        "        +int total_episodes\n",
        "        +int total_steps\n",
        "    }\n",
        "    \n",
        "    class FeatureConfig {\n",
        "        +dict observation_space\n",
        "        +dict action_space\n",
        "        +float reward_range\n",
        "        +string task_type\n",
        "    }\n",
        "    \n",
        "    class SplitConfig {\n",
        "        +float train_ratio\n",
        "        +float val_ratio\n",
        "        +float test_ratio\n",
        "        +int train_episodes\n",
        "        +int val_episodes\n",
        "        +int test_episodes\n",
        "    }\n",
        "    \n",
        "    DatasetConfig --> FeatureConfig : contains\n",
        "    DatasetConfig --> SplitConfig : contains\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Á§∫‰æãÔºöÊäìÂèñ‰ªªÂä°Êï∞ÊçÆÈõÜ\n",
        "\n",
        "#### Êï∞ÊçÆÈõÜÂÖÉ‰ø°ÊÅØ\n",
        "| Â±ûÊÄß | ÂÄº |\n",
        "|------|-----|\n",
        "| Êï∞ÊçÆÈõÜÂêçÁß∞ | `robot_pick_place_v1` |\n",
        "| ÁâàÊú¨ | `1.0.0` |\n",
        "| ‰ªªÂä°Á±ªÂûã | `Pick and Place` |\n",
        "| Êú∫Âô®‰∫∫Âπ≥Âè∞ | `Franka Panda` |\n",
        "| ÊÄªepisodeÊï∞ | `10,000` |\n",
        "| ÊÄªÊ≠•Êï∞ | `500,000` |\n",
        "| Âπ≥ÂùáepisodeÈïøÂ∫¶ | `50 steps` |\n",
        "\n",
        "#### EpisodeÁ§∫‰æãÊï∞ÊçÆ\n",
        "\n",
        "**Episode 1 ÂÖÉÊï∞ÊçÆ**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\n",
        "{\n",
        "    \"episode_id\": \"episode_0001\",\n",
        "    \"task_type\": \"pick_red_cube\",\n",
        "    \"success\": true,\n",
        "    \"duration_seconds\": 12.5,\n",
        "    \"robot_id\": \"franka_001\",\n",
        "    \"scene_id\": \"kitchen_table_01\",\n",
        "    \"difficulty\": \"easy\",\n",
        "    \"annotations\": {\n",
        "        \"pick_frame\": 15,\n",
        "        \"place_frame\": 42,\n",
        "        \"contact_frames\": [16, 43]\n",
        "    }\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### StepÊï∞ÊçÆÁªìÊûÑËØ¶Ëß£\n",
        "\n",
        "**Step 0 (ÂàùÂßãÁä∂ÊÄÅ)**\n",
        "| Â≠óÊÆµ | ÂÄº | ËØ¥Êòé |\n",
        "|------|-----|------|\n",
        "| `is_first` | `True` | ËΩ®ËøπÂºÄÂßã |\n",
        "| `is_last` | `False` | ÈùûÁªìÊùüÊ≠• |\n",
        "| `is_terminal` | `False` | ÈùûÁªàÊ≠¢Ê≠• |\n",
        "| `reward` | `0.0` | ÂàùÂßãÂ•ñÂä± |\n",
        "| `discount` | `1.0` | Ê†áÂáÜÊäòÊâ£ |\n",
        "\n",
        "**ËßÇÊµãÊï∞ÊçÆ (Step 0)**\n",
        "| ËßÇÊµãÈ°π | Êï∞ÊçÆÁ±ªÂûã | ÂΩ¢Áä∂ | Á§∫‰æãÂÄº/ÊèèËø∞ |\n",
        "|--------|----------|------|-------------|\n",
        "| `image_primary` | `tf.string` | `[]` | JPEGÁºñÁ†ÅÁöÑRGBÂõæÂÉè (480√ó640√ó3) |\n",
        "| `image_wrist` | `tf.string` | `[]` | JPEGÁºñÁ†ÅÁöÑÊâãËÖïÁõ∏Êú∫ÂõæÂÉè (240√ó320√ó3) |\n",
        "| `depth_primary` | `tf.string` | `[]` | ÂéãÁº©ÁöÑÊ∑±Â∫¶Âõæ (480√ó640√ó1) |\n",
        "| `joint_positions` | `tf.float32` | `[7]` | `[0.0, -0.785, 0.0, -2.356, 0.0, 1.571, 0.785]` |\n",
        "| `joint_velocities` | `tf.float32` | `[7]` | `[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]` |\n",
        "| `end_effector_pose` | `tf.float32` | `[7]` | `[0.5, 0.0, 0.3, 0.0, 0.0, 0.0, 1.0]` (‰ΩçÁΩÆ+ÂõõÂÖÉÊï∞) |\n",
        "| `gripper_state` | `tf.float32` | `[1]` | `[0.08]` (ÂºÄÂêØÁä∂ÊÄÅ) |\n",
        "| `task_description` | `tf.string` | `[]` | `\"Pick up the red cube and place it in the box\"` |\n",
        "\n",
        "**Âä®‰ΩúÊï∞ÊçÆ (Step 0‚Üí1)**\n",
        "| Âä®‰ΩúÁª¥Â∫¶ | ÂÄº | ËØ¥Êòé |\n",
        "|----------|-----|------|\n",
        "| `delta_pos_x` | `0.02` | XËΩ¥‰ΩçÁßª (m) |\n",
        "| `delta_pos_y` | `0.01` | YËΩ¥‰ΩçÁßª (m) |\n",
        "| `delta_pos_z` | `-0.005` | ZËΩ¥‰ΩçÁßª (m) |\n",
        "| `delta_rot_x` | `0.0` | XËΩ¥ÊóãËΩ¨ (rad) |\n",
        "| `delta_rot_y` | `0.0` | YËΩ¥ÊóãËΩ¨ (rad) |\n",
        "| `delta_rot_z` | `0.1` | ZËΩ¥ÊóãËΩ¨ (rad) |\n",
        "| `gripper_cmd` | `0.0` | Â§πÁà™ÂëΩ‰ª§ (‰øùÊåÅÂºÄÂêØ) |\n",
        "\n",
        "## Êï∞ÊçÆÂ§ÑÁêÜÊµÅÊ∞¥Á∫ø\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 5\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**ÊµÅÁ®ãÂõæ**ÔºåÊèèËø∞‰∫ÜÂ§ÑÁêÜÊ≠•È™§ÂíåÂÜ≥Á≠ñÊµÅÁ®ã„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart TD\n",
        "    A[ÂéüÂßã‰º†ÊÑüÂô®Êï∞ÊçÆ] --> B[Êï∞ÊçÆÈááÈõÜ]\n",
        "    B --> C[Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ]\n",
        "    C --> D[RLDSÊ†ºÂºèËΩ¨Êç¢]\n",
        "    D --> E[Ë¥®ÈáèÊ£ÄÊü•]\n",
        "    E --> F[Êï∞ÊçÆÈõÜÊûÑÂª∫]\n",
        "    \n",
        "    subgraph Preprocess[Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ]\n",
        "        C1[ÂõæÂÉèÂéãÁº©]\n",
        "        C2[ÂùêÊ†áÁ≥ªÂØπÈΩê]\n",
        "        C3[Êó∂Èó¥Êà≥ÂêåÊ≠•]\n",
        "        C4[ÂºÇÂ∏∏ÂÄºËøáÊª§]\n",
        "    end\n",
        "    \n",
        "    subgraph Quality[Ë¥®ÈáèÊ£ÄÊü•]\n",
        "        E1[ËΩ®ËøπÂÆåÊï¥ÊÄß]\n",
        "        E2[Êï∞ÊçÆ‰∏ÄËá¥ÊÄß]\n",
        "        E3[ÊàêÂäüÁéáÁªüËÆ°]\n",
        "        E4[ÂºÇÂ∏∏Ê£ÄÊµã]\n",
        "    end\n",
        "    \n",
        "    C -.-> Preprocess\n",
        "    E -.-> Quality\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Êï∞ÊçÆÂä†ËΩΩÁ§∫‰æã\n",
        "\n",
        "### Python‰ª£Á†ÅÁ§∫‰æã\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
        "ds_builder = tfds.builder('robot_pick_place_v1', data_dir='/path/to/data')\n",
        "ds = ds_builder.as_dataset(split='train', shuffle_files=True)\n",
        "\n",
        "# Ê£ÄÊü•Êï∞ÊçÆÁªìÊûÑ\n",
        "print(\"Dataset info:\")\n",
        "print(ds_builder.info)\n",
        "\n",
        "# ÈÅçÂéÜepisodes\n",
        "for episode in ds.take(1):\n",
        "    print(f\"Episode ID: {episode['episode_id']}\")\n",
        "    print(f\"Episode steps: {len(episode['steps'])}\")\n",
        "    \n",
        "    # Êü•ÁúãÁ¨¨‰∏ÄÊ≠•\n",
        "    first_step = episode['steps'][0]\n",
        "    print(f\"First step observation keys: {first_step['observation'].keys()}\")\n",
        "    print(f\"Action shape: {first_step['action'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Êï∞ÊçÆÁªüËÆ°‰ø°ÊÅØ\n",
        "\n",
        "#### Êï∞ÊçÆÈõÜÂàÜÂâ≤\n",
        "| ÂàÜÂâ≤ | EpisodeÊï∞ | Ê≠•Êï∞ | ÊàêÂäüÁéá | Âπ≥ÂùáÈïøÂ∫¶ |\n",
        "|------|-----------|------|--------|----------|\n",
        "| Train | 8,000 | 400,000 | 85% | 50 steps |\n",
        "| Validation | 1,000 | 50,000 | 83% | 50 steps |\n",
        "| Test | 1,000 | 50,000 | 82% | 50 steps |\n",
        "\n",
        "#### Âä®‰ΩúÁªüËÆ°\n",
        "| Âä®‰ΩúÁª¥Â∫¶ | ÊúÄÂ∞èÂÄº | ÊúÄÂ§ßÂÄº | ÂùáÂÄº | Ê†áÂáÜÂ∑Æ |\n",
        "|----------|--------|--------|------|--------|\n",
        "| `delta_pos_x` | -0.05 | 0.05 | 0.001 | 0.012 |\n",
        "| `delta_pos_y` | -0.05 | 0.05 | -0.002 | 0.015 |\n",
        "| `delta_pos_z` | -0.05 | 0.05 | 0.000 | 0.008 |\n",
        "| `delta_rot_x` | -0.2 | 0.2 | 0.003 | 0.045 |\n",
        "| `delta_rot_y` | -0.2 | 0.2 | -0.001 | 0.038 |\n",
        "| `delta_rot_z` | -0.2 | 0.2 | 0.005 | 0.052 |\n",
        "| `gripper_cmd` | -1.0 | 1.0 | 0.12 | 0.68 |\n",
        "\n",
        "## ‰∏éÂÖ∂‰ªñÊ†ºÂºèÂØπÊØî\n",
        "\n",
        "### Êï∞ÊçÆÊ†ºÂºèÂØπÊØîË°®\n",
        "| ÁâπÊÄß | RLDS | HDF5 | ROS Bag | OpenAI Gym |\n",
        "|------|------|------|---------|------------|\n",
        "| Ê†áÂáÜÂåñÁ®ãÂ∫¶ | È´ò | ‰∏≠ | ‰Ωé | ‰∏≠ |\n",
        "| ÂÖÉÊï∞ÊçÆÊîØÊåÅ | ‰ºòÁßÄ | ËâØÂ•Ω | ‰ºòÁßÄ | Âü∫Á°Ä |\n",
        "| ÂéãÁº©ÊïàÁéá | È´ò | È´ò | ‰∏≠ | ‰Ωé |\n",
        "| Êü•ËØ¢ÊÄßËÉΩ | ‰ºòÁßÄ | ËâØÂ•Ω | Â∑Æ | ËâØÂ•Ω |\n",
        "| ÁîüÊÄÅÁ≥ªÁªü | TF/JAX | ÈÄöÁî® | ROS | RLÁ§æÂå∫ |\n",
        "| ÁâàÊú¨ÊéßÂà∂ | ÊîØÊåÅ | ÊúâÈôê | Êó† | Êó† |\n",
        "| ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉ | ÂéüÁîüÊîØÊåÅ | ÈúÄË¶ÅÈ¢ùÂ§ñÂ∑•ÂÖ∑ | Â§çÊùÇ | Â§çÊùÇ |\n",
        "\n",
        "## ÊúÄ‰Ω≥ÂÆûË∑µ\n",
        "\n",
        "### Êï∞ÊçÆÁªÑÁªáÂª∫ËÆÆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Êû∂ÊûÑÂõæ 6\n",
        "\n",
        "> **VSCode Áî®Êà∑Ê≥®ÊÑè**: Ë¶ÅÊü•Áúã‰∏ãÊñπÁöÑ Mermaid ÂõæË°®ÔºåËØ∑Ôºö\n",
        "> \n",
        "> 1. **Êé®Ëçê**: ÂÆâË£Ö VSCode Êâ©Â±ï `Mermaid Preview` (ID: `bierner.markdown-mermaid`)\n",
        "> 2. **‰∏¥Êó∂ÊñπÊ°à**: Â§çÂà∂‰∏ãÊñπ‰ª£Á†ÅÂà∞ https://mermaid.live/ Âú®Á∫øÊü•Áúã\n",
        "> 3. **Êõø‰ª£ÊñπÊ°à**: Êü•ÁúãÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "#### üìù ÊñáÂ≠óÁâàÊû∂ÊûÑËØ¥Êòé\n",
        "\n",
        "ËøôÊòØ‰∏Ä‰∏™**Ëá™‰∏äËÄå‰∏ãÁöÑÊµÅÁ®ãÂõæ**ÔºåÂ±ïÁ§∫‰∫ÜÁªÑ‰ª∂‰πãÈó¥ÁöÑÂ±ÇÊ¨°ÂÖ≥Á≥ªÂíåÊï∞ÊçÆÊµÅÂêë„ÄÇ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[Êï∞ÊçÆÈõÜÊ†πÁõÆÂΩï] --> B[Êï∞ÊçÆÊñá‰ª∂]\n",
        "    A --> C[ÂÖÉÊï∞ÊçÆ]\n",
        "    A --> D[ÈÖçÁΩÆÊñá‰ª∂]\n",
        "    A --> E[ÊñáÊ°£]\n",
        "    \n",
        "    B --> B1[\"train/\"]\n",
        "    B --> B2[\"validation/\"]\n",
        "    B --> B3[\"test/\"]\n",
        "    \n",
        "    C --> C1[\"dataset_info.json\"]\n",
        "    C --> C2[\"statistics.json\"]\n",
        "    C --> C3[\"features.json\"]\n",
        "    \n",
        "    D --> D1[\"builder_config.py\"]\n",
        "    D --> D2[\"preprocessing.py\"]\n",
        "    \n",
        "    E --> E1[\"README.md\"]\n",
        "    E --> E2[\"LICENSE\"]\n",
        "    E --> E3[\"CHANGELOG.md\"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Êï∞ÊçÆË¥®ÈáèÊ£ÄÊü•Ê∏ÖÂçï\n",
        "| Ê£ÄÊü•È°π | ÈáçË¶ÅÊÄß | ÊèèËø∞ |\n",
        "|--------|--------|------|\n",
        "| ËΩ®ËøπÂÆåÊï¥ÊÄß | È´ò | Á°Æ‰øùÊØè‰∏™episodeÈÉΩÊúâÂÆåÊï¥ÁöÑÂºÄÂßãÂíåÁªìÊùü |\n",
        "| Êó∂Èó¥‰∏ÄËá¥ÊÄß | È´ò | Ê£ÄÊü•Êó∂Èó¥Êà≥ÁöÑÂçïË∞ÉÊÄßÂíåÂêàÁêÜÊÄß |\n",
        "| Âä®‰ΩúÂêàÁêÜÊÄß | È´ò | È™åËØÅÂä®‰ΩúÂú®Áâ©ÁêÜÁ∫¶ÊùüËåÉÂõ¥ÂÜÖ |\n",
        "| ÂõæÂÉèË¥®Èáè | ‰∏≠ | Ê£ÄÊü•ÂõæÂÉèÊòØÂê¶Ê∏ÖÊô∞„ÄÅÊó†ÊçüÂùè |\n",
        "| Ê†áÊ≥®ÂáÜÁ°ÆÊÄß | È´ò | È™åËØÅÊàêÂäü/Â§±Ë¥•Ê†áÊ≥®ÁöÑÂáÜÁ°ÆÊÄß |\n",
        "| Êï∞ÊçÆÂπ≥Ë°°ÊÄß | ‰∏≠ | Á°Æ‰øù‰∏çÂêå‰ªªÂä°Âú∫ÊôØÁöÑÂπ≥Ë°°ÂàÜÂ∏É |\n",
        "\n",
        "## Êâ©Â±ïÂíåÂÆöÂà∂\n",
        "\n",
        "### Ëá™ÂÆö‰πâËßÇÊµãÁ©∫Èó¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ê∑ªÂä†Ëá™ÂÆö‰πâËßÇÊµã\n",
        "custom_observation_spec = {\n",
        "    'image_overhead': tfds.features.Image(shape=(480, 640, 3)),\n",
        "    'force_torque': tfds.features.Tensor(shape=(6,), dtype=tf.float32),\n",
        "    'tactile_sensor': tfds.features.Tensor(shape=(16,), dtype=tf.float32),\n",
        "    'audio_data': tfds.features.Audio(sample_rate=16000),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ‰ªªÂä°ÁâπÂÆöÂ≠óÊÆµ\n",
        "| ‰ªªÂä°Á±ªÂûã | ÁâπÂÆöÂ≠óÊÆµ | Á±ªÂûã | ÊèèËø∞ |\n",
        "|----------|----------|------|------|\n",
        "| ÊäìÂèñ‰ªªÂä° | `grasp_success` | `tf.bool` | ÊäìÂèñÊòØÂê¶ÊàêÂäü |\n",
        "| ÂØºËà™‰ªªÂä° | `collision_detected` | `tf.bool` | ÊòØÂê¶ÂèëÁîüÁ¢∞Êíû |\n",
        "| Êìç‰Ωú‰ªªÂä° | `contact_forces` | `tf.float32[6]` | Êé•Ëß¶Âäõ‰ø°ÊÅØ |\n",
        "| Â≠¶‰π†‰ªªÂä° | `demonstration_id` | `tf.string` | Á§∫ÊïôID |\n",
        "\n",
        "## RLDSÊ†∏ÂøÉÁªÑ‰ª∂ËØ¶Ëß£\n",
        "\n",
        "### 1. EnvLogger - ÂêàÊàêÊï∞ÊçÆÊî∂ÈõÜ\n",
        "\n",
        "EnvLoggerÊòØdm_envÁéØÂ¢ÉÂåÖË£ÖÂô®ÔºåÁî®‰∫éËÆ∞ÂΩïÊô∫ËÉΩ‰Ωì‰∏éÁéØÂ¢ÉÁöÑ‰∫§‰∫íÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import envlogger\n",
        "\n",
        "# Âü∫Êú¨Áî®Ê≥ï\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset'\n",
        ")\n",
        "\n",
        "# È´òÁ∫ßÁî®Ê≥ï - Ê∑ªÂä†ÂÖÉÊï∞ÊçÆÂõûË∞É\n",
        "def step_metadata_fn(timestep, action, env):\n",
        "    return {\n",
        "        'custom_reward': compute_custom_reward(timestep),\n",
        "        'difficulty': env.get_difficulty()\n",
        "    }\n",
        "\n",
        "def episode_metadata_fn(env):\n",
        "    return {\n",
        "        'success': env.is_success(),\n",
        "        'episode_length': env.step_count()\n",
        "    }\n",
        "\n",
        "env = envlogger.EnvLogger(\n",
        "    environment=base_env,\n",
        "    data_directory='/tmp/my_dataset',\n",
        "    step_metadata_fn=step_metadata_fn,\n",
        "    episode_metadata_fn=episode_metadata_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**EnvLoggerÊï∞ÊçÆÊµÅ**Ôºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ÁîüÊàê: (o_0, _, _, _, m_0) ‚Üí (o_1, a_0, r_0, d_0, m_1) ‚Üí (o_2, a_1, r_1, d_1, m_2)\n",
        "Â≠òÂÇ®: (o_0, a_0, r_0, d_0, m_0) ‚Üí (o_1, a_1, r_1, d_1, m_1) ‚Üí (o_2, a_2, r_2, d_2, m_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. RLDS Creator - ‰∫∫Á±ªÊï∞ÊçÆÊî∂ÈõÜ\n",
        "\n",
        "Âü∫‰∫éWebÁöÑÂ∑•ÂÖ∑ÔºåÂÖÅËÆ∏‰∫∫Á±ªÈÄöËøáÊµèËßàÂô®‰∏éÁéØÂ¢É‰∫§‰∫íÔºö\n",
        "\n",
        "**ÁâπÊÄßÔºö**\n",
        "- Ë∑®Âπ≥Âè∞WebÁïåÈù¢\n",
        "- ÂÆûÊó∂Êï∞ÊçÆËÆ∞ÂΩï\n",
        "- ÊîØÊåÅÂ§öÁßçËæìÂÖ•ËÆæÂ§á\n",
        "- ‰ºóÂåÖÊï∞ÊçÆÊî∂ÈõÜÊîØÊåÅ\n",
        "\n",
        "### 3. TFDSÈõÜÊàê\n",
        "\n",
        "#### Êï∞ÊçÆÈõÜÂä†ËΩΩÊñπÂºè\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# ÊñπÂºè1: ‰ªéÁõÆÂΩïÂä†ËΩΩ\n",
        "ds = tfds.builder_from_directory('/path/to/dataset').as_dataset(split='all')\n",
        "\n",
        "# ÊñπÂºè2: ‰ªéÂ§ö‰∏™ÁõÆÂΩïÂä†ËΩΩ\n",
        "ds = tfds.builder_from_directories(['/path1', '/path2']).as_dataset(split='all')\n",
        "\n",
        "# ÊñπÂºè3: ‰ªéTFDSÁõÆÂΩïÂä†ËΩΩ\n",
        "ds = tfds.load('d4rl_mujoco_halfcheetah/v0-medium')['train']\n",
        "\n",
        "# ÊñπÂºè4: ÊâπÈáèÂä†ËΩΩ(ÈùûÂµåÂ•óÊ†ºÂºè)\n",
        "ds = tfds.load('dataset_name', \n",
        "               decoders={rlds.STEPS: tfds.decode.SkipDecoding()},\n",
        "               split='train')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSÂØπTFDSÁöÑÈù©ÂëΩÊÄßÊâ©Â±ï\n",
        "\n",
        "RLDS‰∏ç‰ªÖÊòØTFDSÁöÑÁÆÄÂçïÁî®Êà∑ÔºåËÄåÊòØÂØπTFDSËøõË°å‰∫ÜÊ∑±Â∫¶Êâ©Â±ïÂíåÊîπËøõÔºå‰∏ìÈó®ÈíàÂØπÂº∫ÂåñÂ≠¶‰π†Êï∞ÊçÆÁöÑÁâπÊÆäÈúÄÊ±Ç„ÄÇ‰ª•‰∏ãÊòØRLDSÂú®TFDSÂü∫Á°Ä‰∏äÂÅöÂá∫ÁöÑÂÖ≥ÈîÆÂàõÊñ∞ÂíåÊîπËøõÔºö\n",
        "\n",
        "### 1. ÂµåÂ•óÊï∞ÊçÆÈõÜÁªìÊûÑÊîØÊåÅ\n",
        "\n",
        "#### ‰º†ÁªüTFDSÁöÑÂ±ÄÈôêÊÄß\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‰º†ÁªüTFDS - ÊâÅÂπ≥ÂåñÊï∞ÊçÆÁªìÊûÑ\n",
        "traditional_sample = {\n",
        "    'image': tf.Tensor(...),\n",
        "    'label': tf.Tensor(...),\n",
        "    'metadata': tf.Tensor(...)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### RLDSÁöÑÂµåÂ•óÊï∞ÊçÆÈõÜÂàõÊñ∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RLDS - ÂµåÂ•óÊï∞ÊçÆÈõÜÁªìÊûÑ\n",
        "rlds_episode = {\n",
        "    'episode_id': tf.string,\n",
        "    'episode_metadata': {\n",
        "        'success': tf.bool,\n",
        "        'task_id': tf.string,\n",
        "        'collector_id': tf.string\n",
        "    },\n",
        "    'steps': tf.data.Dataset.from_generator(...)  # ÂµåÂ•óÊï∞ÊçÆÈõÜÔºÅ\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Ê†∏ÂøÉÂàõÊñ∞ÁÇπÔºö**\n",
        "- **ÂµåÂ•ótf.data.Dataset**ÔºöRLDSÂú®TFDS‰∏≠È¶ñÊ¨°ÂÆûÁé∞‰∫ÜÊï∞ÊçÆÈõÜÂÜÖÂµåÂ•óÊï∞ÊçÆÈõÜÁöÑÊîØÊåÅ\n",
        "- **Êó∂Â∫èÊï∞ÊçÆ‰øùÊä§**ÔºöÁ°Æ‰øùepisodeÂÜÖÊ≠•È™§ÁöÑÊó∂Â∫èÂÖ≥Á≥ª‰∏çË¢´Á†¥Âùè\n",
        "- **Âä®ÊÄÅÈïøÂ∫¶ÊîØÊåÅ**ÔºöÊØè‰∏™episodeÂèØ‰ª•Êúâ‰∏çÂêåÁöÑÊ≠•Êï∞\n",
        "\n",
        "### 2. ‰∏ìÁî®ÁöÑRLDS BuilderÂü∫Á±ª\n",
        "\n",
        "RLDSÊâ©Â±ï‰∫ÜTFDSÁöÑBuilderÊû∂ÊûÑÔºåÊèê‰æõ‰∫Ü‰∏ìÈó®ÁöÑÂü∫Á±ªÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import rlds\n",
        "\n",
        "class RoboticDatasetBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"RLDS‰∏ìÁî®ÁöÑÊï∞ÊçÆÈõÜÊûÑÂª∫Âô®\"\"\"\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"RLDS compliant robotic dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                # EpisodeÁ∫ßÂÖÉÊï∞ÊçÆ\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'episode_metadata': tfds.features.FeaturesDict({\n",
        "                    'success': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'task': tfds.features.Text(),\n",
        "                    'total_reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                }),\n",
        "                \n",
        "                # Ê†∏ÂøÉÂàõÊñ∞ÔºöÂµåÂ•óÊï∞ÊçÆÈõÜÁªìÊûÑ\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    # StepÁ∫ßÊï∞ÊçÆÁªìÊûÑ\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        # ÊîØÊåÅÂ§öÊ®°ÊÄÅËßÇÊµã\n",
        "                        'image_primary': tfds.features.Image(shape=(224, 224, 3)),\n",
        "                        'image_wrist': tfds.features.Image(shape=(128, 128, 3)),\n",
        "                        'depth': tfds.features.Tensor(shape=(224, 224, 1), dtype=tf.float32),\n",
        "                        'proprioception': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                        'gripper_state': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(7,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    \n",
        "                    # RLDSÊ†áÂáÜÂ≠óÊÆµ\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    \n",
        "                    # ÂèØÊâ©Â±ïÁöÑÂÖÉÊï∞ÊçÆ\n",
        "                    'step_metadata': tfds.features.FeaturesDict({\n",
        "                        'timestamp': tfds.features.Scalar(dtype=tf.float64),\n",
        "                        'control_frequency': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    }),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,  # RLÊï∞ÊçÆÊ≤°ÊúâÁõëÁù£Â≠¶‰π†ÁöÑÈîÆ\n",
        "            homepage='https://robotics-dataset.example.com',\n",
        "            citation=BIBTEX_CITATION,\n",
        "        )\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"ÁîüÊàêRLDSÂÖºÂÆπÁöÑÊ†∑Êú¨\"\"\"\n",
        "        for episode_idx, episode_data in enumerate(self._load_episodes(data_path)):\n",
        "            # ÊûÑÂª∫Ê≠•È™§Â∫èÂàó\n",
        "            steps = []\n",
        "            for step_idx, step_data in enumerate(episode_data['trajectory']):\n",
        "                step = {\n",
        "                    'observation': {\n",
        "                        'image_primary': step_data['cam_primary'],\n",
        "                        'image_wrist': step_data['cam_wrist'],\n",
        "                        'depth': step_data['depth_map'],\n",
        "                        'proprioception': step_data['joint_positions'],\n",
        "                        'gripper_state': step_data['gripper_pos'],\n",
        "                    },\n",
        "                    'action': step_data['action'],\n",
        "                    'reward': step_data['reward'],\n",
        "                    'discount': step_data.get('discount', 1.0),\n",
        "                    'is_first': step_idx == 0,\n",
        "                    'is_last': step_idx == len(episode_data['trajectory']) - 1,\n",
        "                    'is_terminal': step_data.get('terminal', False),\n",
        "                    'step_metadata': {\n",
        "                        'timestamp': step_data['timestamp'],\n",
        "                        'control_frequency': step_data['freq'],\n",
        "                    }\n",
        "                }\n",
        "                steps.append(step)\n",
        "            \n",
        "            # ÊûÑÂª∫ÂÆåÊï¥episode\n",
        "            episode = {\n",
        "                'episode_id': f\"episode_{episode_idx:06d}\",\n",
        "                'episode_metadata': {\n",
        "                    'success': episode_data['metadata']['success'],\n",
        "                    'task': episode_data['metadata']['task_name'],\n",
        "                    'total_reward': sum(s['reward'] for s in steps),\n",
        "                },\n",
        "                'steps': steps\n",
        "            }\n",
        "            \n",
        "            yield f\"episode_{episode_idx}\", episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. È´òÁ∫ßÊï∞ÊçÆÂèòÊç¢Ê°ÜÊû∂\n",
        "\n",
        "RLDS‰∏∫TFDSÊ∑ªÂä†‰∫Ü‰∏ìÈó®ÁöÑÂèòÊç¢Ê°ÜÊû∂ÔºåÊîØÊåÅÂ§çÊùÇÁöÑRLÊï∞ÊçÆÂ§ÑÁêÜÔºö\n",
        "\n",
        "#### a) EpisodeÁ∫ßÂèòÊç¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds.transformations as rlds_transforms\n",
        "\n",
        "def advanced_episode_transform():\n",
        "    \"\"\"È´òÁ∫ßepisodeÂèòÊç¢Á§∫‰æã\"\"\"\n",
        "    \n",
        "    def add_episode_statistics(episode):\n",
        "        \"\"\"‰∏∫episodeÊ∑ªÂä†ÁªüËÆ°‰ø°ÊÅØ\"\"\"\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # ËÆ°ÁÆóepisodeÁ∫ßÁªüËÆ°\n",
        "        total_steps = tf.data.experimental.cardinality(steps)\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        total_reward = rewards.reduce(tf.constant(0.0), tf.add)\n",
        "        \n",
        "        # Ê∑ªÂä†Âà∞ÂÖÉÊï∞ÊçÆ\n",
        "        episode['episode_metadata']['episode_length'] = total_steps\n",
        "        episode['episode_metadata']['total_reward'] = total_reward\n",
        "        return episode\n",
        "    \n",
        "    def filter_successful_episodes(episode):\n",
        "        \"\"\"ËøáÊª§ÊàêÂäüÁöÑepisode\"\"\"\n",
        "        return episode['episode_metadata']['success']\n",
        "    \n",
        "    def normalize_rewards(episode):\n",
        "        \"\"\"ÂΩí‰∏ÄÂåñÂ•ñÂä±\"\"\"\n",
        "        def normalize_step(step):\n",
        "            # Â∫îÁî®z-scoreÂΩí‰∏ÄÂåñ\n",
        "            normalized_reward = (step['reward'] - reward_mean) / reward_std\n",
        "            step['reward'] = normalized_reward\n",
        "            return step\n",
        "        \n",
        "        steps = episode[rlds.STEPS].map(normalize_step)\n",
        "        episode[rlds.STEPS] = steps\n",
        "        return episode\n",
        "    \n",
        "    return [add_episode_statistics, filter_successful_episodes, normalize_rewards]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) StepÁ∫ßÈ´òÁ∫ßÂèòÊç¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def advanced_step_transforms():\n",
        "    \"\"\"È´òÁ∫ßstepÂèòÊç¢Á§∫‰æã\"\"\"\n",
        "    \n",
        "    def augment_observations(step):\n",
        "        \"\"\"Êï∞ÊçÆÂ¢ûÂº∫\"\"\"\n",
        "        obs = step['observation']\n",
        "        \n",
        "        # ÂõæÂÉèÂ¢ûÂº∫\n",
        "        if 'image_primary' in obs:\n",
        "            image = obs['image_primary']\n",
        "            # ÈöèÊú∫È¢úËâ≤ÊäñÂä®\n",
        "            image = tf.image.random_hue(image, max_delta=0.1)\n",
        "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "            obs['image_primary'] = image\n",
        "        \n",
        "        step['observation'] = obs\n",
        "        return step\n",
        "    \n",
        "    def add_next_observation(step, next_step):\n",
        "        \"\"\"Ê∑ªÂä†‰∏ã‰∏ÄÊ≠•ËßÇÊµãÔºàÁî®‰∫éQÂ≠¶‰π†Á≠âÔºâ\"\"\"\n",
        "        step['next_observation'] = next_step['observation']\n",
        "        return step\n",
        "    \n",
        "    def compute_advantage(step, value_estimate):\n",
        "        \"\"\"ËÆ°ÁÆó‰ºòÂäøÂáΩÊï∞ÔºàÁî®‰∫éÁ≠ñÁï•Ê¢ØÂ∫¶Ôºâ\"\"\"\n",
        "        step['advantage'] = step['reward'] + 0.99 * value_estimate - step['value']\n",
        "        return step\n",
        "    \n",
        "    return [augment_observations, add_next_observation, compute_advantage]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4. Âπ∂Ë°åÂåñÊï∞ÊçÆÊûÑÂª∫ÊîØÊåÅ\n",
        "\n",
        "RLDSÊâ©Â±ï‰∫ÜTFDSÁöÑApache BeamÊîØÊåÅÔºåÂÆûÁé∞È´òÊïàÁöÑÂπ∂Ë°åÊï∞ÊçÆÂ§ÑÁêÜÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‰º†ÁªüTFDSÊûÑÂª∫\n",
        "tfds build\n",
        "\n",
        "# RLDSÂπ∂Ë°åÊûÑÂª∫\n",
        "tfds build --overwrite --beam_pipeline_options=\"direct_running_mode=multi_processing,direct_num_workers=16\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Ëá™ÂÆö‰πâÂπ∂Ë°åÂ§ÑÁêÜÂô®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSParallelBuilder(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"ÊîØÊåÅÂπ∂Ë°åÂ§ÑÁêÜÁöÑRLDSÊûÑÂª∫Âô®\"\"\"\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        \"\"\"ÊîØÊåÅBeamÂπ∂Ë°åÂ§ÑÁêÜÁöÑÁîüÊàêÂô®\"\"\"\n",
        "        import apache_beam as beam\n",
        "        \n",
        "        # ÂàõÂª∫BeamÁÆ°ÈÅì\n",
        "        with beam.Pipeline() as pipeline:\n",
        "            episodes = (\n",
        "                pipeline\n",
        "                | 'CreateEpisodePaths' >> beam.Create(self._get_episode_paths(data_path))\n",
        "                | 'ProcessEpisodes' >> beam.Map(self._process_single_episode)\n",
        "                | 'ValidateEpisodes' >> beam.Filter(self._is_valid_episode)\n",
        "                | 'FormatForTFDS' >> beam.Map(self._format_for_tfds)\n",
        "            )\n",
        "        \n",
        "        return episodes\n",
        "    \n",
        "    def _process_single_episode(self, episode_path):\n",
        "        \"\"\"Â§ÑÁêÜÂçï‰∏™episodeÔºàÂπ∂Ë°åÊâßË°åÔºâ\"\"\"\n",
        "        # Ëøô‰∏™ÂáΩÊï∞‰ºöÂú®Â§ö‰∏™worker‰∏äÂπ∂Ë°åÊâßË°å\n",
        "        raw_data = self._load_episode_data(episode_path)\n",
        "        processed_episode = self._convert_to_rlds_format(raw_data)\n",
        "        return processed_episode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5. Êï∞ÊçÆÈõÜ‰øÆÊîπÂíåËΩ¨Êç¢Ê°ÜÊû∂\n",
        "\n",
        "RLDSÊèê‰æõ‰∫ÜÂº∫Â§ßÁöÑÊï∞ÊçÆÈõÜÂêéÂ§ÑÁêÜËÉΩÂäõÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‰ΩøÁî®RLDSÊï∞ÊçÆÈõÜ‰øÆÊîπÊ°ÜÊû∂\n",
        "python modify_rlds_dataset.py \\\n",
        "    --dataset=my_robot_dataset \\\n",
        "    --mods=resize_images,add_language_conditioning,normalize_actions \\\n",
        "    --target_dir=/path/to/modified/dataset \\\n",
        "    --n_workers=16\n",
        "\n",
        "# ÊîØÊåÅÁöÑ‰øÆÊîπÊìç‰Ωú\n",
        "SUPPORTED_MODIFICATIONS = {\n",
        "    'resize_images': ResizeImagesTransform(target_size=(224, 224)),\n",
        "    'jpeg_encode': JpegEncodeTransform(quality=95),\n",
        "    'add_language_conditioning': AddLanguageConditioningTransform(),\n",
        "    'normalize_actions': NormalizeActionsTransform(),\n",
        "    'filter_by_success': FilterBySuccessTransform(),\n",
        "    'subsample_timesteps': SubsampleTimestepsTransform(factor=2),\n",
        "    'add_goal_conditioning': AddGoalConditioningTransform(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Ëá™ÂÆö‰πâ‰øÆÊîπÂáΩÊï∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomRLDSModification:\n",
        "    \"\"\"Ëá™ÂÆö‰πâRLDSÊï∞ÊçÆ‰øÆÊîπ\"\"\"\n",
        "    \n",
        "    def modify_dataset_info(self, info):\n",
        "        \"\"\"‰øÆÊîπÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\"\"\"\n",
        "        # Ê∑ªÂä†Êñ∞ÁöÑÁâπÂæÅ\n",
        "        features = info.features.copy()\n",
        "        features['steps']['goal_image'] = tfds.features.Image(shape=(224, 224, 3))\n",
        "        \n",
        "        return info._replace(features=features)\n",
        "    \n",
        "    def modify_example(self, example):\n",
        "        \"\"\"‰øÆÊîπÂçï‰∏™Ê†∑Êú¨\"\"\"\n",
        "        steps = example['steps']\n",
        "        \n",
        "        # ‰∏∫ÊØè‰∏™stepÊ∑ªÂä†ÁõÆÊ†áÂõæÂÉè\n",
        "        def add_goal_to_step(step):\n",
        "            # ‰ΩøÁî®ÊúÄÂêé‰∏ÄÊ≠•ÁöÑËßÇÊµã‰Ωú‰∏∫ÁõÆÊ†á\n",
        "            step['goal_image'] = steps[-1]['observation']['image_primary']\n",
        "            return step\n",
        "        \n",
        "        modified_steps = steps.map(add_goal_to_step)\n",
        "        example['steps'] = modified_steps\n",
        "        \n",
        "        return example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 6. ‰∏ìÁî®ÁöÑRLDSÈ™åËØÅÊ°ÜÊû∂\n",
        "\n",
        "RLDSÊâ©Â±ï‰∫ÜTFDSÁöÑÈ™åËØÅÊú∫Âà∂ÔºåÂ¢ûÂä†‰∫ÜRLÁâπÂÆöÁöÑÊ£ÄÊü•Ôºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSValidator:\n",
        "    \"\"\"RLDSÊï∞ÊçÆÈõÜÈ™åËØÅÂô®\"\"\"\n",
        "    \n",
        "    def validate_episode_structure(self, episode):\n",
        "        \"\"\"È™åËØÅepisodeÁªìÊûÑ\"\"\"\n",
        "        checks = [\n",
        "            self._check_required_fields(episode),\n",
        "            self._check_step_consistency(episode),\n",
        "            self._check_temporal_ordering(episode),\n",
        "            self._check_terminal_states(episode),\n",
        "            self._check_reward_validity(episode),\n",
        "        ]\n",
        "        \n",
        "        return all(checks)\n",
        "    \n",
        "    def _check_step_consistency(self, episode):\n",
        "        \"\"\"Ê£ÄÊü•Ê≠•È™§‰∏ÄËá¥ÊÄß\"\"\"\n",
        "        steps = episode['steps']\n",
        "        \n",
        "        # Ê£ÄÊü•Á¨¨‰∏ÄÊ≠•Ê†áËÆ∞\n",
        "        first_step = next(iter(steps))\n",
        "        if not first_step['is_first']:\n",
        "            raise ValueError(\"First step must have is_first=True\")\n",
        "        \n",
        "        # Ê£ÄÊü•ÊúÄÂêé‰∏ÄÊ≠•Ê†áËÆ∞\n",
        "        step_count = 0\n",
        "        last_step = None\n",
        "        for step in steps:\n",
        "            step_count += 1\n",
        "            last_step = step\n",
        "        \n",
        "        if not last_step['is_last']:\n",
        "            raise ValueError(\"Last step must have is_last=True\")\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def _check_temporal_ordering(self, episode):\n",
        "        \"\"\"Ê£ÄÊü•Êó∂Èó¥Â∫èÂàóÂÆåÊï¥ÊÄß\"\"\"\n",
        "        steps = list(episode['steps'])\n",
        "        \n",
        "        # È™åËØÅÊó∂Èó¥Êà≥ÂçïË∞ÉÈÄíÂ¢û\n",
        "        if 'timestamp' in steps[0].get('step_metadata', {}):\n",
        "            timestamps = [s['step_metadata']['timestamp'] for s in steps]\n",
        "            if not all(t1 <= t2 for t1, t2 in zip(timestamps, timestamps[1:])):\n",
        "                raise ValueError(\"Timestamps must be non-decreasing\")\n",
        "        \n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 7. Open X-EmbodimentÊï∞ÊçÆÈõÜÈõÜÊàê\n",
        "\n",
        "RLDS‰∏∫Â§ßËßÑÊ®°Êú∫Âô®‰∫∫Êï∞ÊçÆÈõÜÊèê‰æõ‰∫Ü‰∏ìÈó®ÁöÑÊîØÊåÅÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open X-EmbodimentÊï∞ÊçÆÈõÜ‰∏ãËΩΩÂíåÂ§ÑÁêÜ\n",
        "bash prepare_open_x.sh\n",
        "\n",
        "# ÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜËΩ¨Êç¢\n",
        "OPEN_X_DATASETS = [\n",
        "    'bridge_v2',\n",
        "    'rt_1',\n",
        "    'berkeley_autolab_ur5',\n",
        "    'taco_play',\n",
        "    'kuka_multimodal',\n",
        "    'stanford_robocook',\n",
        "    # ... 50+ Êï∞ÊçÆÈõÜ\n",
        "]\n",
        "\n",
        "# Áªü‰∏ÄÁöÑÂèòÊç¢Êé•Âè£\n",
        "def transform_for_x_embodiment(step):\n",
        "    \"\"\"ËΩ¨Êç¢‰∏∫X-embodimentÊ†áÂáÜÊ†ºÂºè\"\"\"\n",
        "    return {\n",
        "        'observation': {\n",
        "            'image': step['observation']['image_primary'],  # Âçï‰∏ÄRGBËæìÂÖ•\n",
        "            'natural_language_embedding': step['language_embedding'],\n",
        "        },\n",
        "        'action': step['action'][:7],  # Ê†áÂáÜ7-DOFÂä®‰Ωú\n",
        "        'reward': step['reward'],\n",
        "        'is_first': step['is_first'],\n",
        "        'is_last': step['is_last'],\n",
        "        'is_terminal': step['is_terminal'],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 8. È´òÁ∫ßÊÄßËÉΩ‰ºòÂåñ\n",
        "\n",
        "RLDSÂÆûÁé∞‰∫ÜÈíàÂØπRLÊï∞ÊçÆÁöÑ‰∏ìÈó®‰ºòÂåñÔºö\n",
        "\n",
        "#### a) Êô∫ËÉΩÁºìÂ≠òÁ≠ñÁï•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RLDSCachingStrategy:\n",
        "    \"\"\"RLDS‰∏ìÁî®ÁºìÂ≠òÁ≠ñÁï•\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.episode_cache = {}\n",
        "        self.step_cache = {}\n",
        "    \n",
        "    def cache_episode(self, episode_id, episode):\n",
        "        \"\"\"ÁºìÂ≠òÂÆåÊï¥episode\"\"\"\n",
        "        # Âè™ÁºìÂ≠òÂ∞èÂûãepisodeÔºåÈÅøÂÖçÂÜÖÂ≠òÊ∫¢Âá∫\n",
        "        if self._estimate_episode_size(episode) < 100_000_000:  # 100MB\n",
        "            self.episode_cache[episode_id] = episode\n",
        "    \n",
        "    def cache_step_sequence(self, episode_id, start_idx, steps):\n",
        "        \"\"\"ÁºìÂ≠òÊ≠•È™§Â∫èÂàóÔºàÁî®‰∫éN-stepÂ≠¶‰π†Ôºâ\"\"\"\n",
        "        cache_key = f\"{episode_id}_{start_idx}\"\n",
        "        self.step_cache[cache_key] = steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### b) Ëá™ÈÄÇÂ∫îÊâπÂ§ÑÁêÜ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaptive_batching(dataset, target_memory_usage=8_000_000_000):  # 8GB\n",
        "    \"\"\"Ê†πÊçÆÂÜÖÂ≠ò‰ΩøÁî®ÊÉÖÂÜµËá™ÈÄÇÂ∫îË∞ÉÊï¥ÊâπÂ§ßÂ∞è\"\"\"\n",
        "    \n",
        "    def estimate_sample_size(sample):\n",
        "        \"\"\"‰º∞ÁÆóÊ†∑Êú¨ÂÜÖÂ≠ò‰ΩøÁî®\"\"\"\n",
        "        size = 0\n",
        "        for step in sample['steps']:\n",
        "            for key, value in step['observation'].items():\n",
        "                if 'image' in key:\n",
        "                    size += value.shape.num_elements() * 4  # float32\n",
        "                else:\n",
        "                    size += value.shape.num_elements() * value.dtype.size\n",
        "        return size\n",
        "    \n",
        "    # Âä®ÊÄÅËÆ°ÁÆóÊâπÂ§ßÂ∞è\n",
        "    sample = next(iter(dataset))\n",
        "    sample_size = estimate_sample_size(sample)\n",
        "    optimal_batch_size = max(1, target_memory_usage // sample_size)\n",
        "    \n",
        "    return dataset.batch(optimal_batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9. ‰∏éÁé∞ÊúâÁîüÊÄÅÁ≥ªÁªüÁöÑÂÖºÂÆπÊÄß\n",
        "\n",
        "RLDSÁ°Æ‰øù‰∏éTensorFlowÁîüÊÄÅÁ≥ªÁªüÁöÑÂÆåÁæéÂÖºÂÆπÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‰∏étf.dataÁöÑÊó†ÁºùÈõÜÊàê\n",
        "rlds_dataset = tfds.load('my_robot_dataset')\n",
        "tf_data_pipeline = (\n",
        "    rlds_dataset['train']\n",
        "    .flat_map(lambda ep: ep['steps'])  # Â±ïÂπ≥‰∏∫stepÁ∫ßÊï∞ÊçÆ\n",
        "    .map(preprocess_function)\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# ‰∏étf.saved_modelÁöÑÂÖºÂÆπ\n",
        "@tf.function\n",
        "def process_rlds_batch(batch):\n",
        "    \"\"\"Â§ÑÁêÜRLDSÊâπÊ¨°Êï∞ÊçÆ\"\"\"\n",
        "    observations = batch['observation']['image']\n",
        "    actions = batch['action']\n",
        "    return model(observations), actions\n",
        "\n",
        "# ‰øùÂ≠ò‰∏∫SavedModel\n",
        "tf.saved_model.save(process_rlds_batch, '/path/to/saved_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ÂºïÁî®ÂíåËá¥Ë∞¢\n",
        "\n",
        "Â¶ÇÊûú‰ΩøÁî®RLDSÔºåËØ∑ÂºïÁî®ÂÆòÊñπËÆ∫ÊñáÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@misc{ramos2021rlds,\n",
        "    title={RLDS: an Ecosystem to Generate, Share and Use Datasets in Reinforcement Learning},\n",
        "    author={Sabela Ramos and Sertan Girgin and L√©onard Hussenot and Damien Vincent and Hanna Yakubovich and Daniel Toyama and Anita Gergely and Piotr Stanczyk and Raphael Marinier and Jeremiah Harmsen and Olivier Pietquin and Nikola Momchev},\n",
        "    year={2021},\n",
        "    eprint={2111.02767},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.LG}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ‰ΩøÁî®RLDSÁöÑÈáçË¶ÅËÆ∫Êñá\n",
        "\n",
        "- **Hyperparameter Selection for Imitation Learning** (ICML 2021)\n",
        "- **Continuous Control with Action Quantization from Demonstrations** (NeurIPS 2021)  \n",
        "- **What Matters for Adversarial Imitation Learning?** (NeurIPS 2021)\n",
        "- **MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale**\n",
        "- **Offline Reinforcement Learning with Pseudometric Learning** (ICML 2021)\n",
        "\n",
        "## ÊÄªÁªì\n",
        "\n",
        "RLDSÊèê‰æõ‰∫Ü‰∏Ä‰∏™Ê†áÂáÜÂåñ„ÄÅÈ´òÊïàÁöÑÂº∫ÂåñÂ≠¶‰π†Êï∞ÊçÆÂ≠òÂÇ®ÂíåÂ§ÑÁêÜÊ°ÜÊû∂„ÄÇÂÖ∂‰∏ªË¶Å‰ºòÂäøÂåÖÊã¨Ôºö\n",
        "\n",
        "1. **Ê†áÂáÜÂåñÊ†ºÂºè**ÔºöÁªü‰∏ÄÁöÑÊï∞ÊçÆÁªìÊûÑ‰æø‰∫é‰∏çÂêåÈ°πÁõÆÈó¥ÁöÑÊï∞ÊçÆÂÖ±‰∫´\n",
        "2. **È´òÊïàÂ≠òÂÇ®**ÔºöÂü∫‰∫éTensorFlowÁöÑ‰ºòÂåñÂ≠òÂÇ®Ê†ºÂºè  \n",
        "3. **‰∏∞ÂØåÂÖÉÊï∞ÊçÆ**ÔºöÊîØÊåÅËØ¶ÁªÜÁöÑ‰ªªÂä°ÂíåËΩ®ËøπÊ†áÊ≥®\n",
        "4. **Êòì‰∫éÂ§ÑÁêÜ**Ôºö‰∏éÁé∞‰ª£Êú∫Âô®Â≠¶‰π†Â∑•ÂÖ∑ÈìæÊó†ÁºùÈõÜÊàê\n",
        "5. **ÂèØÊâ©Â±ïÊÄß**ÔºöÊîØÊåÅËá™ÂÆö‰πâËßÇÊµãÁ©∫Èó¥Âíå‰ªªÂä°ÁâπÂÆöÂ≠óÊÆµ\n",
        "6. **ÊÄßËÉΩ‰ºòÂåñ**ÔºöÈíàÂØπRLÊï∞ÊçÆÁâπÁÇπÁöÑ‰∏ìÈó®‰ºòÂåñ\n",
        "7. **Á§æÂå∫ÁîüÊÄÅ**ÔºöÊ¥ªË∑ÉÁöÑÂºÄÊ∫êÁ§æÂå∫Âíå‰∏∞ÂØåÁöÑÊï∞ÊçÆÈõÜËµÑÊ∫ê\n",
        "\n",
        "ÈÄöËøá‰ΩøÁî®RLDSÔºåÁ†îÁ©∂ËÄÖÂèØ‰ª•Êõ¥ÂÆπÊòìÂú∞ÊûÑÂª∫„ÄÅÂÖ±‰∫´Âíå‰ΩøÁî®Â§ßËßÑÊ®°Âº∫ÂåñÂ≠¶‰π†Êï∞ÊçÆÈõÜÔºåÊé®Âä®Âº∫ÂåñÂ≠¶‰π†ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ \n",
        "\n",
        "## È´òÁ∫ßÊï∞ÊçÆÁªìÊûÑËßÑËåÉ\n",
        "\n",
        "### EpisodeÂÖÉÊï∞ÊçÆÊâ©Â±ïËßÑËåÉ\n",
        "\n",
        "Âü∫‰∫éÂÆòÊñπGitHub‰ªìÂ∫ìÔºåEpisodeÊîØÊåÅ‰ª•‰∏ãÊ†áÂáÜÂÖÉÊï∞ÊçÆÂ≠óÊÆµÔºö\n",
        "\n",
        "| Â≠óÊÆµÂêç | Á±ªÂûã | ÂøÖÈúÄ | ÊèèËø∞ | Á§∫‰æã |\n",
        "|--------|------|------|------|------|\n",
        "| `episode_id` | `tf.string` | Êé®Ëçê | ÂÖ®Â±ÄÂîØ‰∏ÄÊ†áËØÜÁ¨¶ | `\"dataset_v1_episode_12345\"` |\n",
        "| `agent_id` | `tf.string/tf.Tensor` | ÂèØÈÄâ | Êô∫ËÉΩ‰ΩìÊ†áËØÜÁ¨¶(ÊîØÊåÅÂ§öÊô∫ËÉΩ‰Ωì) | `\"sac_agent_v2\"` Êàñ `[[agent_name, agent_id], ...]` |\n",
        "| `environment_config` | `dict` | ÂèØÈÄâ | ÁéØÂ¢ÉÈÖçÁΩÆÂèÇÊï∞ | `{\"gravity\": -9.8, \"friction\": 0.1}` |\n",
        "| `experiment_id` | `tf.string` | ÂèØÈÄâ | ÂÆûÈ™åÊ†áËØÜÁ¨¶ | `\"exp_20231215_hyperopt\"` |\n",
        "| `invalid` | `tf.bool` | ÂèØÈÄâ | Êó†ÊïàepisodeÊ†áËÆ∞ | `False` |\n",
        "\n",
        "### StepÂ≠óÊÆµÂÆåÊï¥ËßÑËåÉ\n",
        "\n",
        "#### ÂøÖÈúÄÂ≠óÊÆµ\n",
        "| Â≠óÊÆµÂêç | Á±ªÂûã | ÊèèËø∞ | ÈáçË¶ÅËØ¥Êòé |\n",
        "|--------|------|------|----------|\n",
        "| `is_first` | `tf.bool` | ÊòØÂê¶‰∏∫È¶ñÊ≠• | ÂåÖÂê´ÂàùÂßãÁä∂ÊÄÅ |\n",
        "| `is_last` | `tf.bool` | ÊòØÂê¶‰∏∫Êú´Ê≠• | ÂΩì‰∏∫TrueÊó∂ÔºåÂêéÁª≠Â≠óÊÆµÊó†Êïà |\n",
        "\n",
        "#### ÂèØÈÄâÂ≠óÊÆµ\n",
        "| Â≠óÊÆµÂêç | Á±ªÂûã | ÊèèËø∞ | Êù°‰ª∂Á∫¶Êùü |\n",
        "|--------|------|------|----------|\n",
        "| `observation` | `dict` | ÂΩìÂâçËßÇÊµã | ÁªìÊûÑÂú®Êï∞ÊçÆÈõÜÂÜÖÂøÖÈ°ª‰∏ÄËá¥ |\n",
        "| `action` | `tf.Tensor` | ÊâßË°åÁöÑÂä®‰Ωú | `is_last=True`Êó∂Êó†Êïà |\n",
        "| `reward` | `tf.float32` | Ëé∑ÂæóÁöÑÂ•ñÂä± | `is_last=True`Êó∂Êó†Êïà |\n",
        "| `discount` | `tf.float32` | ÊäòÊâ£Âõ†Â≠ê | ÈÄöÂ∏∏‰∏∫1.0ÊàñŒ≥ |\n",
        "| `is_terminal` | `tf.bool` | ÊòØÂê¶‰∏∫ÁªàÊ≠¢Áä∂ÊÄÅ | Âå∫ÂàÜÊà™Êñ≠vsÁªàÊ≠¢ |\n",
        "\n",
        "#### ÁªàÊ≠¢Áä∂ÊÄÅËØ≠‰πâ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ëá™ÁÑ∂ÁªàÊ≠¢ (Ê∏∏ÊàèÁªìÊùü)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': True,\n",
        "    'observation': final_obs,  # ÊúâÊïàÁöÑÊúÄÁªàËßÇÊµã\n",
        "    'action': None,           # Êó†Êïà\n",
        "    'reward': None,           # Êó†Êïà\n",
        "    'discount': None          # Êó†Êïà\n",
        "}\n",
        "\n",
        "# Êà™Êñ≠ÁªàÊ≠¢ (Êó∂Èó¥ÈôêÂà∂)\n",
        "{\n",
        "    'is_last': True,\n",
        "    'is_terminal': False,\n",
        "    'observation': final_obs,  # ÊúâÊïàÁöÑÊà™Êñ≠ËßÇÊµã\n",
        "    'action': None,           # ÂèØËÉΩÊó†Êïà\n",
        "    'reward': final_reward,   # ÂèØËÉΩÊúâÊïà\n",
        "    'discount': gamma         # ÂèØËÉΩÊúâÊïà\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## RLDSÂèòÊç¢Â∫ìËØ¶Ëß£\n",
        "\n",
        "### Ê†∏ÂøÉÂèòÊç¢Êìç‰Ωú\n",
        "\n",
        "RLDSÊèê‰æõ‰ºòÂåñÁöÑÂèòÊç¢Â∫ìÔºåËÄÉËôë‰∫ÜRLÊï∞ÊçÆÈõÜÁöÑÂµåÂ•óÁªìÊûÑÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rlds\n",
        "\n",
        "# 1. EpisodeÁ∫ßÂèòÊç¢\n",
        "def process_episode(episode):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    # Ê∑ªÂä†Ëá™ÂÆö‰πâepisodeÁªüËÆ°\n",
        "    episode_length = tf.data.experimental.cardinality(steps)\n",
        "    episode['metadata']['length'] = episode_length\n",
        "    return episode\n",
        "\n",
        "dataset = dataset.map(process_episode)\n",
        "\n",
        "# 2. StepÁ∫ßÂèòÊç¢ - Â±ïÂπ≥episode\n",
        "step_dataset = episode_dataset.flat_map(lambda x: x[rlds.STEPS])\n",
        "\n",
        "# 3. Á™óÂè£ÂåñÂèòÊç¢ - NÊ≠•ËΩ¨Áßª\n",
        "def make_n_step_transitions(episode, n=5):\n",
        "    steps = episode[rlds.STEPS]\n",
        "    windowed = steps.window(n, shift=1, drop_remainder=True)\n",
        "    return windowed.flat_map(lambda w: w.batch(n))\n",
        "\n",
        "# 4. ËøáÊª§ÂèòÊç¢\n",
        "def filter_successful_episodes(episode):\n",
        "    return episode['metadata']['success'] == True\n",
        "\n",
        "dataset = dataset.filter(filter_successful_episodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### È´òÊÄßËÉΩÊâπÂ§ÑÁêÜ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ëá™Âä®ÊâπÂ§ÑÁêÜ - ËÄÉËôëepisodeËæπÁïå\n",
        "def smart_batch(dataset, batch_size, respect_episode_boundaries=True):\n",
        "    if respect_episode_boundaries:\n",
        "        # Á°Æ‰øùbatchÂÜÖÁöÑstepÊù•Ëá™Âêå‰∏Äepisode\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS].batch(batch_size)\n",
        "        )\n",
        "    else:\n",
        "        # Ë∑®episodeÊâπÂ§ÑÁêÜ\n",
        "        return dataset.flat_map(\n",
        "            lambda ep: ep[rlds.STEPS]\n",
        "        ).batch(batch_size)\n",
        "\n",
        "# Á§∫‰æãÁî®Ê≥ï\n",
        "batched_steps = smart_batch(dataset, batch_size=32, \n",
        "                           respect_episode_boundaries=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ÊÄßËÉΩ‰ºòÂåñÊúÄ‰Ω≥ÂÆûË∑µ\n",
        "\n",
        "### 1. ÂÜÖÂ≠ò‰ºòÂåñ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÂáèÂ∞ëÂÜÖÂ≠ò‰ΩøÁî®ÁöÑReadConfig\n",
        "read_config = tfds.ReadConfig(\n",
        "    # ÂáèÂ∞ëÂπ∂Ë°åÂä†ËΩΩÁöÑÊñá‰ª∂Êï∞\n",
        "    interleave_cycle_length=4,\n",
        "    interleave_block_length=1,\n",
        "    # ÂêØÁî®Á°ÆÂÆöÊÄßËØªÂèñ\n",
        "    shuffle_seed=42,\n",
        "    shuffle_reshuffle_each_iteration=True\n",
        ")\n",
        "\n",
        "dataset = tfds.load('dataset_name', read_config=read_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. Âπ∂Ë°åÂ§ÑÁêÜ‰ºòÂåñ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Â§öËøõÁ®ãÊï∞ÊçÆÂä†ËΩΩ\n",
        "def optimized_pipeline(dataset_name, num_parallel_calls=tf.data.AUTOTUNE):\n",
        "    dataset = tfds.load(dataset_name, shuffle_files=True)\n",
        "    \n",
        "    # Âπ∂Ë°åËß£Á†ÅÂíåÈ¢ÑÂ§ÑÁêÜ\n",
        "    dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        num_parallel_calls=num_parallel_calls\n",
        "    )\n",
        "    \n",
        "    # È¢ÑÂèñ‰ºòÂåñ\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. ÈöèÊú∫ÂåñÁ≠ñÁï•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÊñπÂºè1: ÂÆåÁæéÈöèÊú∫Âåñ (È´òÂÜÖÂ≠ò)\n",
        "shuffled = dataset.shuffle(buffer_size=10000)  # ÈúÄË¶ÅÂ§ßÁºìÂÜ≤Âå∫\n",
        "\n",
        "# ÊñπÂºè2: ‰∫§ÈîôÈöèÊú∫Âåñ (ÂÜÖÂ≠òÂèãÂ•Ω)\n",
        "def create_interleaved_dataset(dataset_name, num_copies=4):\n",
        "    def dataset_loader():\n",
        "        ds = tfds.load(dataset_name, shuffle_files=True)\n",
        "        return ds.flat_map(lambda x: x[rlds.STEPS])\n",
        "    \n",
        "    # ÂàõÂª∫Â§ö‰∏™Áã¨Á´ãÈöèÊú∫ÂåñÁöÑÊï∞ÊçÆÈõÜÂâØÊú¨\n",
        "    dataset = tf.data.Dataset.range(num_copies).interleave(\n",
        "        lambda _: dataset_loader(),\n",
        "        cycle_length=num_copies,\n",
        "        block_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "# ÊñπÂºè3: ÂàÜÁâáÈöèÊú∫Âåñ (ÈÅøÂÖçÈáçÂ§ç)\n",
        "def distributed_random_access(dataset_name, num_workers, worker_id):\n",
        "    # ÊØè‰∏™workerÂ§ÑÁêÜ‰∏çÂêåÁöÑÂàÜÁâá\n",
        "    split_name = f'train[{worker_id}shard{num_workers}]'\n",
        "    return tfds.load(dataset_name, split=split_name, shuffle_files=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Â§öÊô∫ËÉΩ‰ΩìÊîØÊåÅ\n",
        "\n",
        "RLDSÂéüÁîüÊîØÊåÅÂ§öÊô∫ËÉΩ‰ΩìÂú∫ÊôØÔºö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Â§öÊô∫ËÉΩ‰ΩìEpisodeÁªìÊûÑ\n",
        "multi_agent_episode = {\n",
        "    'episode_id': 'multi_agent_001',\n",
        "    'agent_id': tf.constant([\n",
        "        ['player_1', 'dqn_agent_v1'],\n",
        "        ['player_2', 'human_expert'],\n",
        "        ['env_bot', 'scripted_agent']\n",
        "    ]),\n",
        "    'steps': [\n",
        "        {\n",
        "            'observation': {\n",
        "                'player_1': player1_obs,\n",
        "                'player_2': player2_obs,\n",
        "                'global': global_obs\n",
        "            },\n",
        "            'action': {\n",
        "                'player_1': player1_action,\n",
        "                'player_2': player2_action\n",
        "            },\n",
        "            'reward': {\n",
        "                'player_1': player1_reward,\n",
        "                'player_2': player2_reward\n",
        "            },\n",
        "            'is_first': True,\n",
        "            'is_last': False,\n",
        "            'is_terminal': False\n",
        "        }\n",
        "    ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ÂèØÁî®Êï∞ÊçÆÈõÜÁîüÊÄÅ\n",
        "\n",
        "### ÂÆòÊñπÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜ\n",
        "\n",
        "| Êï∞ÊçÆÈõÜÁ≥ªÂàó | È¢ÜÂüü | ‰ªªÂä°Êï∞Èáè | ÊèèËø∞ |\n",
        "|------------|------|----------|------|\n",
        "| **D4RL** | Êú∫Âô®‰∫∫/Ê∏∏Êàè | 34+ | Mujoco, Adroit, AntMaze‰ªªÂä° |\n",
        "| **RL Unplugged** | Â§öÈ¢ÜÂüü | 50+ | DMLab, Atari, ÁúüÂÆû‰∏ñÁïåRL |\n",
        "| **Robosuite** | Êú∫Âô®‰∫∫Êìç‰Ωú | 3 | Áî®RLDSÂ∑•ÂÖ∑ÁîüÊàê |\n",
        "| **Robomimic** | Êú∫Âô®‰∫∫Â≠¶‰π† | 15+ | Ê®°‰ªøÂ≠¶‰π†Êï∞ÊçÆÈõÜ |\n",
        "| **MuJoCo Locomotion** | ËøêÂä®ÊéßÂà∂ | 8 | SACÊô∫ËÉΩ‰ΩìÁîüÊàê |\n",
        "| **MT-Opt** | Êú∫Âô®‰∫∫ | 1 | Â§ßËßÑÊ®°Â§ö‰ªªÂä°Êï∞ÊçÆÈõÜ |\n",
        "\n",
        "### Êï∞ÊçÆÈõÜ‰ΩøÁî®Á§∫‰æã\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Âä†ËΩΩ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆÈõÜ\n",
        "datasets = {\n",
        "    # ËøûÁª≠ÊéßÂà∂\n",
        "    'mujoco': tfds.load('d4rl_mujoco_hopper/v1-medium'),\n",
        "    \n",
        "    # Á¶ªÊï£ÊéßÂà∂  \n",
        "    'atari': tfds.load('rl_unplugged_atari_breakout/run_1'),\n",
        "    \n",
        "    # Êú∫Âô®‰∫∫Êìç‰Ωú\n",
        "    'robot': tfds.load('robosuite_lift/human_demos'),\n",
        "    \n",
        "    # ÂØºËà™‰ªªÂä°\n",
        "    'maze': tfds.load('d4rl_antmaze/umaze-v1')\n",
        "}\n",
        "\n",
        "# Áªü‰∏ÄÂ§ÑÁêÜÊé•Âè£\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"\\n{name.upper()} Dataset:\")\n",
        "    for episode in dataset['train'].take(1):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        print(f\"  Episode length: {tf.data.experimental.cardinality(steps)}\")\n",
        "        \n",
        "        for step in steps.take(1):\n",
        "            obs_keys = list(step['observation'].keys())\n",
        "            action_shape = step['action'].shape\n",
        "            print(f\"  Observation keys: {obs_keys}\")\n",
        "            print(f\"  Action shape: {action_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Á§æÂå∫Ë¥°ÁåÆÂíåÊâ©Â±ï\n",
        "\n",
        "### Ê∑ªÂä†Ëá™ÂÆö‰πâÊï∞ÊçÆÈõÜÂà∞TFDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class MyRLDataset(tfds.core.GeneratorBasedBuilder):\n",
        "    \"\"\"Ëá™ÂÆö‰πâRLDSÂÖºÂÆπÊï∞ÊçÆÈõÜ\"\"\"\n",
        "    \n",
        "    VERSION = tfds.core.Version('1.0.0')\n",
        "    \n",
        "    def _info(self) -> tfds.core.DatasetInfo:\n",
        "        return tfds.core.DatasetInfo(\n",
        "            builder=self,\n",
        "            description=\"My custom RL dataset\",\n",
        "            features=tfds.features.FeaturesDict({\n",
        "                'episode_id': tfds.features.Text(),\n",
        "                'steps': tfds.features.Dataset({\n",
        "                    'observation': tfds.features.FeaturesDict({\n",
        "                        'image': tfds.features.Image(shape=(84, 84, 3)),\n",
        "                        'state': tfds.features.Tensor(shape=(10,), dtype=tf.float32),\n",
        "                    }),\n",
        "                    'action': tfds.features.Tensor(shape=(4,), dtype=tf.float32),\n",
        "                    'reward': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'discount': tfds.features.Scalar(dtype=tf.float32),\n",
        "                    'is_first': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_last': tfds.features.Scalar(dtype=tf.bool),\n",
        "                    'is_terminal': tfds.features.Scalar(dtype=tf.bool),\n",
        "                })\n",
        "            }),\n",
        "            supervised_keys=None,\n",
        "            homepage='https://my-dataset-homepage.com',\n",
        "            citation=\"\"\"@article{my2023dataset, ...}\"\"\",\n",
        "        )\n",
        "    \n",
        "    def _split_generators(self, dl_manager):\n",
        "        return [\n",
        "            tfds.core.SplitGenerator(\n",
        "                name=tfds.Split.TRAIN,\n",
        "                gen_kwargs={'data_path': '/path/to/train/data'},\n",
        "            ),\n",
        "        ]\n",
        "    \n",
        "    def _generate_examples(self, data_path):\n",
        "        # ÂÆûÁé∞Êï∞ÊçÆÁîüÊàêÈÄªËæë\n",
        "        for episode_file in episode_files:\n",
        "            episode_id, steps = load_episode(episode_file)\n",
        "            yield episode_id, {\n",
        "                'episode_id': episode_id,\n",
        "                'steps': steps\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ÂÆûÈôÖÂ∫îÁî®Ê°à‰æã\n",
        "\n",
        "### Ê°à‰æã1: Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def offline_rl_pipeline(dataset_name, algorithm='cql'):\n",
        "    # Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
        "    def preprocess_for_offline_rl(episode):\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # ËÆ°ÁÆóreturn-to-go\n",
        "        rewards = steps.map(lambda s: s['reward'])\n",
        "        returns = compute_returns_to_go(rewards)\n",
        "        \n",
        "        # Ê∑ªÂä†return‰ø°ÊÅØ\n",
        "        enriched_steps = tf.data.Dataset.zip((steps, returns))\n",
        "        return enriched_steps.map(lambda step, ret: {\n",
        "            **step, 'return_to_go': ret\n",
        "        })\n",
        "    \n",
        "    processed_dataset = dataset.map(preprocess_for_offline_rl)\n",
        "    \n",
        "    # ËΩ¨Êç¢‰∏∫stepÁ∫ßÊï∞ÊçÆÁî®‰∫éËÆ≠ÁªÉ\n",
        "    step_dataset = processed_dataset.flat_map(lambda x: x)\n",
        "    \n",
        "    return step_dataset.batch(256).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Ê°à‰æã2: Ê®°‰ªøÂ≠¶‰π†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imitation_learning_pipeline(expert_dataset, student_dataset):\n",
        "    # Âä†ËΩΩ‰∏ìÂÆ∂Êï∞ÊçÆ\n",
        "    expert_ds = tfds.load(expert_dataset)['train']\n",
        "    expert_steps = expert_ds.flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # ËøáÊª§ÊàêÂäüÁöÑËΩ®Ëøπ\n",
        "    def is_successful_episode(episode):\n",
        "        return episode.get('metadata', {}).get('success', True)\n",
        "    \n",
        "    expert_steps = expert_ds.filter(is_successful_episode)\\\n",
        "                           .flat_map(lambda ep: ep[rlds.STEPS])\n",
        "    \n",
        "    # ÂàõÂª∫(observation, action)ÂØπ\n",
        "    bc_data = expert_steps.map(lambda step: {\n",
        "        'observation': step['observation'],\n",
        "        'action': step['action']\n",
        "    }).filter(lambda x: not x.get('is_last', False))\n",
        "    \n",
        "    return bc_data.batch(128).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Ê°à‰æã3: Êï∞ÊçÆÈõÜÂàÜÊûê\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset(dataset_name):\n",
        "    \"\"\"ÂÖ®Èù¢ÂàÜÊûêRLDSÊï∞ÊçÆÈõÜ\"\"\"\n",
        "    dataset = tfds.load(dataset_name)['train']\n",
        "    \n",
        "    # EpisodeÁ∫ßÁªüËÆ°\n",
        "    episode_lengths = []\n",
        "    success_rates = []\n",
        "    \n",
        "    # StepÁ∫ßÁªüËÆ°  \n",
        "    action_stats = []\n",
        "    reward_stats = []\n",
        "    \n",
        "    for episode in dataset:\n",
        "        steps = episode[rlds.STEPS]\n",
        "        \n",
        "        # EpisodeÂàÜÊûê\n",
        "        episode_length = tf.data.experimental.cardinality(steps).numpy()\n",
        "        episode_lengths.append(episode_length)\n",
        "        \n",
        "        success = episode.get('metadata', {}).get('success', None)\n",
        "        if success is not None:\n",
        "            success_rates.append(success.numpy())\n",
        "        \n",
        "        # StepÂàÜÊûê\n",
        "        for step in steps:\n",
        "            if not step['is_last']:\n",
        "                action_stats.append(step['action'].numpy())\n",
        "                reward_stats.append(step['reward'].numpy())\n",
        "    \n",
        "    # ÁîüÊàêÊä•Âëä\n",
        "    analysis_report = {\n",
        "        'episode_count': len(episode_lengths),\n",
        "        'avg_episode_length': np.mean(episode_lengths),\n",
        "        'std_episode_length': np.std(episode_lengths),\n",
        "        'success_rate': np.mean(success_rates) if success_rates else None,\n",
        "        'total_steps': sum(episode_lengths),\n",
        "        'action_dimensionality': action_stats[0].shape if action_stats else None,\n",
        "        'reward_range': (np.min(reward_stats), np.max(reward_stats)) if reward_stats else None,\n",
        "    }\n",
        "    \n",
        "    return analysis_report \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "octo_clean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
